From d55902da667b0baafa39302b0acb77150217ce82 Mon Sep 17 00:00:00 2001
From: Ghennadi Procopciuc <ghennadi.procopciuc@nxp.com>
Date: Thu, 23 Sep 2021 15:57:08 +0300
Subject: [PATCH 13/20] arm64: Disable ERR050481 workaround for S32G3

Issue: ALB-7732
Upstream-Status: Pending 

Signed-off-by: Ghennadi Procopciuc <ghennadi.procopciuc@nxp.com>
Signed-off-by: Zhantao Tang <zhantao.tang@windriver.com>
---
 arch/arm64/include/asm/cpucaps.h    |  3 +-
 arch/arm64/include/asm/cpufeature.h | 15 ++++++
 arch/arm64/include/asm/sysreg.h     |  1 +
 arch/arm64/include/asm/tlbflush.h   | 76 +++++++++++++----------------
 arch/arm64/kernel/cpu_errata.c      | 31 ++++++++++++
 5 files changed, 83 insertions(+), 43 deletions(-)

diff --git a/arch/arm64/include/asm/cpucaps.h b/arch/arm64/include/asm/cpucaps.h
index e7d98997c09c..b1fcb914b508 100644
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@ -66,7 +66,8 @@
 #define ARM64_HAS_TLB_RANGE			56
 #define ARM64_MTE				57
 #define ARM64_WORKAROUND_1508412		58
+#define ARM64_WORKAROUND_NXP_ERR050481		59
 
-#define ARM64_NCAPS				59
+#define ARM64_NCAPS				60
 
 #endif /* __ASM_CPUCAPS_H */
diff --git a/arch/arm64/include/asm/cpufeature.h b/arch/arm64/include/asm/cpufeature.h
index da250e4741bd..67109649e6b7 100644
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@ -788,6 +788,21 @@ static inline unsigned int get_vmid_bits(u64 mmfr1)
 u32 get_kvm_ipa_limit(void);
 void dump_cpu_features(void);
 
+static inline bool cpu_has_nxp_err050481(void)
+{
+	if (!IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481))
+		return false;
+
+	/**
+	 * Enable the workaround for the early stages of the boot
+	 * regardless of capability enablement.
+	 */
+	if (!system_capabilities_finalized())
+		return true;
+
+	return cpus_have_const_cap(ARM64_WORKAROUND_NXP_ERR050481);
+}
+
 #endif /* __ASSEMBLY__ */
 
 #endif
diff --git a/arch/arm64/include/asm/sysreg.h b/arch/arm64/include/asm/sysreg.h
index 801861d05426..b1878b53f2f4 100644
--- a/arch/arm64/include/asm/sysreg.h
+++ b/arch/arm64/include/asm/sysreg.h
@@ -380,6 +380,7 @@
 #define SYS_CLIDR_EL1			sys_reg(3, 1, 0, 0, 1)
 #define SYS_GMID_EL1			sys_reg(3, 1, 0, 0, 4)
 #define SYS_AIDR_EL1			sys_reg(3, 1, 0, 0, 7)
+#define SYS_L2CTRL_EL1			sys_reg(3, 1, 11, 0, 2)
 
 #define SYS_CSSELR_EL1			sys_reg(3, 2, 0, 0, 0)
 
diff --git a/arch/arm64/include/asm/tlbflush.h b/arch/arm64/include/asm/tlbflush.h
index 40f993ddedb9..aab97005ab94 100644
--- a/arch/arm64/include/asm/tlbflush.h
+++ b/arch/arm64/include/asm/tlbflush.h
@@ -47,7 +47,37 @@
 
 #define __TLBI_N(op, arg, n, ...) __TLBI_##n(op, arg)
 
+#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
+ /**
+  * This checks if VA[48:41] bitset of an 12 bits shifted address is zero.
+  */
+#define IS_ERR050481_ADDR(addr_shr_12)  \
+	(((addr_shr_12) & GENMASK_ULL(36, 29)) != 0)
+
+#define S32GEN1_TLBI_ALT(OP, ADDR) do {\
+	unsigned long __temp_050481 = (ADDR);\
+	if (cpu_has_nxp_err050481() && IS_ERR050481_ADDR(__temp_050481))\
+		__TLBI_0(vmalle1is, 0);\
+	else\
+		__TLBI_1(OP, __temp_050481);\
+} while (0)
+
+#define __tlbi_vaae1is(ADDR, ...)	S32GEN1_TLBI_ALT(vaae1is, ADDR)
+#define __tlbi_vaae1is(ADDR, ...)	S32GEN1_TLBI_ALT(vaae1is, ADDR)
+#define __tlbi_vaale1is(ADDR, ...)	S32GEN1_TLBI_ALT(vaale1is, ADDR)
+#define __tlbi_vae1is(ADDR, ...)	S32GEN1_TLBI_ALT(vae1is, ADDR)
+#define __tlbi_vale1is(ADDR, ...)	S32GEN1_TLBI_ALT(vale1is, ADDR)
+#define __tlbi_vmalle1()		__TLBI_0(vmalle1, 0)
+#define __tlbi_vmalle1is()		__TLBI_0(vmalle1is, 0)
+#define __tlbi_aside1is(ASID)		__TLBI_1(aside1is, ASID)
+#define __tlbi_rvale1is(ADDR)		__TLBI_1(rvale1is, ADDR)
+#define __tlbi_rvae1is(ADDR)		__TLBI_1(rvae1is, ADDR)
+
+#define __tlbi(op, ...) __tlbi_##op(__VA_ARGS__)
+
+#else
 #define __tlbi(op, ...)		__TLBI_N(op, ##__VA_ARGS__, 1, 0)
+#endif
 
 #define __tlbi_user(op, arg) do {						\
 	if (arm64_kernel_unmapped_at_el0())					\
@@ -63,17 +93,6 @@
 		__ta;						\
 	})
 
-#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
-/* The most significant 44 VA bits get encoded as VA[55:12] in TLBI instructions
- * on A53 cores. Of these, the most significant (44 - (VA_BITS - 12)) are either
- * all 1 or all 0.
- * Note: The __TLBI_VADDR(addr) macro has already shifted addr by 12 and masked
- * by GENMASK_ULL(43, 0).
- */
-#define S32_IS_KERN_ADDR(addr_shr_12)  \
-	((((long)(addr_shr_12)) >> (VA_BITS - 12)) + 1 == (1 << (56 - VA_BITS)))
-#endif
-
 /*
  * Get translation granule of the system, which is decided by
  * PAGE_SIZE.  Used by TTL.
@@ -273,15 +292,8 @@ static inline void flush_tlb_page_nosync(struct vm_area_struct *vma,
 
 	dsb(ishst);
 	addr = __TLBI_VADDR(uaddr, ASID(vma->vm_mm));
-#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
-	if (S32_IS_KERN_ADDR(addr)) {
-		__tlbi(vmalle1is);
-	} else
-#endif
-	{
-		__tlbi(vale1is, addr);
-		__tlbi_user(vale1is, addr);
-	}
+        __tlbi(vale1is, addr);
+        __tlbi_user(vale1is, addr);
 
 }
 
@@ -349,12 +361,6 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 		if (!system_supports_tlb_range() ||
 		    pages % 2 == 1) {
 			addr = __TLBI_VADDR(start, asid);
-#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
-			if (S32_IS_KERN_ADDR(addr)) {
-				__tlbi(vmalle1is);
-				break;
-			}
-#endif
 			if (last_level) {
 				__tlbi_level(vale1is, addr, tlb_level);
 				__tlbi_user_level(vale1is, addr, tlb_level);
@@ -410,15 +416,8 @@ static inline void flush_tlb_kernel_range(unsigned long start, unsigned long end
 	end = __TLBI_VADDR(end, 0);
 
 	dsb(ishst);
-	for (addr = start; addr < end; addr += 1 << (PAGE_SHIFT - 12)) {
-#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
-		if (S32_IS_KERN_ADDR(addr)) {
-			__tlbi(vmalle1is);
-			break;
-		}
-#endif
+	for (addr = start; addr < end; addr += 1 << (PAGE_SHIFT - 12))
 		__tlbi(vaale1is, addr);
-	}
 	dsb(ish);
 	isb();
 }
@@ -432,14 +431,7 @@ static inline void __flush_tlb_kernel_pgtable(unsigned long kaddr)
 	unsigned long addr = __TLBI_VADDR(kaddr, 0);
 
 	dsb(ishst);
-#if IS_ENABLED(CONFIG_NXP_S32GEN1_ERRATUM_ERR050481)
-	if (S32_IS_KERN_ADDR(addr))
-		__tlbi(vmalle1is);
-	else
-#endif
-	{
-		__tlbi(vaae1is, addr);
-	}
+	__tlbi(vaae1is, addr);
 	dsb(ish);
 	isb();
 }
diff --git a/arch/arm64/kernel/cpu_errata.c b/arch/arm64/kernel/cpu_errata.c
index cafaf0da05b7..91ecf9fef466 100644
--- a/arch/arm64/kernel/cpu_errata.c
+++ b/arch/arm64/kernel/cpu_errata.c
@@ -196,6 +196,29 @@ has_neoverse_n1_erratum_1542419(const struct arm64_cpu_capabilities *entry,
 	return is_midr_in_range(midr, &range) && has_dic;
 }
 
+#ifdef CONFIG_NXP_S32GEN1_ERRATUM_ERR050481
+#define SYS_L2CTRL_NCORES_SHIFT	24
+#define SYS_L2CTRL_NCORES_MASK	(0x3 << SYS_L2CTRL_NCORES_SHIFT)
+#define SYS_L2CTRL_2CORES	0x1
+
+static bool
+has_nxp_s32gen1_erratum_err050481(const struct arm64_cpu_capabilities *entry,
+				  int scope)
+{
+	u32 l2ctrl = read_sysreg_s(SYS_L2CTRL_EL1);
+	u32 ncores;
+
+	ncores = (l2ctrl & SYS_L2CTRL_NCORES_MASK);
+	ncores >>= SYS_L2CTRL_NCORES_SHIFT;
+
+	/**
+	 * Applies to S32GEN1 platforms with 2 cores per cluster.
+	 * This excludes S32G3.
+	 */
+	return (ncores == SYS_L2CTRL_2CORES);
+}
+#endif
+
 #ifdef CONFIG_RANDOMIZE_BASE
 
 static const struct midr_range ca57_a72[] = {
@@ -534,6 +557,14 @@ const struct arm64_cpu_capabilities arm64_errata[] = {
 				  0, 0,
 				  1, 0),
 	},
+#endif
+#ifdef CONFIG_NXP_S32GEN1_ERRATUM_ERR050481
+	{
+		.desc = "NXP erratum ERR050481 (TLBI handled incorrectly)",
+		.capability = ARM64_WORKAROUND_NXP_ERR050481,
+		.type = ARM64_CPUCAP_LOCAL_CPU_ERRATUM,
+		.matches = has_nxp_s32gen1_erratum_err050481,
+	},
 #endif
 	{
 	}
-- 
2.25.1

