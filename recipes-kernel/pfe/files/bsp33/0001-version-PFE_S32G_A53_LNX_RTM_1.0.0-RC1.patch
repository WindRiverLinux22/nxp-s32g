From 750a67d440d9dbc460f0e67fde79715fc59e737a Mon Sep 17 00:00:00 2001
From: Claudiu Manoil <claudiu.manoil@nxp.com>
Date: Wed, 4 May 2022 12:28:45 +0300
Subject: [PATCH 1/3] version PFE_S32G_A53_LNX_RTM_1.0.0 RC1

pfe.git: 35e0f6e720cd20272b375dc6a5ecf8e64b258ce0

Includes driver updates for the updated reserved memory regions
device tree nodes, like the new "fsl,pfe-rt-pool" reserved
memory node for the routing table.

FCI and platfrom driver fixes and new development work up to date.

Upstream-Status: Pending 

Signed-off-by: Claudiu Manoil <claudiu.manoil@nxp.com>
Signed-off-by: Zhantao Tang <zhantao.tang@windriver.com>
---
 sw/build_env.mak                              |   11 +-
 sw/common/public/pfe_cfg.h                    |    8 +-
 sw/elf/public/elf.h                           |    4 +-
 sw/elf/src/elf.c                              |    6 +-
 sw/fci/src/fci.c                              |  224 ++--
 sw/fci/src/fci_connections.c                  |  245 ++--
 sw/fci/src/fci_flexible_filter.c              |   12 +-
 sw/fci/src/fci_fp.c                           |   11 +-
 sw/fci/src/fci_fp_db.c                        |  218 ++--
 sw/fci/src/fci_fw_features.c                  |    4 +-
 sw/fci/src/fci_interfaces.c                   |   85 +-
 sw/fci/src/fci_internal.h                     |    9 +-
 sw/fci/src/fci_l2br.c                         |   16 +-
 sw/fci/src/fci_l2br_domains.c                 |  116 +-
 sw/fci/src/fci_mirror.c                       |   42 +-
 sw/fci/src/fci_qos.c                          |   36 +-
 sw/fci/src/fci_routes.c                       |   59 +-
 sw/fci/src/fci_rt_db.c                        |    2 +
 sw/fci/src/fci_spd.c                          |   14 +-
 sw/libfci_cli/Makefile                        |    4 +-
 sw/linux-pfeng/Makefile                       |    9 +-
 sw/linux-pfeng/pfeng-drv.c                    |   10 +-
 sw/linux-pfeng/pfeng.h                        |    2 +-
 sw/oal/public/oal_mm.h                        |   21 +-
 sw/oal/public/oal_util_net.h                  |    6 +-
 sw/oal/src/oal_mm_linux.c                     |  336 +++--
 sw/oal/src/oal_util_net_linux.c               |    6 +-
 sw/pfe_hif_drv/public/pfe_hif_drv.h           |   14 +-
 sw/pfe_platform/hw/s32g/pfe_class_csr.c       |    2 +-
 sw/pfe_platform/hw/s32g/pfe_emac_csr.c        |   14 +-
 sw/pfe_platform/hw/s32g/pfe_emac_csr.h        |    5 +-
 sw/pfe_platform/hw/s32g/pfe_global_wsp.h      |    6 +-
 sw/pfe_platform/hw/s32g/pfe_gpi_csr.c         |    6 +-
 sw/pfe_platform/hw/s32g/pfe_gpi_csr.h         |    6 +-
 sw/pfe_platform/hw/s32g/pfe_hif_csr.c         |   50 +-
 sw/pfe_platform/hw/s32g/pfe_hif_csr.h         |    4 +-
 sw/pfe_platform/hw/s32g/pfe_platform_master.c |  172 ++-
 sw/pfe_platform/hw/s32g/pfe_platform_slave.c  |    2 +-
 sw/pfe_platform/hw/s32g/pfe_tmu_csr.c         |   35 +-
 sw/pfe_platform/hw/s32g/pfe_tmu_csr.h         |   12 +-
 sw/pfe_platform/public/pfe_gpi.h              |    6 +-
 sw/pfe_platform/public/pfe_hif_ring_linux.h   |    4 +-
 sw/pfe_platform/public/pfe_idex.h             |    5 +-
 sw/pfe_platform/public/pfe_l2br.h             |    1 +
 sw/pfe_platform/public/pfe_platform_rpc.h     |   47 +-
 sw/pfe_platform/public/pfe_rtable.h           |    4 +-
 sw/pfe_platform/src/pfe_class.c               |   44 +-
 sw/pfe_platform/src/pfe_feature_mgr.c         |   24 +-
 sw/pfe_platform/src/pfe_gpi.c                 |   18 +-
 sw/pfe_platform/src/pfe_hif_chnl_linux.c      |   21 +-
 sw/pfe_platform/src/pfe_hif_ring_linux.c      |   64 +-
 sw/pfe_platform/src/pfe_hw_feature.c          |    2 +-
 sw/pfe_platform/src/pfe_idex.c                |  175 ++-
 sw/pfe_platform/src/pfe_l2br.c                |  106 ++
 sw/pfe_platform/src/pfe_log_if.c              |    2 +-
 sw/pfe_platform/src/pfe_log_if_slave.c        |   81 +-
 sw/pfe_platform/src/pfe_pe.c                  |   98 +-
 sw/pfe_platform/src/pfe_phy_if.c              |    2 +-
 sw/pfe_platform/src/pfe_phy_if_slave.c        |  198 +++
 sw/pfe_platform/src/pfe_rtable.c              |   30 +-
 sw/pfe_platform/src/pfe_spd.c                 |    7 +-
 sw/pfe_platform/src/pfe_spd_acc.c             |    2 +
 sw/pfe_platform/src/pfe_tmu.c                 |   29 +-
 sw/pfe_platform/src/pfe_util.c                |   94 +-
 sw/xfci/libfci/Makefile                       |    3 +-
 sw/xfci/libfci/public/fpp_ext.h               | 1083 +++++++++--------
 sw/xfci/libfci/public/libfci.h                |   29 +-
 67 files changed, 2287 insertions(+), 1736 deletions(-)

diff --git a/sw/build_env.mak b/sw/build_env.mak
index 18eb374..803aab5 100644
--- a/sw/build_env.mak
+++ b/sw/build_env.mak
@@ -90,6 +90,8 @@ export PFE_CFG_IEEE1588_I_CLK_HZ?=0
 export PFE_CFG_IEEE1588_EMAC0_O_CLK_HZ?=0
 export PFE_CFG_IEEE1588_EMAC1_O_CLK_HZ?=0
 export PFE_CFG_IEEE1588_EMAC2_O_CLK_HZ?=0
+#enable reserved memory for the Slave driver
+export PFE_CFG_LINUX_RES_MEM_ENABLE?=0
 #PFE system buffers location
 export PFE_CFG_SYS_MEM?="pfe_ddr"
 #Buffer descriptors location
@@ -176,10 +178,6 @@ ifeq ($(PFE_CFG_PFE_MASTER),0)
     $(warning HIF nocpy is not supported in SLAVE mode)
     PFE_CFG_HIF_NOCPY_SUPPORT=0
   endif
-  # Linux supports FCI netlink on Slave
-  ifneq ($(TARGET_OS),LINUX)
-  export PFE_CFG_FCI_ENABLE=0
-  endif
 endif
 
 #Set default verbosity level for sysfs. Valid values are from 1 to 10.
@@ -211,6 +209,11 @@ ifneq ($(PFE_CFG_MULTI_INSTANCE_SUPPORT),0)
     GLOBAL_CCFLAGS+=-DPFE_CFG_MULTI_INSTANCE_SUPPORT
     GLOBAL_CCFLAGS+=-DPFE_CFG_SLAVE_HIF_MASTER_UP_TMOUT=$(PFE_CFG_SLAVE_HIF_MASTER_UP_TMOUT)
     GLOBAL_CCFLAGS+=-DPFE_CFG_IP_READY_MS_TMOUT=$(PFE_CFG_IP_READY_MS_TMOUT)
+    GLOBAL_CCFLAGS+=-DPFE_CFG_ERR051211_WORKAROUND_ENABLE
+endif
+
+ifneq ($(PFE_CFG_LINUX_RES_MEM_ENABLE),0)
+    GLOBAL_CCFLAGS+=-DPFE_CFG_LINUX_RES_MEM_ENABLE
 endif
 
 ifneq ($(PFE_CFG_PFE_MASTER),0)
diff --git a/sw/common/public/pfe_cfg.h b/sw/common/public/pfe_cfg.h
index aacc9c6..d6f6dec 100644
--- a/sw/common/public/pfe_cfg.h
+++ b/sw/common/public/pfe_cfg.h
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2019-2021 NXP
+ *  Copyright 2019-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -15,4 +15,10 @@
 
 /*  Find the configuration parameters defined in makefiles  */
 
+/**
+ * @def	    PFE_CFG_HIF_IRQ_ENABLED
+ * @brief	If TRUE then HIF interrupt will be used.
+ */
+#define PFE_CFG_HIF_IRQ_ENABLED       TRUE
+
 #endif /*PFE_CFG_H*/
diff --git a/sw/elf/public/elf.h b/sw/elf/public/elf.h
index 7033d34..dd029f3 100644
--- a/sw/elf/public/elf.h
+++ b/sw/elf/public/elf.h
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -234,7 +234,7 @@ typedef struct __attribute__((packed))
     uint32_t   u32ProgScanIdx;
     uint32_t   u32FileSize;
     bool_t     bIs64Bit;
-    void       *pvData; /* Raw file */
+    void __attribute__((aligned(4))) *pvData; /* Raw file */
 } ELF_File_t;
 
 /*==================================================================================================
diff --git a/sw/elf/src/elf.c b/sw/elf/src/elf.c
index f3309c6..ef42f95 100644
--- a/sw/elf/src/elf.c
+++ b/sw/elf/src/elf.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -754,7 +754,7 @@ static void ELF32_PrintSections(const ELF_File_t *pElfFile)
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     /* Check prerequisities */
-    if (unlikely ((NULL == pElfFile)
+    if ((NULL == pElfFile)
   #if TRUE == ELF_CFG_SECTION_TABLE_USED
      || (NULL == pElfFile->arSectHead32)
      || (NULL == pElfFile->acSectNames)
@@ -762,7 +762,7 @@ static void ELF32_PrintSections(const ELF_File_t *pElfFile)
   #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
      || (NULL == pElfFile->arProgHead32)
   #endif /* ELF_CFG_PROGRAM_TABLE_USED */
-      ))
+      )
     {
         NXP_LOG_ERROR("NXP_LOG_INFOSections: Failed - elf not opened!\n");
     }
diff --git a/sw/fci/src/fci.c b/sw/fci/src/fci.c
index 0266ff1..594034d 100644
--- a/sw/fci/src/fci.c
+++ b/sw/fci/src/fci.c
@@ -58,14 +58,14 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 	/* Normal FCI processing */
 
 	errno_t ret = EOK; /* Return value */
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	uint16_t fci_ret = FPP_ERR_OK; /* FCI command return value */
 	uint32_t *reply_buf_ptr = NULL;
 	uint32_t *reply_buf_len_ptr = NULL;
 	uint16_t *reply_retval_ptr = NULL;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely((NULL == context) || (NULL == msg) || (NULL == rep_msg)))
+	if (unlikely((NULL == fci_context) || (NULL == msg) || (NULL == rep_msg)))
 	{
 		NXP_LOG_ERROR("NULL argument received\n");
 		return EINVAL;
@@ -110,7 +110,7 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 						buf.len = fci_buf->len;
 						(void)memcpy(&buf.payload, fci_buf->payload, fci_buf->len);
 
-						ret = pfe_class_put_data(context->class, &buf);
+						ret = pfe_class_put_data(fci_context->class, &buf);
 						if (EOK != ret)
 						{
 							NXP_LOG_DEBUG("pfe_class_buf_put() failed: %d\n", ret);
@@ -152,11 +152,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				case FPP_CMD_IP_ROUTE:
 				{
 					/*	Process 'route' commands (add/del/update/query/...) */
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						ret = fci_routes_cmd(msg, &fci_ret, (fpp_rt_cmd_t *)reply_buf_ptr, reply_buf_len_ptr);
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -166,11 +166,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				{
 					/*	Update default timeouts for connections */
 
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						ret = fci_connections_ipv4_timeout_cmd(msg, &fci_ret, (fpp_timeout_cmd_t *)reply_buf_ptr, reply_buf_len_ptr);
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -179,11 +179,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				case FPP_CMD_IPV4_CONNTRACK:
 				{
 					/*	Process 'ipv4 connection' commands (add/del/updated/query/...) */
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						ret = fci_connections_ipv4_ct_cmd(msg, &fci_ret, (fpp_ct_cmd_t *)reply_buf_ptr, reply_buf_len_ptr);
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -192,11 +192,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				case FPP_CMD_IPV6_CONNTRACK:
 				{
 					/*	Process 'ipv6 connection' commands (add/del/updated/query/...) */
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						ret = fci_connections_ipv6_ct_cmd(msg, &fci_ret, (fpp_ct6_cmd_t *)reply_buf_ptr, reply_buf_len_ptr);
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -205,11 +205,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				case FPP_CMD_IPV4_RESET:
 				{
 					/*	Remove all IPv4 routes, including connections */
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						fci_routes_drop_all_ipv4();
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -218,11 +218,11 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
 				case FPP_CMD_IPV6_RESET:
 				{
 					/*	Remove all IPv6 routes, including connections */
-					ret = oal_mutex_lock(&context->db_mutex);
+					ret = oal_mutex_lock(&fci_context->db_mutex);
 					if (EOK == ret)
 					{
 						fci_routes_drop_all_ipv6();
-						(void)oal_mutex_unlock(&context->db_mutex);
+						(void)oal_mutex_unlock(&fci_context->db_mutex);
 					}
 
 					break;
@@ -374,7 +374,7 @@ errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
  */
 errno_t fci_init(fci_init_info_t *info, const char_t *const identifier)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	errno_t err = EOK;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -385,21 +385,21 @@ errno_t fci_init(fci_init_info_t *info, const char_t *const identifier)
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-	if(TRUE == context->fci_initialized)
+	if(TRUE == fci_context->fci_initialized)
 	{
 		NXP_LOG_ERROR("FCI has already been initialized!\n");
 		return EINVAL;
 	}
 
-	(void)memset(context, 0, sizeof(fci_t));
+	(void)memset(fci_context, 0, sizeof(fci_t));
+
+	fci_context->db_mutex_initialized = FALSE;
+	fci_context->log_if_db_initialized = FALSE;
+	fci_context->phy_if_db_initialized = FALSE;
+	fci_context->rt_db_initialized = FALSE;
+	fci_context->rtable_initialized = FALSE;
+	fci_context->tmu_initialized = FALSE;
 
-	context->db_mutex_initialized = FALSE;
-	context->log_if_db_initialized = FALSE;
-	context->phy_if_db_initialized = FALSE;
-	context->rt_db_initialized = FALSE;
-	context->rtable_initialized = FALSE;
-	context->tmu_initialized = FALSE;
-	
 	/*	Sanity check */
 	if (6U != sizeof(pfe_mac_addr_t))
 	{
@@ -416,83 +416,83 @@ errno_t fci_init(fci_init_info_t *info, const char_t *const identifier)
 	}
 
 #ifdef PFE_CFG_PFE_MASTER
-	err = oal_mutex_init(&context->db_mutex);
+	err = oal_mutex_init(&fci_context->db_mutex);
 	if (EOK != err)
 	{
 		goto free_and_fail;
 	}
 	else
 	{
-		context->db_mutex_initialized = TRUE;
+		fci_context->db_mutex_initialized = TRUE;
 	}
 
 	/*	Initialize the Flexible Parser databases */
 	fci_fp_db_init();
 	if (NULL != info)
 	{
-		context->class = info->class;
+		fci_context->class = info->class;
 	}
 
 	/*	Initialize the physical interface database */
 	if (NULL != info)
 	{
-		context->phy_if_db = info->phy_if_db;
+		fci_context->phy_if_db = info->phy_if_db;
 	}
 
-	if(NULL != context->log_if_db)
+	if(NULL != fci_context->log_if_db)
 	{
-		context->phy_if_db_initialized = TRUE;
+		fci_context->phy_if_db_initialized = TRUE;
 	}
 
 	/*	Initialize the logical interface database */
 	if (NULL != info)
 	{
-		context->log_if_db = info->log_if_db;
+		fci_context->log_if_db = info->log_if_db;
 	}
 
-	if(NULL != context->log_if_db)
+	if(NULL != fci_context->log_if_db)
 	{
-		context->log_if_db_initialized = TRUE;
+		fci_context->log_if_db_initialized = TRUE;
 	}
 
 	/*	Initialize the route database */
-	fci_rt_db_init(&context->route_db);
-	context->rt_db_initialized = TRUE;
+	fci_rt_db_init(&fci_context->route_db);
+	fci_context->rt_db_initialized = TRUE;
 
 	/*	Store the routing table and bridge reference */
 	if (NULL != info)
 	{
 		if (NULL != info->rtable)
 		{
-			context->rtable = info->rtable;
-			context->rtable_initialized = TRUE;
+			fci_context->rtable = info->rtable;
+			fci_context->rtable_initialized = TRUE;
 		}
 
 		if (NULL != info->l2_bridge)
 		{
-			context->l2_bridge = info->l2_bridge;
-			context->l2_bridge_initialized = TRUE;
+			fci_context->l2_bridge = info->l2_bridge;
+			fci_context->l2_bridge_initialized = TRUE;
 		}
 	}
 
 	if (NULL != info)
 	{
 		/*	Initialize the TMU  */
-		context->tmu = info->tmu;
+		fci_context->tmu = info->tmu;
 	}
 
-	if(NULL != context->tmu)
+	if(NULL != fci_context->tmu)
 	{
-		context->tmu_initialized = TRUE;
+		fci_context->tmu_initialized = TRUE;
 	}
 #else
 	(void)info;
 #endif /* PFE_CFG_PFE_MASTER */
 
-	context->default_timeouts.timeout_tcp = 5U * 24U * 60U * 60U; 	/* 5 days */
-	context->default_timeouts.timeout_udp = 300U; 					/* 5 min */
-	context->default_timeouts.timeout_other = 240U; 				/* 4 min */
-	context->fci_initialized = TRUE;
+	fci_context->default_timeouts.timeout_tcp = 5U * 24U * 60U * 60U; 	/* 5 days */
+	fci_context->default_timeouts.timeout_udp = 300U; 					/* 5 min */
+	fci_context->default_timeouts.timeout_other = 240U; 				/* 4 min */
+	fci_context->fci_initialized = TRUE;
 	return err;
 
 free_and_fail:
@@ -505,155 +505,67 @@ free_and_fail:
  */
 void fci_fini(void)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 #ifdef PFE_CFG_PFE_MASTER
 	uint32_t session_id = 0U;
 #endif /* PFE_CFG_PFE_MASTER */
 
-	if (FALSE == context->fci_initialized)
+	if (FALSE == fci_context->fci_initialized)
 	{
 		return;
 	}
 
 	/*	Shut down the endpoint */
-	if (NULL != context->core)
+	if (NULL != fci_context->core)
 	{
 		fci_core_fini();
-		context->core = NULL;
+		fci_context->core = NULL;
 	}
 
 #ifdef PFE_CFG_PFE_MASTER
 	(void)pfe_if_db_lock(&session_id);
 	/*	Shutdown the logical IF DB */
-	if (TRUE == context->log_if_db_initialized)
+	if (TRUE == fci_context->log_if_db_initialized)
 	{
 		/* Freeing of the DB is handled by platfrom driver*/
-		context->log_if_db = NULL;
-		context->log_if_db_initialized = FALSE;
+		fci_context->log_if_db = NULL;
+		fci_context->log_if_db_initialized = FALSE;
 	}
 
 	/*  Shutdown the physical IF DB */
-	if (TRUE == context->phy_if_db_initialized)
+	if (TRUE == fci_context->phy_if_db_initialized)
 	{
 		/* Freeing of the DB is handled by platfrom driver*/
-		context->phy_if_db = NULL;
-		context->phy_if_db_initialized = FALSE;
+		fci_context->phy_if_db = NULL;
+		fci_context->phy_if_db_initialized = FALSE;
 	}
 	(void)pfe_if_db_unlock(session_id);
 
 	/*	Shutdown the RT DB */
-	if (TRUE == context->rt_db_initialized)
+	if (TRUE == fci_context->rt_db_initialized)
 	{
-		if (TRUE == context->db_mutex_initialized)
+		if (TRUE == fci_context->db_mutex_initialized)
 		{
-			(void)oal_mutex_lock(&context->db_mutex);
+			(void)oal_mutex_lock(&fci_context->db_mutex);
 			fci_routes_drop_all();
-			(void)oal_mutex_unlock(&context->db_mutex);
+			(void)oal_mutex_unlock(&fci_context->db_mutex);
 		}
 
-		context->rt_db_initialized = FALSE;
+		fci_context->rt_db_initialized = FALSE;
 	}
 
 	/*	Invalidate the routing table */
-	context->rtable = NULL;
-	context->rtable_initialized = FALSE;
+	fci_context->rtable = NULL;
+	fci_context->rtable_initialized = FALSE;
 
-	if (TRUE == context->db_mutex_initialized)
+	if (TRUE == fci_context->db_mutex_initialized)
 	{
-		(void)oal_mutex_destroy(&context->db_mutex);
+		(void)oal_mutex_destroy(&fci_context->db_mutex);
 	}
 #endif /* PFE_CFG_PFE_MASTER */
 
-	(void)memset(context, 0, sizeof(fci_t));
-	context->fci_initialized = FALSE;
-}
-
-/**
- * @brief		Enable interface to receive/transmit data
- * @param[in]	phy_if The interface instance
- * @retval		EOK Success
- * @retval		EINVAL Invalid or missing argument
- */
-errno_t fci_enable_if(pfe_phy_if_t *phy_if)
-{
-
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == phy_if))
-	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		return EINVAL;
-	}
-#endif /* PFE_CFG_NULL_ARG_CHECK */
-
-	return pfe_phy_if_enable(phy_if);
+	(void)memset(fci_context, 0, sizeof(fci_t));
+	fci_context->fci_initialized = FALSE;
 }
 
-#ifdef PFE_CFG_PFE_MASTER
-/**
- * @brief		Disable transmission/reception on interface
- * @param[in]	phy_if The interface instance
- * @retval		EOK Success
- * @retval		EINVAL Invalid or missing argument
- */
-errno_t fci_disable_if(pfe_phy_if_t *phy_if)
-{
-	fci_t *context = (fci_t *)&__context;
-	fci_rt_db_entry_t *route_entry;
-#if defined(PFE_CFG_RTABLE_ENABLE)
-	pfe_rtable_entry_t *rtable_entry;
-#endif /* PFE_CFG_RTABLE_ENABLE */
-	errno_t ret = EOK;
-
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == phy_if))
-	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		return EINVAL;
-	}
-
-	if (unlikely(FALSE == context->fci_initialized))
-	{
-		NXP_LOG_ERROR("Context not initialized\n");
-		return EPERM;
-	}
-#endif /* PFE_CFG_NULL_ARG_CHECK */
-
-	/*	Don't disable the interface if some routing table entry is using it */
-	route_entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_IF, phy_if);
-	while (NULL != route_entry)
-	{
-#if defined(PFE_CFG_RTABLE_ENABLE)
-		rtable_entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_BY_ROUTE_ID, &route_entry->id);
-		if (NULL != rtable_entry)
-		{
-			/*	There is routing table entry using the interface */
-			return EOK;
-		}
-#endif /* PFE_CFG_RTABLE_ENABLE */
-
-		route_entry = fci_rt_db_get_next(&context->route_db);
-	}
-
-#if defined(PFE_CFG_L2BRIDGE_ENABLE)
-	/*	Also don't disable it when interface is in bridge */
-	if (NULL != pfe_l2br_get_first_domain(context->l2_bridge, L2BD_BY_PHY_IF, (void *)phy_if))
-	{
-		/*	Interface is assigned to some L2 bridge domain */
-		return EOK;
-	}
-#endif /* PFE_CFG_L2BRIDGE_ENABLE */
-
-	/*	Interface is not being used by FCI logic, disable it. Note that
-	 	if some logical interface associated with this physical one is
-	 	active, the interface will not be disabled. */
-	ret = pfe_phy_if_disable(phy_if);
-	if (EOK != ret)
-	{
-		NXP_LOG_ERROR("Can't disable interface (%s)\n", pfe_phy_if_get_name(phy_if));
-	}
-
-	return ret;
-}
-#endif /* PFE_CFG_PFE_MASTER */
-
 #endif /* PFE_CFG_FCI_ENABLE */
diff --git a/sw/fci/src/fci_connections.c b/sw/fci/src/fci_connections.c
index 8fe91cd..984af74 100644
--- a/sw/fci/src/fci_connections.c
+++ b/sw/fci/src/fci_connections.c
@@ -37,6 +37,7 @@
 
 #include "oal_util_net.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /*	IP address conversion */
@@ -50,10 +51,10 @@ static void fci_connections_ipv6_cmd_to_5t_rep(const fpp_ct6_cmd_t *ct6_cmd, pfe
 static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t *route,
 								const pfe_5_tuple_t *tuple, const pfe_5_tuple_t *tuple_rep);
 static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
-static errno_t fci_connections_ipv4_cmd_to_rep_entry(fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
+static errno_t fci_connections_ipv4_cmd_to_rep_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
 static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
-static errno_t fci_connections_ipv6_cmd_to_rep_entry(fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
-static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t *fci_ret, void *reply_buf, uint32_t *reply_len);
+static errno_t fci_connections_ipv6_cmd_to_rep_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
+static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, uint16_t *fci_ret, void *reply_buf, uint32_t *reply_len);
 #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
 #ifdef NXP_LOG_ENABLED
 static char_t * fci_connections_ipv4_cmd_to_str(fpp_ct_cmd_t *ct_cmd);
@@ -63,7 +64,6 @@ static char_t * fci_connections_build_str(bool_t ipv6, uint8_t *sip, uint8_t *di
 									uint8_t *sip_out, uint8_t *dip_out, uint16_t *sport_out, uint16_t *dport_out, uint8_t *proto);
 #endif /* NXP_LOG_ENABLED */
 #endif /* PFE_CFG_VERBOSITY_LEVEL */
-static pfe_phy_if_t *fci_connections_rentry_to_if(const pfe_rtable_entry_t *entry);
 
 #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
 #ifdef NXP_LOG_ENABLED
@@ -506,7 +506,7 @@ static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t
  */
 static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *route;
 	pfe_5_tuple_t tuple_buf, tuple_rep_buf;
 	pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
@@ -518,7 +518,7 @@ static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -535,7 +535,7 @@ static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe
 	}
 
 	/*	Get route */
-	route = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id);
+	route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id);
 	if (NULL == route)
 	{
 		NXP_LOG_ERROR("No such route (0x%x)\n", (uint_t)ct_cmd->route_id);
@@ -574,9 +574,9 @@ static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe
  * 				direction is not requested.
  * @return		EOK if success, error code otherwise
  */
-static errno_t fci_connections_ipv4_cmd_to_rep_entry(fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
+static errno_t fci_connections_ipv4_cmd_to_rep_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *route;
 	pfe_5_tuple_t tuple_buf, tuple_rep_buf;
 	pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
@@ -588,7 +588,7 @@ static errno_t fci_connections_ipv4_cmd_to_rep_entry(fpp_ct_cmd_t *ct_cmd, pfe_r
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -605,7 +605,7 @@ static errno_t fci_connections_ipv4_cmd_to_rep_entry(fpp_ct_cmd_t *ct_cmd, pfe_r
 	}
 
 	/*	Get route */
-	route = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id_reply);
+	route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id_reply);
 	if (NULL == route)
 	{
 		NXP_LOG_ERROR("No such route (0x%x)\n", (uint_t)oal_ntohl(ct_cmd->route_id_reply));
@@ -644,7 +644,7 @@ static errno_t fci_connections_ipv4_cmd_to_rep_entry(fpp_ct_cmd_t *ct_cmd, pfe_r
  */
 static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *route;
 	pfe_5_tuple_t tuple_buf, tuple_rep_buf;
 	pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
@@ -656,7 +656,7 @@ static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, p
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -672,7 +672,7 @@ static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, p
 	}
 
 	/*	Get route */
-	route = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id);
+	route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id);
 	if (NULL == route)
 	{
 		NXP_LOG_ERROR("No such route (0x%x)\n", (uint_t)ct6_cmd->route_id);
@@ -711,9 +711,9 @@ static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, p
  * 				reply direction is not requested.
  * @return		EOK if success, error code otherwise
  */
-static errno_t fci_connections_ipv6_cmd_to_rep_entry(fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
+static errno_t fci_connections_ipv6_cmd_to_rep_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *route;
 	pfe_5_tuple_t tuple_buf, tuple_rep_buf;
 	pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
@@ -725,7 +725,7 @@ static errno_t fci_connections_ipv6_cmd_to_rep_entry(fpp_ct6_cmd_t *ct6_cmd, pfe
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -742,7 +742,7 @@ static errno_t fci_connections_ipv6_cmd_to_rep_entry(fpp_ct6_cmd_t *ct6_cmd, pfe
 	}
 
 	/*	Get route */
-	route = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id_reply);
+	route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id_reply);
 	if (NULL == route)
 	{
 		NXP_LOG_ERROR("No such route (0x%x)\n", (uint_t)oal_ntohl(ct6_cmd->route_id_reply));
@@ -772,51 +772,6 @@ static errno_t fci_connections_ipv6_cmd_to_rep_entry(fpp_ct6_cmd_t *ct6_cmd, pfe
 	return EOK;
 }
 
-/**
- * @brief		Get egress interface associated with routing table entry
- * @param[in]	entry Routing table entry
- * @return		The interface instance or NULL if failed
- */
-static pfe_phy_if_t *fci_connections_rentry_to_if(const pfe_rtable_entry_t *entry)
-{
-	fci_t *context = (fci_t *)&__context;
-	uint32_t route_id;
-	errno_t ret;
-	fci_rt_db_entry_t *route;
-
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely((NULL == entry)))
-	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		return NULL;
-	}
-
-    if (unlikely(FALSE == context->fci_initialized))
-	{
-    	NXP_LOG_ERROR("Context not initialized\n");
-		return NULL;
-	}
-#endif /* PFE_CFG_NULL_ARG_CHECK */
-
-	/*	Get route ID */
-	ret = pfe_rtable_entry_get_route_id(entry, &route_id);
-	if (EOK != ret)
-	{
-		NXP_LOG_ERROR("Can't get route id: %d\n", ret);
-		return NULL;
-	}
-
-	/*	Get 'reply' route */
-	route = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (const void *)&route_id);
-	if (NULL == route)
-	{
-		NXP_LOG_ERROR("No such route: %d\n", (int_t)oal_ntohl(route_id));
-		return NULL;
-	}
-
-	return route->iface;
-}
-
 /**
  * @brief			Process FPP_CMD_IPV4_CONNTRACK/FPP_CMD_IPV6_CONNTRACK commands
  * @param[in]		ipv6 If TRUE then message carries FPP_CMD_IPV6_CONNTRACK. Else it contains FPP_CMD_IPV4_CONNTRACK.
@@ -828,9 +783,9 @@ static pfe_phy_if_t *fci_connections_rentry_to_if(const pfe_rtable_entry_t *entr
  * @note			Function is only called within the FCI worker thread context.
  * @note			Must run with route DB protected against concurrent accesses.
  */
-static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t *fci_ret, void *reply_buf, uint32_t *reply_len)
+static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, uint16_t *fci_ret, void *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_ct_cmd_t *ct_cmd, *ct_reply;
 	fpp_ct6_cmd_t *ct6_cmd, *ct6_reply;
 	errno_t ret = EOK;
@@ -840,6 +795,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t
 	pfe_5_tuple_t tuple;
 	pfe_ct_route_actions_t actions;
 	pfe_phy_if_t *phy_if = NULL, *phy_if_reply = NULL;
+	uint16_t vlan;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
@@ -848,7 +804,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -955,7 +911,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t
 				pfe_rtable_entry_set_child(entry, rep_entry);
 				pfe_rtable_entry_set_refptr(entry, msg->client);
 
-				ret = pfe_rtable_add_entry(context->rtable, entry);
+				ret = pfe_rtable_add_entry(fci_context->rtable, entry);
 				if (EEXIST == ret)
 				{
 					NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Entry already added\n");
@@ -973,20 +929,12 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t
 					NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry added\n");
 					*fci_ret = FPP_ERR_OK;
 				}
-
-				/*	Enable 'route' interface */
-				ret = fci_enable_if(phy_if);
-				if (EOK != ret)
-				{
-					NXP_LOG_DEBUG("Could not enable interface (%s): %d\n", pfe_phy_if_get_name(phy_if), ret);
-					goto free_and_fail;
-				}
 			}
 
 			/*	Add entry also for reply direction if requested */
 			if (NULL != rep_entry)
 			{
-				ret = pfe_rtable_add_entry(context->rtable, rep_entry);
+				ret = pfe_rtable_add_entry(fci_context->rtable, rep_entry);
 				if (EEXIST == ret)
 				{
 					NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Reply entry already added\n");
@@ -1002,14 +950,6 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, fci_msg_t *msg, uint16_t
 					NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry added (reply direction)\n");
 					*fci_ret = FPP_ERR_OK;
 				}
-
-				/*	Enable 'reply route' interface */
-				ret = fci_enable_if(phy_if_reply);
-				if (EOK != ret)
-				{
-					NXP_LOG_DEBUG("Could not enable interface (%s): %d\n", pfe_phy_if_get_name(phy_if_reply), ret);
-					goto free_and_fail;
-				}
 			}
 
 			break;
@@ -1019,7 +959,7 @@ free_and_fail:
 
 			if (NULL != entry)
 			{
-				if (EOK != pfe_rtable_del_entry(context->rtable, entry))
+				if (EOK != pfe_rtable_del_entry(fci_context->rtable, entry))
 				{
 					NXP_LOG_ERROR("Can't remove route entry\n");
 				}
@@ -1028,17 +968,9 @@ free_and_fail:
 				entry = NULL;
 			}
 
-			if (NULL != phy_if)
-			{
-				if (EOK != fci_disable_if(phy_if))
-				{
-					NXP_LOG_DEBUG("Could not disable interface (%s)\n", pfe_phy_if_get_name(phy_if));
-				}
-			}
-
 			if (NULL != rep_entry)
 			{
-				if (EOK != pfe_rtable_del_entry(context->rtable, rep_entry))
+				if (EOK != pfe_rtable_del_entry(fci_context->rtable, rep_entry))
 				{
 					NXP_LOG_ERROR("Can't remove route entry\n");
 				}
@@ -1047,14 +979,6 @@ free_and_fail:
 				rep_entry = NULL;
 			}
 
-			if (NULL != phy_if_reply)
-			{
-				if (EOK != fci_disable_if(phy_if_reply))
-				{
-					NXP_LOG_DEBUG("Could not disable interface (%s)\n", pfe_phy_if_get_name(phy_if_reply));
-				}
-			}
-
 			break;
 		}
 
@@ -1081,7 +1005,7 @@ free_and_fail:
 				fci_connections_ipv4_cmd_to_5t(ct_cmd, &tuple);
 			}
 
-			entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);
+			entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);
 
 			/*	Delete the entries from table */
 			if (NULL != entry)
@@ -1089,7 +1013,7 @@ free_and_fail:
 				/*	Get associated entry */
 				rep_entry = pfe_rtable_entry_get_child(entry);
 
-				ret = pfe_rtable_del_entry(context->rtable, entry);
+				ret = pfe_rtable_del_entry(fci_context->rtable, entry);
 				if (EOK != ret)
 				{
 					NXP_LOG_ERROR("Can't remove route entry: %d\n", ret);
@@ -1098,24 +1022,6 @@ free_and_fail:
 				}
 				else
 				{
-					phy_if = fci_connections_rentry_to_if(entry);
-					if (NULL == phy_if)
-					{
-						NXP_LOG_ERROR("Interface is NULL\n");
-						*fci_ret = FPP_ERR_OK;
-						ret = ENOENT;
-						break;
-					}
-
-					/*	Disable interface */
-					ret = fci_disable_if(phy_if);
-					if (EOK != ret)
-					{
-						NXP_LOG_ERROR("Could not disable interface (%s): %d\n", pfe_phy_if_get_name(phy_if), ret);
-						*fci_ret = FPP_ERR_OK;
-						break;
-					}
-
 					/*	Release all entry-related resources */
 					NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry removed\n");
 					pfe_rtable_entry_free(entry);
@@ -1133,25 +1039,7 @@ free_and_fail:
 			/*	Delete also the reply direction */
 			if (NULL != rep_entry)
 			{
-				phy_if_reply = fci_connections_rentry_to_if(rep_entry);
-				if (NULL == phy_if_reply)
-				{
-					NXP_LOG_ERROR("Reply interface is NULL\n");
-					*fci_ret = FPP_ERR_OK;
-					ret = ENOENT;
-					break;
-				}
-
-				/*	Disable 'reply' interface */
-				ret = fci_disable_if(phy_if_reply);
-				if (EOK != ret)
-				{
-					NXP_LOG_ERROR("Could not disable interface (%s): %d\n", pfe_phy_if_get_name(phy_if_reply), ret);
-					*fci_ret = FPP_ERR_OK;
-					break;
-				}
-
-				ret = pfe_rtable_del_entry(context->rtable, rep_entry);
+				ret = pfe_rtable_del_entry(fci_context->rtable, rep_entry);
 				if (EOK != ret)
 				{
 					NXP_LOG_ERROR("Can't remove reply route entry: %d\n", ret);
@@ -1201,7 +1089,7 @@ free_and_fail:
 				fci_connections_ipv4_cmd_to_5t(ct_cmd, &tuple);
 			}
 
-			entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);
+			entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);
 
 			if (NULL != entry)
 			{
@@ -1248,7 +1136,7 @@ free_and_fail:
 		{
 			pfe_rtable_get_criterion_t crit = (TRUE == ipv6) ? RTABLE_CRIT_ALL_IPV6 : RTABLE_CRIT_ALL_IPV4;
 
-			entry = pfe_rtable_get_first(context->rtable, crit, NULL);
+			entry = pfe_rtable_get_first(fci_context->rtable, crit, NULL);
 			if (NULL == entry)
 			{
 				ret = EOK;
@@ -1262,7 +1150,7 @@ free_and_fail:
 		{
 			if (NULL == entry)
 			{
-				entry = pfe_rtable_get_next(context->rtable);
+				entry = pfe_rtable_get_next(fci_context->rtable);
 				if (NULL == entry)
 				{
 					ret = EOK;
@@ -1288,6 +1176,7 @@ free_and_fail:
 			pfe_rtable_entry_get_sip(entry, &sip);
 			pfe_rtable_entry_get_dip(entry, &dip);
 			(void)pfe_rtable_entry_get_route_id(entry, &route_id);
+			vlan = pfe_rtable_entry_get_out_vlan(entry);
 
 			if (TRUE == ipv6)
 			{
@@ -1295,7 +1184,7 @@ free_and_fail:
 				(void)memcpy(ct6_reply->daddr, &dip.v6, 16);
 				ct6_reply->sport = oal_htons(pfe_rtable_entry_get_sport(entry));
 				ct6_reply->dport = oal_htons(pfe_rtable_entry_get_dport(entry));
-				ct6_reply->vlan = oal_htons(pfe_rtable_entry_get_out_vlan(entry));
+				ct6_reply->vlan = oal_htons(vlan);
 				(void)memcpy(ct6_reply->saddr_reply, ct6_reply->daddr, 16);
 				(void)memcpy(ct6_reply->daddr_reply, ct6_reply->saddr, 16);
 				ct6_reply->sport_reply = ct6_reply->dport;
@@ -1310,7 +1199,7 @@ free_and_fail:
 				(void)memcpy(&ct_reply->daddr, &dip.v4, 4);
 				ct_reply->sport = oal_htons(pfe_rtable_entry_get_sport(entry));
 				ct_reply->dport = oal_htons(pfe_rtable_entry_get_dport(entry));
-				ct_reply->vlan = oal_htons(pfe_rtable_entry_get_out_vlan(entry));
+				ct_reply->vlan = oal_htons(vlan);
 				(void)memcpy(&ct_reply->saddr_reply, &ct_reply->daddr, 4);
 				(void)memcpy(&ct_reply->daddr_reply, &ct_reply->saddr, 4);
 				ct_reply->sport_reply = ct_reply->dport;
@@ -1338,13 +1227,14 @@ free_and_fail:
 			else
 			{
 				/*	Associated entry for reply direction does exist */
+				vlan = pfe_rtable_entry_get_out_vlan(rep_entry);
 				if (TRUE == ipv6)
 				{
-					ct6_reply->vlan_reply = oal_htons(pfe_rtable_entry_get_out_vlan(rep_entry));
+					ct6_reply->vlan_reply = oal_htons(vlan);
 				}
 				else
 				{
-					ct_reply->vlan_reply = oal_htons(pfe_rtable_entry_get_out_vlan(rep_entry));
+					ct_reply->vlan_reply = oal_htons(vlan);
 				}
 			}
 
@@ -1448,7 +1338,7 @@ free_and_fail:
  * @note			Must run with route DB protected against concurrent accesses.
  * @note			Input values passed via fpp_ct_cmd_t are in __NETWORK__ endian format.
  */
-errno_t fci_connections_ipv4_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct_cmd_t *reply_buf, uint32_t *reply_len)
+errno_t fci_connections_ipv4_ct_cmd(const fci_msg_t *msg, uint16_t *fci_ret, fpp_ct_cmd_t *reply_buf, uint32_t *reply_len)
 {
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
@@ -1472,7 +1362,7 @@ errno_t fci_connections_ipv4_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct_cm
  * @note			Must run with route DB protected against concurrent accesses.
  * @note			Input values passed via fpp_ct_cmd_t are in __NETWORK__ endian format.
  */
-errno_t fci_connections_ipv6_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32_t *reply_len)
+errno_t fci_connections_ipv6_ct_cmd(const fci_msg_t *msg, uint16_t *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32_t *reply_len)
 {
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
@@ -1500,7 +1390,7 @@ errno_t fci_connections_ipv6_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct6_c
  */
 errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_timeout_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_timeout_cmd_t *timeout_cmd;
 	pfe_rtable_entry_t *entry = NULL;
 	uint8_t proto;
@@ -1513,7 +1403,7 @@ errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -1537,23 +1427,23 @@ errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_
 	timeout_cmd = (fpp_timeout_cmd_t *)(msg->msg_cmd.payload);
 
 	/*	Update FCI-wide defaults applicable for new connections */
-	if (EOK != fci_connections_set_default_timeout((uint8_t)timeout_cmd->protocol, timeout_cmd->timeout_value1))
+	if (EOK != fci_connections_set_default_timeout((uint8_t)timeout_cmd->protocol, oal_ntohl(timeout_cmd->timeout_value1)))
 	{
 		NXP_LOG_WARNING("Can't set default timeout\n");
 	}
 	else
 	{
-		NXP_LOG_DEBUG("Default timeout for protocol %u set to %u seconds\n", (uint_t)timeout_cmd->protocol, (uint_t)timeout_cmd->timeout_value1);
+		NXP_LOG_DEBUG("Default timeout for protocol %u set to %u seconds\n", (uint_t)timeout_cmd->protocol, (uint_t)oal_ntohl(timeout_cmd->timeout_value1));
 	}
 
 	/*	Update existing connections */
-	entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_ALL, NULL);
+	entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_ALL, NULL);
 	while (NULL != entry)
 	{
 		proto = pfe_rtable_entry_get_proto(entry);
 		timeout = fci_connections_get_default_timeout(proto);
 		pfe_rtable_entry_set_timeout(entry, timeout);
-		entry = pfe_rtable_get_next(context->rtable);
+		entry = pfe_rtable_get_next(fci_context->rtable);
 	}
 
 	*fci_ret = FPP_ERR_OK;
@@ -1569,7 +1459,7 @@ errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_
  */
 errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_ct_cmd_t *ct_cmd = NULL;
 	fpp_ct6_cmd_t *ct6_cmd = NULL;
 	fci_msg_t msg;
@@ -1584,7 +1474,7 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -1621,7 +1511,8 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 			ct_cmd->dport = oal_htons(tuple.dport);
 			ct_cmd->protocol = oal_htons(tuple.proto);
 
-			if (EOK != fci_core_client_send(client, &msg, NULL))
+			ret = fci_core_client_send(client, &msg, NULL);
+			if (EOK != ret)
 			{
 				NXP_LOG_ERROR("Could not notify FCI client\n");
 			}
@@ -1651,7 +1542,8 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 			ct6_cmd->dport = oal_htons(tuple.dport);
 			ct6_cmd->protocol = oal_htons(tuple.proto);
 
-			if (EOK != fci_core_client_send(client, &msg, NULL))
+			ret = fci_core_client_send(client, &msg, NULL);
+			if (EOK != ret)
 			{
 				NXP_LOG_ERROR("Could not notify FCI client\n");
 			}
@@ -1663,7 +1555,7 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 	}
 
 	/*	Remove entry from the routing table */
-	ret = pfe_rtable_del_entry(context->rtable, entry);
+	ret = pfe_rtable_del_entry(fci_context->rtable, entry);
 	if (EOK != ret)
 	{
 		NXP_LOG_ERROR("Fatal: Can't remove rtable entry = memory leak\n");
@@ -1684,12 +1576,12 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
  */
 void fci_connections_drop_all(void)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	pfe_rtable_entry_t *entry = NULL;
 	errno_t ret;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return;
@@ -1698,7 +1590,7 @@ void fci_connections_drop_all(void)
 
 	NXP_LOG_DEBUG("Removing all connections\n");
 
-	entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_ALL, NULL);
+	entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_ALL, NULL);
 	while (NULL != entry)
 	{
 		ret = fci_connections_drop_one(entry);
@@ -1707,7 +1599,7 @@ void fci_connections_drop_all(void)
 			NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
 		}
 
-		entry = pfe_rtable_get_next(context->rtable);
+		entry = pfe_rtable_get_next(fci_context->rtable);
 	}
 }
 
@@ -1719,10 +1611,10 @@ void fci_connections_drop_all(void)
  */
 errno_t fci_connections_set_default_timeout(uint8_t ip_proto, uint32_t timeout)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -1733,19 +1625,19 @@ errno_t fci_connections_set_default_timeout(uint8_t ip_proto, uint32_t timeout)
 	{
 		case 6U:
 		{
-			context->default_timeouts.timeout_tcp = timeout;
+			fci_context->default_timeouts.timeout_tcp = timeout;
 			break;
 		}
 
 		case 17U:
 		{
-			context->default_timeouts.timeout_udp = timeout;
+			fci_context->default_timeouts.timeout_udp = timeout;
 			break;
 		}
 
 		default:
 		{
-			context->default_timeouts.timeout_other = timeout;
+			fci_context->default_timeouts.timeout_other = timeout;
 			break;
 		}
 	}
@@ -1760,11 +1652,11 @@ errno_t fci_connections_set_default_timeout(uint8_t ip_proto, uint32_t timeout)
  */
 uint32_t fci_connections_get_default_timeout(uint8_t ip_proto)
 {
-	const fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	uint32_t ret = 0U;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return 0U;
@@ -1775,25 +1667,26 @@ uint32_t fci_connections_get_default_timeout(uint8_t ip_proto)
 	{
 		case 6U:
 		{
-			ret = context->default_timeouts.timeout_tcp;
+			ret = fci_context->default_timeouts.timeout_tcp;
 			break;
 		}
 
 		case 17U:
 		{
-			ret = context->default_timeouts.timeout_udp;
+			ret = fci_context->default_timeouts.timeout_udp;
 			break;
 		}
 
 		default:
 		{
-			ret = context->default_timeouts.timeout_other;
+			ret = fci_context->default_timeouts.timeout_other;
 			break;
 		}
 	}
-	
+
 	return ret;
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
 /** @}*/
diff --git a/sw/fci/src/fci_flexible_filter.c b/sw/fci/src/fci_flexible_filter.c
index ebec896..f76d825 100644
--- a/sw/fci/src/fci_flexible_filter.c
+++ b/sw/fci/src/fci_flexible_filter.c
@@ -17,6 +17,7 @@
 #include "pfe_flexible_filter.h"
 #include "pfe_feature_mgr.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -31,7 +32,7 @@
  */
 errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_filter_cmd_t *reply_buf, uint32_t *reply_len)
 {
-    fci_t *context = (fci_t *)&__context;
+    const fci_t *fci_context = (fci_t *)&__context;
 
     fpp_flexible_filter_cmd_t *fp_cmd;
     errno_t ret = EOK;
@@ -43,7 +44,7 @@ errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -79,7 +80,7 @@ errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_
         {
             uint32_t addr;
             /* Write the finished table into the DMEM */
-            ret = fci_fp_db_push_table_to_hw(context->class, (char_t *)fp_cmd->table_name);
+            ret = fci_fp_db_push_table_to_hw(fci_context->class, (char_t *)fp_cmd->table_name);
             if(EOK == ret)
             {
                 /* Get the DMEM address */
@@ -87,7 +88,7 @@ errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_
                 if(0U != addr)
                 {
                     /* Let the classifier use the address of the table as flexible filter */
-                    ret = pfe_flexible_filter_set(context->class, oal_htonl(addr));
+                    ret = pfe_flexible_filter_set(fci_context->class, oal_htonl(addr));
                 }
                 else
                 {
@@ -108,7 +109,7 @@ errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_
 		case FPP_ACTION_DEREGISTER:
         {
             /* Write zero (NULL) into the classifier to prevent table being used */
-            ret = pfe_flexible_filter_set(context->class, 0U);
+            ret = pfe_flexible_filter_set(fci_context->class, 0U);
             if(EOK == ret)
             {
                 /* Delete the table from DMEM - no longer in use, copy is in database */
@@ -134,3 +135,4 @@ errno_t fci_flexible_filter_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_flexible_
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_fp.c b/sw/fci/src/fci_fp.c
index bb84c7a..3758635 100644
--- a/sw/fci/src/fci_fp.c
+++ b/sw/fci/src/fci_fp.c
@@ -17,6 +17,7 @@
 #include "fci_flexible_filter.h"
 #include "fci_fp.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -89,7 +90,7 @@ static void fci_fp_construct_rule_reply(fpp_fp_rule_props_t *r, char *rule_name,
 errno_t fci_fp_table_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_table_cmd_t *reply_buf, uint32_t *reply_len)
 {
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    const fci_t *context = (fci_t *)&__context;
+    const fci_t *fci_context = (fci_t *)&__context;
 #endif /* PFE_CFG_NULL_ARG_CHECK */
     fpp_fp_table_cmd_t *fp_cmd;
     errno_t ret = EOK;
@@ -101,7 +102,7 @@ errno_t fci_fp_table_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_table_cmd_t *
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -238,7 +239,7 @@ errno_t fci_fp_table_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_table_cmd_t *
 errno_t fci_fp_rule_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_rule_cmd_t *reply_buf, uint32_t *reply_len)
 {
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    const fci_t *context = (fci_t *)&__context;
+    const fci_t *fci_context = (fci_t *)&__context;
 #endif
     fpp_fp_rule_cmd_t *fp_cmd;
     errno_t ret = EOK;
@@ -250,7 +251,7 @@ errno_t fci_fp_rule_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_rule_cmd_t *re
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -389,4 +390,4 @@ errno_t fci_fp_rule_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fp_rule_cmd_t *re
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
-
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_fp_db.c b/sw/fci/src/fci_fp_db.c
index ca80751..0c4c9cd 100644
--- a/sw/fci/src/fci_fp_db.c
+++ b/sw/fci/src/fci_fp_db.c
@@ -13,6 +13,7 @@
 #include "pfe_fp.h"
 #include "fci.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -105,9 +106,9 @@ static fci_fp_table_db_t fci_fp_table_db;
 static bool_t fci_fp_match_rule_by_criterion(fci_fp_rule_criterion_t crit, const fci_fp_rule_criterion_arg_t *arg, const fci_fp_rule_t *rule);
 static fci_fp_rule_t *fci_fp_rule_get_first(fci_fp_rule_db_t *db, fci_fp_rule_criterion_t crit, void *arg, dbase_t dbase);
 static fci_fp_rule_t *fci_fp_rule_get_next(fci_fp_rule_db_t *db, dbase_t dbase);
-static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, fci_fp_table_criterion_arg_t *arg, fci_fp_table_t *table);
+static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, const fci_fp_table_criterion_arg_t *arg, const fci_fp_table_t *fp_table);
 static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_table_criterion_t crit, void *arg);
-static uint32_t fci_fp_print_table(fci_fp_table_t *table, char_t *buf, uint32_t buf_len, uint8_t verb_level);
+static uint32_t fci_fp_print_table(const fci_fp_table_t *fp_table, char_t *buf, uint32_t buf_len, uint8_t verb_level);
 
 #if 0
 static fci_fp_table_t *fci_fp_table_get_next(fci_fp_table_db_t *db);
@@ -326,15 +327,15 @@ static fci_fp_rule_t *fci_fp_rule_get_next(fci_fp_rule_db_t *db, dbase_t dbase)
  * @brief        Match table using given criterion
  * @param[in]    crit Selects criterion
  * @param[in]    arg Criterion argument
- * @param[in]    table The table to be matched
+ * @param[in]    fp_table The table to be matched
  * @retval       TRUE Table matches the criterion
  * @retval       FALSE Table does not match the criterion
  */
-static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, fci_fp_table_criterion_arg_t *arg, fci_fp_table_t *table)
+static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, const fci_fp_table_criterion_arg_t *arg, const fci_fp_table_t *fp_table)
 {
     bool_t match;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely((NULL == table) || (NULL == arg)))
+    if (unlikely((NULL == fp_table) || (NULL == arg)))
     {
         NXP_LOG_ERROR("NULL argument received\n");
         return FALSE;
@@ -349,7 +350,7 @@ static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, fci
         }
         case FP_TABLE_CRIT_NAME:
         {
-            if(0 == strcmp(arg->name, table->name))
+            if(0 == strcmp(arg->name, fp_table->name))
             {
                 match = TRUE;
             }
@@ -361,7 +362,7 @@ static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, fci
         }
         case FP_TABLE_CRIT_ADDRESS:
         {
-            if(arg->address == table->dmem_addr)
+            if(arg->address == fp_table->dmem_addr)
             {
                 match = TRUE;
             }
@@ -390,7 +391,7 @@ static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, fci
 static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_table_criterion_t crit, void *arg)
 {
     LLIST_t *item;
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     bool_t match = FALSE;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if (unlikely(NULL == db))
@@ -455,13 +456,13 @@ static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_tabl
         LLIST_ForEach(item, &db->tables)
         {
             /*    Get data */
-            table = LLIST_Data(item, fci_fp_table_t, db_entry);
+            fp_table = LLIST_Data(item, fci_fp_table_t, db_entry);
 
             /*    Remember current item to know where to start later */
             db->cur_item = item->prNext;
-            if (NULL != table)
+            if (NULL != fp_table)
             {
-                if (TRUE == fci_fp_match_table_by_criterion(db->cur_crit, &db->cur_crit_arg, table))
+                if (TRUE == fci_fp_match_table_by_criterion(db->cur_crit, &db->cur_crit_arg, fp_table))
                 {
                     match = TRUE;
                     break;
@@ -472,7 +473,7 @@ static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_tabl
 
     if (TRUE == match)
     {
-        return table;
+        return fp_table;
     }
     else
     {
@@ -537,18 +538,18 @@ static fci_fp_table_t *fci_fp_table_get_next(fci_fp_table_db_t *db)
 #endif
 /**
 * @brief Returns the position of the rule within a table
-* @param[in] table Table to determine postion of the rule within
+* @param[in] fp_table Table to determine postion of the rule within
 * @param[in] rule Rule which position within the table shall be determined
 * @param[out] pos Determined rule position
 * @return EOK on success, ENOENT if rule is not part of the table.
 */
-static errno_t fci_fp_get_rule_pos_in_table(fci_fp_table_t *table, fci_fp_rule_t *rule, uint8_t *pos)
+static errno_t fci_fp_get_rule_pos_in_table(const fci_fp_table_t *fp_table, fci_fp_rule_t *rule, uint8_t *pos)
 {
     uint8_t i = 0U;
     fci_fp_rule_t *rule_item;
     LLIST_t *item;
 
-    LLIST_ForEach(item, &table->rules_db.rules)
+    LLIST_ForEach(item, &fp_table->rules_db.rules)
     {
         rule_item = LLIST_Data(item, fci_fp_rule_t, table_entry);
         if(rule_item == rule)
@@ -588,6 +589,7 @@ errno_t fci_fp_db_create_rule(char_t *name, uint32_t data, uint32_t mask, uint16
 
     uint32_t mem_size;
     fci_fp_rule_t *rule = NULL;
+    bool_t ignore_next_rule = FALSE;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if(NULL == name)
@@ -609,7 +611,7 @@ errno_t fci_fp_db_create_rule(char_t *name, uint32_t data, uint32_t mask, uint16
     if((0U != ((uint8_t)flags & ((uint8_t)FP_FL_ACCEPT | (uint8_t)FP_FL_REJECT))) && (NULL != next_rule))
     {   /* Ignored argument */
         NXP_LOG_WARNING("Next rule is ignored with these flags: 0x%x\n", flags);
-        next_rule = NULL; /* Avoid memory allocation and value storage to avoid future problems */
+        ignore_next_rule = TRUE;
     }
     /* Check that the name is unique in our database */
     if(NULL != fci_fp_rule_get_first(&fci_fp_rule_db, FP_RULE_CRIT_NAME, name, COMMON))
@@ -620,7 +622,7 @@ errno_t fci_fp_db_create_rule(char_t *name, uint32_t data, uint32_t mask, uint16
 
     /* Calculate needed memory size */
     mem_size = sizeof(fci_fp_rule_t) + strlen(name) + 1U; /* Structure + name string */
-    if(NULL != next_rule)
+    if((NULL != next_rule) && (FALSE == ignore_next_rule))
     {
         mem_size += strlen(next_rule) + 1U; /* Add next rule name string space */
     }
@@ -643,14 +645,14 @@ errno_t fci_fp_db_create_rule(char_t *name, uint32_t data, uint32_t mask, uint16
         rule->data = data;
         rule->mask = mask;
         rule->offset = offset;
-        if(NULL != next_rule)
+        if((NULL != next_rule) && (FALSE == ignore_next_rule))
         {   /* Just store the next rule name, no validation yet because rule may be added later */
             rule->next_rule = rule->name + strlen(name) + 1U;
             (void)strcpy(rule->next_rule, next_rule);
         }
         else
         {
-        rule->next_rule = NULL;
+            rule->next_rule = NULL;
         }
         rule->flags = flags;
         /* Add the rule into the global database */
@@ -703,7 +705,7 @@ errno_t fci_fp_db_destroy_rule(char_t *name)
 errno_t fci_fp_db_create_table(char_t *name)
 {
     uint32_t mem_size;
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if(NULL == name)
     {
@@ -720,8 +722,8 @@ errno_t fci_fp_db_create_table(char_t *name)
 
     /* Allocate memory for the table */
     mem_size = sizeof(fci_fp_table_t) + strlen(name) + 1U;
-    table = oal_mm_malloc(mem_size);
-    if(NULL == table)
+    fp_table = oal_mm_malloc(mem_size);
+    if(NULL == fp_table)
     {
         NXP_LOG_ERROR("No memory for the table\n");
         return ENOMEM;
@@ -729,14 +731,14 @@ errno_t fci_fp_db_create_table(char_t *name)
     else
     {
         /* Initialize */
-        (void)memset(table, 0, mem_size);
-        LLIST_Init(&table->db_entry);
-        LLIST_Init(&table->rules_db.rules);
+        (void)memset(fp_table, 0, mem_size);
+        LLIST_Init(&fp_table->db_entry);
+        LLIST_Init(&fp_table->rules_db.rules);
         /* Store the input parameters */
-        table->name = (char_t *)&table[1];
-        (void)strcpy(table->name, name);
+        fp_table->name = (char_t *)&fp_table[1];
+        (void)strcpy(fp_table->name, name);
         /* Add the table into the global database */
-        LLIST_AddAtEnd(&table->db_entry, &fci_fp_table_db.tables);
+        LLIST_AddAtEnd(&fp_table->db_entry, &fci_fp_table_db.tables);
     }
     return EOK;
 
@@ -750,7 +752,7 @@ errno_t fci_fp_db_create_table(char_t *name)
 */
 errno_t fci_fp_db_destroy_table(char_t *name, bool_t force)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     fci_fp_rule_t *rule;
     LLIST_t *item, *aux;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -761,14 +763,14 @@ errno_t fci_fp_db_destroy_table(char_t *name, bool_t force)
     }
 #endif
     /* Find the table */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, name);
+    if(NULL == fp_table)
     {
         NXP_LOG_ERROR("Table with name \"%s\" does not exist\n", name);
         return ENOENT;
     }
     /* Check that the table is not in use */
-    if(0U != table->dmem_addr)
+    if(0U != fp_table->dmem_addr)
     {   /* Table is still in use */
         if(FALSE == force)
         {   /* No override */
@@ -778,25 +780,25 @@ errno_t fci_fp_db_destroy_table(char_t *name, bool_t force)
         else
         {   /* Override (and ride to hell) */
             NXP_LOG_WARNING("Table \"%s\" is in use\n", name);
-            table->dmem_addr = 0U;
+            fp_table->dmem_addr = 0U;
         }
     }
 
     /* Unlink all rules in the table if there are any */
-    if(FALSE == LLIST_IsEmpty(&table->rules_db.rules))
+    if(FALSE == LLIST_IsEmpty(&fp_table->rules_db.rules))
     {
-        LLIST_ForEachRemovable(item, aux, &table->rules_db.rules)
+        LLIST_ForEachRemovable(item, aux, &fp_table->rules_db.rules)
         {
             rule = LLIST_Data(item, fci_fp_rule_t, table_entry);
             LLIST_Remove(item);
-            table->rule_count -= 1U;
+            fp_table->rule_count -= 1U;
             rule->table = NULL;
         }
     }
     /* Remove table from the database */
-    LLIST_Remove(&table->db_entry);
+    LLIST_Remove(&fp_table->db_entry);
     /* Free the memory */
-    oal_mm_free(table);
+    oal_mm_free(fp_table);
     return EOK;
 }
 
@@ -812,7 +814,7 @@ errno_t fci_fp_db_destroy_table(char_t *name, bool_t force)
 */
 errno_t fci_fp_db_add_rule_to_table(char_t *table_name, char_t *rule_name, uint16_t position)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     fci_fp_rule_t *rule;
     LLIST_t *item;
     uint32_t i = 0U; /* Start search from position 0 */
@@ -838,48 +840,48 @@ errno_t fci_fp_db_add_rule_to_table(char_t *table_name, char_t *rule_name, uint1
         return EACCES;
     }
     /* Check that the table does exist */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_ERROR("Table \"%s\" does not exist\n", table_name);
         return ENOENT;
     }
 
     /* Add rule into the table */
-    if(LLIST_IsEmpty(&table->rules_db.rules))
+    if(LLIST_IsEmpty(&fp_table->rules_db.rules))
     {   /* Empty list - ignore position */
         if((position != FCI_FP_RULE_POSITION_FIRST) && (position != FCI_FP_RULE_POSITION_LAST))
         {
             NXP_LOG_WARNING("Adding into an empty table position %u ignored\n", position);
         }
-        LLIST_AddAtBegin(&rule->table_entry, &table->rules_db.rules);
-        rule->table = table;
-        table->rule_count = 1U; /* 1st rule in table */
+        LLIST_AddAtBegin(&rule->table_entry, &fp_table->rules_db.rules);
+        rule->table = fp_table;
+        fp_table->rule_count = 1U; /* 1st rule in table */
     }
     else
     {   /* Table not empty - need to handle position request */
         if(position == FCI_FP_RULE_POSITION_FIRST)
         {   /* Insert as the first one */
-            LLIST_AddAtBegin(&rule->table_entry, &table->rules_db.rules);
-            rule->table = table;
-            table->rule_count += 1U;
+            LLIST_AddAtBegin(&rule->table_entry, &fp_table->rules_db.rules);
+            rule->table = fp_table;
+            fp_table->rule_count += 1U;
         }
         else if(position >= FCI_FP_RULE_POSITION_LAST)
         {   /* Add as the last one */
-            LLIST_AddAtEnd(&rule->table_entry, &table->rules_db.rules);
-            rule->table = table;
-            table->rule_count += 1U;
+            LLIST_AddAtEnd(&rule->table_entry, &fp_table->rules_db.rules);
+            rule->table = fp_table;
+            fp_table->rule_count += 1U;
         }
         else if(position > FCI_FP_RULE_POSITION_FIRST)
         {   /* Insert at specified position */
             bool_t added = FALSE;
-            LLIST_ForEach(item, &table->rules_db.rules)
+            LLIST_ForEach(item, &fp_table->rules_db.rules)
             {
                 if(position == i)
                 {   /* This is the right position - put rule before the item */
                     LLIST_Insert(&rule->table_entry, item);
-                    rule->table = table;
-                    table->rule_count += 1U;
+                    rule->table = fp_table;
+                    fp_table->rule_count += 1U;
                     added = TRUE;
                     break;
                 }
@@ -888,9 +890,9 @@ errno_t fci_fp_db_add_rule_to_table(char_t *table_name, char_t *rule_name, uint1
             if(FALSE == added)
             {   /* The requested position has not been found - add at the end */
                 NXP_LOG_WARNING("Position %u does not exist, adding at %u\n", (uint_t)position, (uint_t)i);
-                LLIST_AddAtEnd(&rule->table_entry, &table->rules_db.rules);
-                rule->table = table;
-                table->rule_count += 1U;
+                LLIST_AddAtEnd(&rule->table_entry, &fp_table->rules_db.rules);
+                rule->table = fp_table;
+                fp_table->rule_count += 1U;
             }
         }
         else
@@ -947,7 +949,7 @@ errno_t fci_fp_db_remove_rule_from_table(char_t *rule_name)
 */
 uint32_t fci_fp_db_get_table_dmem_addr(char_t *table_name)
 {
-    fci_fp_table_t *table;
+    const fci_fp_table_t *fp_table;
     uint32_t retval;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -958,15 +960,15 @@ uint32_t fci_fp_db_get_table_dmem_addr(char_t *table_name)
     }
 #endif
 
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
         retval = 0U;
     }
     else
     {
-        retval = table->dmem_addr;
+        retval = fp_table->dmem_addr;
     }
     return retval;
 }
@@ -982,7 +984,7 @@ uint32_t fci_fp_db_get_table_dmem_addr(char_t *table_name)
 */
 errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     fci_fp_rule_t *next_rule;
     pfe_ct_fp_rule_t rule_buf;
     LLIST_t *item;
@@ -999,23 +1001,23 @@ errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
     }
 #endif
     /* Get the table */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
         return ENOENT;
     }
 
-    table->dmem_addr = pfe_fp_create_table(class, table->rule_count);
-    table->class = class;
-    if(0U == table->dmem_addr)
+    fp_table->dmem_addr = pfe_fp_create_table(class, fp_table->rule_count);
+    fp_table->class = class;
+    if(0U == fp_table->dmem_addr)
     {
         NXP_LOG_ERROR("Cannot write the table");
         return EFAULT;
     }
 
     /* Write rules into the table */
-    LLIST_ForEach(item, &table->rules_db.rules)
+    LLIST_ForEach(item, &fp_table->rules_db.rules)
     {
         rule = LLIST_Data(item, fci_fp_rule_t, table_entry);
         rule_buf.data = rule->data;
@@ -1025,19 +1027,19 @@ errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
         if(NULL != rule->next_rule)
         {   /* Next rule is specified */
             /* Convert next_rule name to position in the table */
-            next_rule = fci_fp_rule_get_first(&table->rules_db, FP_RULE_CRIT_NAME, rule->next_rule, TABLE);
+            next_rule = fci_fp_rule_get_first(&fp_table->rules_db, FP_RULE_CRIT_NAME, rule->next_rule, TABLE);
             if(NULL == next_rule)
             {   /* Failed - cannot proceed */
                 NXP_LOG_ERROR("Referenced rule \"%s\" is not part of the table \"%s\"\n", rule->next_rule, table_name);
-                pfe_fp_destroy_table(class, table->dmem_addr);
-                table->dmem_addr = 0U;
+                pfe_fp_destroy_table(class, fp_table->dmem_addr);
+                fp_table->dmem_addr = 0U;
                 return ENOENT;
             }
-            if(EOK != fci_fp_get_rule_pos_in_table(table, next_rule, &pos))
+            if(EOK != fci_fp_get_rule_pos_in_table(fp_table, next_rule, &pos))
             {   /* Failed - cannot proceed */
                 NXP_LOG_ERROR("Referenced rule \"%s\" is not part of the table \"%s\"\n", rule->next_rule, table_name);
-                pfe_fp_destroy_table(class, table->dmem_addr);
-                table->dmem_addr = 0U;
+                pfe_fp_destroy_table(class, fp_table->dmem_addr);
+                fp_table->dmem_addr = 0U;
                 return ENOENT;
             }
             rule_buf.next_idx = pos;
@@ -1046,7 +1048,7 @@ errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
         {   /* Next rule is not used */
             rule_buf.next_idx = 0xFFU; /* If used it will cause FW internal check to detect it */
         }
-        (void)pfe_fp_table_write_rule(class, table->dmem_addr, &rule_buf, i);
+        (void)pfe_fp_table_write_rule(class, fp_table->dmem_addr, &rule_buf, i);
 
         i++;
     }
@@ -1064,7 +1066,7 @@ errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
 */
 errno_t fci_fp_db_pop_table_from_hw(char_t *table_name)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if(NULL == table_name)
     {
@@ -1073,18 +1075,18 @@ errno_t fci_fp_db_pop_table_from_hw(char_t *table_name)
     }
 #endif
     /* Get the table */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
         return ENOENT;
     }
 
     /* Free the DMEM */
-    pfe_fp_destroy_table(table->class, table->dmem_addr);
+    pfe_fp_destroy_table(fp_table->class, fp_table->dmem_addr);
     /* Clear the references to DMEM */
-    table->dmem_addr = 0U;
-    table->class = NULL;
+    fp_table->dmem_addr = 0U;
+    fp_table->class = NULL;
     return EOK;
 }
 
@@ -1096,7 +1098,7 @@ errno_t fci_fp_db_pop_table_from_hw(char_t *table_name)
 */
 errno_t fci_fp_db_get_table_from_addr(uint32_t addr, char_t **table_name)
 {
-    fci_fp_table_t *table;
+    const fci_fp_table_t *fp_table;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if(NULL == table_name)
     {
@@ -1109,13 +1111,13 @@ errno_t fci_fp_db_get_table_from_addr(uint32_t addr, char_t **table_name)
         return EINVAL;
     }
 
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_ADDRESS, &addr);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_ADDRESS, &addr);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table with address 0x%x not found\n", (uint_t)addr);
         return ENOENT;
     }
-    *table_name = table->name;
+    *table_name = fp_table->name;
     return EOK;
 }
 
@@ -1222,7 +1224,7 @@ errno_t fci_fp_db_get_next_rule(char_t **rule_name, uint32_t *data, uint32_t *ma
 */
 errno_t fci_fp_db_get_table_first_rule(char_t *table_name, char_t **rule_name, uint32_t *data, uint32_t *mask, uint16_t *offset, pfe_ct_fp_flags_t *flags, char_t **next_rule)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     fci_fp_rule_t *rule;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if((NULL == table_name) || (NULL == rule_name) || (NULL == data) || (NULL == mask) || (NULL == offset) || (NULL == flags) || (NULL == next_rule))
@@ -1232,14 +1234,14 @@ errno_t fci_fp_db_get_table_first_rule(char_t *table_name, char_t **rule_name, u
     }
 #endif
     /* Get the table */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
         return ENOENT;
     }
     /* Get the first rule */
-    rule = fci_fp_rule_get_first(&table->rules_db, FP_RULE_CRIT_ALL, NULL, TABLE);
+    rule = fci_fp_rule_get_first(&fp_table->rules_db, FP_RULE_CRIT_ALL, NULL, TABLE);
     if(NULL == rule)
     {
         return ENOENT;
@@ -1270,7 +1272,7 @@ errno_t fci_fp_db_get_table_first_rule(char_t *table_name, char_t **rule_name, u
 */
 errno_t fci_fp_db_get_table_next_rule(char_t *table_name, char_t **rule_name, uint32_t *data, uint32_t *mask, uint16_t *offset, pfe_ct_fp_flags_t *flags, char_t **next_rule)
 {
-    fci_fp_table_t *table;
+    fci_fp_table_t *fp_table;
     fci_fp_rule_t *rule;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
     if((NULL == table_name) || (NULL == rule_name) || (NULL == data) || (NULL == mask) || (NULL == offset) || (NULL == flags) || (NULL == next_rule))
@@ -1280,14 +1282,14 @@ errno_t fci_fp_db_get_table_next_rule(char_t *table_name, char_t **rule_name, ui
     }
 #endif
     /* Get the table */
-    table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
-    if(NULL == table)
+    fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
+    if(NULL == fp_table)
     {
         NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
         return ENOENT;
     }
     /* Get the rule */
-    rule = fci_fp_rule_get_next(&table->rules_db, TABLE);
+    rule = fci_fp_rule_get_next(&fp_table->rules_db, TABLE);
     if(NULL == rule)
     {
         return ENOENT;
@@ -1361,14 +1363,14 @@ static uint32_t fci_fp_print_rule(fci_fp_rule_t *rule, char_t *buf, uint32_t buf
 * @param[in] verb_level Verbosity level
 * @return Number of characters written into the buffer
 */
-static uint32_t fci_fp_print_table(fci_fp_table_t *table, char_t *buf, uint32_t buf_len, uint8_t verb_level)
+static uint32_t fci_fp_print_table(const fci_fp_table_t *fp_table, char_t *buf, uint32_t buf_len, uint8_t verb_level)
 {
     uint32_t len = 0U;
     LLIST_t *item;
     fci_fp_rule_t *rule;
 
-    len += oal_util_snprintf(buf + len, buf_len - len, "%s = {\n", table->name);
-    LLIST_ForEach(item, &table->rules_db.rules)
+    len += oal_util_snprintf(buf + len, buf_len - len, "%s = {\n", fp_table->name);
+    LLIST_ForEach(item, &fp_table->rules_db.rules)
     {
         rule = LLIST_Data(item, fci_fp_rule_t, table_entry);
         len += fci_fp_print_rule(rule, buf + len, buf_len - len, verb_level);
@@ -1388,21 +1390,21 @@ static uint32_t fci_fp_print_table(fci_fp_table_t *table, char_t *buf, uint32_t
 */
 uint32_t fci_fp_print_tables(char_t *buf, uint32_t buf_len, uint8_t verb_level)
 {
-    fci_fp_table_t *table;
+    const fci_fp_table_t *fp_table;
     LLIST_t *item;
     uint32_t len = 0U;
 
     LLIST_ForEach(item, &fci_fp_table_db.tables)
     {
-        table = LLIST_Data(item,  fci_fp_table_t, db_entry);
-        len += fci_fp_print_table(table, buf + len, buf_len - len, verb_level);
+        fp_table = LLIST_Data(item,  fci_fp_table_t, db_entry);
+        len += fci_fp_print_table(fp_table, buf + len, buf_len - len, verb_level);
     }
     return len;
 }
 
 uint32_t pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32_t buf_len, uint8_t verb_level)
 {
-    const fci_fp_table_t *table;
+    const fci_fp_table_t *fp_table;
     pfe_ct_class_flexi_parser_stats_t *c_stats;
     LLIST_t *item;
     uint32_t len = 0U;
@@ -1411,11 +1413,11 @@ uint32_t pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32_t buf_le
 
     LLIST_ForEach(item, &fci_fp_table_db.tables)
     {
-        table = LLIST_Data(item,  fci_fp_table_t, db_entry);
-        len += oal_util_snprintf(buf + len, buf_len - len, "%s = {\n", table->name);
-        if (table->dmem_addr != 0U)
+        fp_table = LLIST_Data(item,  fci_fp_table_t, db_entry);
+        len += oal_util_snprintf(buf + len, buf_len - len, "%s = {\n", fp_table->name);
+        if (fp_table->dmem_addr != 0U)
         {
-            c_stats = oal_mm_malloc(sizeof(pfe_ct_class_flexi_parser_stats_t) * (pfe_class_get_num_of_pes(table->class) + 1U));
+            c_stats = oal_mm_malloc(sizeof(pfe_ct_class_flexi_parser_stats_t) * (pfe_class_get_num_of_pes(fp_table->class) + 1U));
             if(NULL == c_stats)
             {
                 NXP_LOG_ERROR("Memory allocation failed\n");
@@ -1423,11 +1425,11 @@ uint32_t pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32_t buf_le
                 return len;
             }
 
-            (void)memset(c_stats, 0, sizeof(pfe_ct_class_flexi_parser_stats_t) * (pfe_class_get_num_of_pes(table->class) + 1U));
+            (void)memset(c_stats, 0, sizeof(pfe_ct_class_flexi_parser_stats_t) * (pfe_class_get_num_of_pes(fp_table->class) + 1U));
 
-            for(pe_idx = 0U; pe_idx < pfe_class_get_num_of_pes(table->class); pe_idx++)
+            for(pe_idx = 0U; pe_idx < pfe_class_get_num_of_pes(fp_table->class); pe_idx++)
             {
-                (void)pfe_fp_table_get_statistics(table->class, pe_idx, table->dmem_addr, &c_stats[pe_idx +1U]);
+                (void)pfe_fp_table_get_statistics(fp_table->class, pe_idx, fp_table->dmem_addr, &c_stats[pe_idx +1U]);
                 pfe_class_flexi_parser_stats_endian(&c_stats[pe_idx + 1U]);
                 pfe_class_sum_flexi_parser_stats(&c_stats[0], &c_stats[pe_idx + 1U]);
             }
@@ -1448,4 +1450,4 @@ uint32_t pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32_t buf_le
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
-
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_fw_features.c b/sw/fci/src/fci_fw_features.c
index f712d1e..b41f95f 100644
--- a/sw/fci/src/fci_fw_features.c
+++ b/sw/fci/src/fci_fw_features.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2020-2021 NXP
+ *  Copyright 2020-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -19,6 +19,7 @@
 #include "pfe_feature_mgr.h"
 #include "fci_fw_features.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -183,3 +184,4 @@ errno_t fci_fw_features_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_fw_features_c
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_interfaces.c b/sw/fci/src/fci_interfaces.c
index c3f7850..2bffcae 100644
--- a/sw/fci/src/fci_interfaces.c
+++ b/sw/fci/src/fci_interfaces.c
@@ -28,6 +28,7 @@
 #include "pfe_mirror.h"
 #include "pfe_feature_mgr.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 
@@ -44,6 +45,7 @@ static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_r
 static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_rules_t rule, void **offset, size_t *size, uint32_t *fp_table_addr)
 {
 	errno_t retval = EOK; /* Function return value */
+	uint32_t table_addr;
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == m_arg) || (NULL == offset) || (NULL == size)))
 	{
@@ -120,7 +122,8 @@ static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_r
 		case IF_MATCH_FP0:
 		{
 			/* Get the table address in the HW */
-			*fp_table_addr = oal_htonl(fci_fp_db_get_table_dmem_addr(m_arg->fp_table0));
+			table_addr = fci_fp_db_get_table_dmem_addr(m_arg->fp_table0);
+			*fp_table_addr = oal_htonl(table_addr);
 			if(0U == *fp_table_addr)
 			{
 				retval = ENOENT;
@@ -133,7 +136,8 @@ static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_r
 		case IF_MATCH_FP1:
 		{
 			/* Get the table address in the HW */
-			*fp_table_addr = oal_htonl(fci_fp_db_get_table_dmem_addr(m_arg->fp_table1));
+			table_addr = fci_fp_db_get_table_dmem_addr(m_arg->fp_table1);
+			*fp_table_addr = oal_htonl(table_addr);
 			if(0U == *fp_table_addr)
 			{
 				retval = ENOENT;
@@ -221,7 +225,7 @@ static errno_t fci_interfaces_destroy_fptables(const fpp_if_m_rules_t match, con
  */
 errno_t fci_interfaces_session_cmd(uint32_t code, uint16_t *fci_ret)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	errno_t ret = EOK;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -237,7 +241,7 @@ errno_t fci_interfaces_session_cmd(uint32_t code, uint16_t *fci_ret)
 		case FPP_CMD_IF_LOCK_SESSION:
 		{
 			*fci_ret = FPP_ERR_OK;
-			if (EOK != pfe_if_db_lock(&context->if_session_id))
+			if (EOK != pfe_if_db_lock(&fci_context->if_session_id))
 			{
 				*fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
 				NXP_LOG_DEBUG("DB lock failed\n");
@@ -247,7 +251,7 @@ errno_t fci_interfaces_session_cmd(uint32_t code, uint16_t *fci_ret)
 		case FPP_CMD_IF_UNLOCK_SESSION:
 		{
 			*fci_ret = FPP_ERR_OK;
-			if (EOK != pfe_if_db_unlock(context->if_session_id))
+			if (EOK != pfe_if_db_unlock(fci_context->if_session_id))
 			{
 				*fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
 				NXP_LOG_DEBUG("DB unlock failed due to incorrect session ID\n");
@@ -276,7 +280,7 @@ errno_t fci_interfaces_session_cmd(uint32_t code, uint16_t *fci_ret)
  */
 errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_log_if_cmd_t *if_cmd;
 	errno_t ret = EOK;
 	pfe_ct_if_m_args_t args;
@@ -299,7 +303,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 		return EINVAL;
 	}
 
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -327,7 +331,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 		case FPP_ACTION_REGISTER:
 		{
 			/* Get the intended parent physical interface */
-			ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->parent_name, &entry);
+			ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->parent_name, &entry);
 			if(EOK != ret)
 			{
 				*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
@@ -349,7 +353,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 				break;
 			}
 			/* Add the interface into the database */
-			ret = pfe_if_db_add(context->log_if_db, context->if_session_id, log_if, pfe_phy_if_get_id(phy_if));
+			ret = pfe_if_db_add(fci_context->log_if_db, fci_context->if_session_id, log_if, pfe_phy_if_get_id(phy_if));
 			if(EOK != ret)
 			{
 				pfe_log_if_destroy(log_if);
@@ -362,7 +366,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 
 		case FPP_ACTION_DEREGISTER:
 		{
-			ret = pfe_if_db_get_first(context->log_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
+			ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
 
 			if(EOK != ret)
 			{
@@ -394,11 +398,11 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 				args.fp1_table = oal_ntohl(args.fp1_table);
 
 				/* Destroy FP tables */
-				fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, &args);
+				(void)fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, &args);
 			}
 
 			/* Remove interface from the database */
-			(void)pfe_if_db_remove(context->log_if_db, context->if_session_id, entry);
+			(void)pfe_if_db_remove(fci_context->log_if_db, fci_context->if_session_id, entry);
 			/* Destroy the interface */
 			pfe_log_if_destroy(log_if);
 			break;
@@ -409,7 +413,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 			*fci_ret = FPP_ERR_OK;
 			*reply_len = sizeof(fpp_log_if_cmd_t);
 
-			ret = pfe_if_db_get_first(context->log_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
+			ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
 
 			if(EOK != ret)
 			{
@@ -450,7 +454,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 			ret = pfe_log_if_del_match_rule(log_if, rules);
 
 			/* Destroy FP tables if they are not used by new rules */
-			fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, &args);
+			(void)fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, &args);
 
 			if(EOK == ret)
 			{
@@ -471,7 +475,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 				fp_table_addr = fci_fp_db_get_table_dmem_addr(if_cmd->arguments.fp_table0);
 				if(0U == fp_table_addr)
 				{   /* Table has not been created yet */
-					ret = fci_fp_db_push_table_to_hw(context->class, if_cmd->arguments.fp_table0);
+					ret = fci_fp_db_push_table_to_hw(fci_context->class, if_cmd->arguments.fp_table0);
 					if(EOK != ret)
 					{   /* Failed to write */
 						*fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
@@ -506,7 +510,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 				fp_table_addr = fci_fp_db_get_table_dmem_addr(if_cmd->arguments.fp_table1);
 				if(0U == fp_table_addr)
 				{   /* Table has not been created yet */
-					ret = fci_fp_db_push_table_to_hw(context->class, if_cmd->arguments.fp_table1);
+					ret = fci_fp_db_push_table_to_hw(fci_context->class, if_cmd->arguments.fp_table1);
 					if(EOK != ret)
 					{   /* Failed to write */
 						*fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
@@ -595,7 +599,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 #endif
 
 					/* For each bit in egress mask search if the phy if exists */
-					ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)index, &entry);
+					ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)index, &entry);
 					if((EOK == ret) && (NULL != entry))
 					{   /* phy if does exist */
 						phy_if = pfe_if_db_entry_get_phy_if(entry);
@@ -724,7 +728,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 		}
 		case FPP_ACTION_QUERY:
 		{
-			ret = pfe_if_db_get_first(context->log_if_db, context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);
+			ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);
 			if (NULL == entry)
 			{
 				*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
@@ -742,7 +746,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 		{
 			if (NULL == entry)
 			{
-				ret = pfe_if_db_get_next(context->log_if_db, context->if_session_id, &entry);
+				ret = pfe_if_db_get_next(fci_context->log_if_db, fci_context->if_session_id, &entry);
 				if (NULL == entry)
 				{
 					*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
@@ -774,8 +778,8 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
 				*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
 				break;
 			}
-
-			if(EOK != (ret = pfe_log_if_get_stats(log_if,&stats)))
+			ret = pfe_log_if_get_stats(log_if,&stats);
+			if(EOK != ret)
 			{
 				NXP_LOG_ERROR("Could not get interface statistics\n");
 				break;
@@ -884,7 +888,7 @@ errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd
  */
 errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_phy_if_cmd_t *if_cmd;
 	errno_t ret = EOK;
 	pfe_if_db_entry_t *entry = NULL;
@@ -906,7 +910,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 		return EINVAL;
 	}
 
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -934,7 +938,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 		case FPP_ACTION_UPDATE:
 		{
 			/* Get the requested interface */
-			ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
+			ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);
 
 			if(EOK != ret)
 			{
@@ -974,7 +978,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 				break;
 			}
 
-			for(i = 0U; i < FPP_MIRRORS_CNT; i++)
+			for(i = 0U; i < (uint32_t)FPP_MIRRORS_CNT; i++)
 			{
 				/* RX */
 				if('\0' == if_cmd->rx_mirrors[i][0])
@@ -1218,7 +1222,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 					addr = fci_fp_db_get_table_dmem_addr((char_t *)if_cmd->ftable);
 					if (0U == addr)
 					{
-						(void)fci_fp_db_push_table_to_hw(context->class, (char_t *)if_cmd->ftable);
+						(void)fci_fp_db_push_table_to_hw(fci_context->class, (char_t *)if_cmd->ftable);
 						addr = fci_fp_db_get_table_dmem_addr((char_t *)if_cmd->ftable);
 					}
 
@@ -1257,7 +1261,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 
 		case FPP_ACTION_QUERY:
 		{
-			ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);
+			ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);
 
 			if(EOK != ret)
 			{
@@ -1278,7 +1282,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 		{
 			if (NULL == entry)
 			{
-				ret = pfe_if_db_get_next(context->phy_if_db, context->if_session_id, &entry);
+				ret = pfe_if_db_get_next(fci_context->phy_if_db, fci_context->if_session_id, &entry);
 				if(EOK != ret)
 				{
 					ret = EOK;
@@ -1301,8 +1305,8 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 				*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
 				break;
 			}
-
-			if(EOK != (ret = pfe_phy_if_get_stats(phy_if, &stats)))
+			ret = pfe_phy_if_get_stats(phy_if, &stats);
+			if(EOK != ret)
 			{
 				NXP_LOG_ERROR("Could not get interface statistics\n");
 				break;
@@ -1318,11 +1322,11 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 
 			reply_buf->flags |= (TRUE == pfe_phy_if_is_promisc(phy_if)) ? oal_htonl(FPP_IF_PROMISC) : 0U;
 			reply_buf->flags |= (TRUE == pfe_phy_if_is_enabled(phy_if)) ? oal_htonl(FPP_IF_ENABLED) : 0U;
-			reply_buf->flags |= (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_VLAN_CONF_CHECK)) ? oal_htonl(FPP_IF_VLAN_CONF_CHECK) : 0U;
-			reply_buf->flags |= (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_PTP_CONF_CHECK)) ? oal_htonl(FPP_IF_PTP_CONF_CHECK) : 0U;
-			reply_buf->flags |= (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_PTP_PROMISC)) ? oal_htonl(FPP_IF_PTP_PROMISC) : 0U;
-			reply_buf->flags |= (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_ALLOW_Q_IN_Q)) ? oal_htonl(FPP_IF_ALLOW_Q_IN_Q) : 0U;
-			reply_buf->flags |= (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_DISCARD_TTL)) ? oal_htonl(FPP_IF_DISCARD_TTL) : 0U;
+			reply_buf->flags |= ((uint32_t)IF_FL_NONE != (uint32_t)pfe_phy_if_get_flag(phy_if, IF_FL_VLAN_CONF_CHECK)) ? oal_htonl(FPP_IF_VLAN_CONF_CHECK) : 0U;
+			reply_buf->flags |= ((uint32_t)IF_FL_NONE != (uint32_t)pfe_phy_if_get_flag(phy_if, IF_FL_PTP_CONF_CHECK)) ? oal_htonl(FPP_IF_PTP_CONF_CHECK) : 0U;
+			reply_buf->flags |= ((uint32_t)IF_FL_NONE != (uint32_t)pfe_phy_if_get_flag(phy_if, IF_FL_PTP_PROMISC)) ? oal_htonl(FPP_IF_PTP_PROMISC) : 0U;
+			reply_buf->flags |= ((uint32_t)IF_FL_NONE != (uint32_t)pfe_phy_if_get_flag(phy_if, IF_FL_ALLOW_Q_IN_Q)) ? oal_htonl(FPP_IF_ALLOW_Q_IN_Q) : 0U;
+			reply_buf->flags |= ((uint32_t)IF_FL_NONE != (uint32_t)pfe_phy_if_get_flag(phy_if, IF_FL_DISCARD_TTL)) ? oal_htonl(FPP_IF_DISCARD_TTL) : 0U;
 
 			/* Get the mode - use the fact enums have same values */
 			reply_buf->mode = (fpp_phy_if_op_mode_t) pfe_phy_if_get_op_mode(phy_if);
@@ -1332,7 +1336,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
 			/* Use the fact that the enums have same values */
 			reply_buf->block_state = (fpp_phy_if_block_state_t)block_state;
 
-			for(i = 0U; i < FPP_MIRRORS_CNT; i++)
+			for(i = 0U; i < (uint32_t)FPP_MIRRORS_CNT; i++)
 			{
 				/* RX */
 				mirror = pfe_phy_if_get_rx_mirror(phy_if, i);
@@ -1419,7 +1423,7 @@ errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd
  */
 errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_if_mac_cmd_t *if_mac_cmd;
 	errno_t ret = EOK;
 	pfe_if_db_entry_t *entry = NULL;
@@ -1433,7 +1437,7 @@ errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd
 		return EINVAL;
 	}
 
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -1463,7 +1467,7 @@ errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd
 
 	/*	Preparation: get the requested interface */
 	{
-		ret = pfe_if_db_get_single(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, if_mac_cmd->name, &entry);
+		ret = pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_mac_cmd->name, &entry);
 
 		if(EOK != ret)
 		{
@@ -1565,7 +1569,7 @@ errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd
 					break;
 				}
 			}
-			
+
 			/* Store phy_if name into reply message */
 			(void)strncpy(reply_buf->name, pfe_phy_if_get_name(phy_if), (uint32_t)IFNAMSIZ-1U);
 
@@ -1620,3 +1624,4 @@ errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_internal.h b/sw/fci/src/fci_internal.h
index 8c29e1b..a63ce7d 100644
--- a/sw/fci/src/fci_internal.h
+++ b/sw/fci/src/fci_internal.h
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -76,14 +76,13 @@ struct fci_tag
  /* Global variable used across all fci files */
 extern fci_t __context;
 
-errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg);
 errno_t fci_interfaces_session_cmd(uint32_t code, uint16_t *fci_ret);
 errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_phy_if_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_buf, uint32_t *reply_len);
-errno_t fci_connections_ipv4_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct_cmd_t *reply_buf, uint32_t *reply_len);
-errno_t fci_connections_ipv6_ct_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32_t *reply_len);
+errno_t fci_connections_ipv4_ct_cmd(const fci_msg_t *msg, uint16_t *fci_ret, fpp_ct_cmd_t *reply_buf, uint32_t *reply_len);
+errno_t fci_connections_ipv6_ct_cmd(const fci_msg_t *msg, uint16_t *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_timeout_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32_t *reply_len);
@@ -96,8 +95,6 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry);
 void fci_connections_drop_all(void);
 errno_t fci_connections_set_default_timeout(uint8_t ip_proto, uint32_t timeout);
 uint32_t fci_connections_get_default_timeout(uint8_t ip_proto);
-errno_t fci_enable_if(pfe_phy_if_t *phy_if);
-errno_t fci_disable_if(pfe_phy_if_t *phy_if);
 errno_t fci_qos_queue_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_queue_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_qos_scheduler_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_scheduler_cmd_t *reply_buf, uint32_t *reply_len);
 errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_shaper_cmd_t *reply_buf, uint32_t *reply_len);
diff --git a/sw/fci/src/fci_l2br.c b/sw/fci/src/fci_l2br.c
index 607967b..c2234c5 100644
--- a/sw/fci/src/fci_l2br.c
+++ b/sw/fci/src/fci_l2br.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2021 NXP
+ *  Copyright 2021-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -25,6 +25,7 @@
 #include "fci_internal.h"
 #include "fci.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -35,7 +36,7 @@
  */
 errno_t fci_l2br_flush_cmd(uint32_t code, uint16_t *fci_ret)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	errno_t ret = EOK;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -52,7 +53,7 @@ errno_t fci_l2br_flush_cmd(uint32_t code, uint16_t *fci_ret)
 	{
 		case FPP_CMD_L2_FLUSH_ALL:
 		{
-			ret = pfe_l2br_flush_all(context->l2_bridge);
+			ret = pfe_l2br_flush_all(fci_context->l2_bridge);
 			if (EOK != ret)
 			{
 				*fci_ret = FPP_ERR_INTERNAL_FAILURE;
@@ -64,25 +65,25 @@ errno_t fci_l2br_flush_cmd(uint32_t code, uint16_t *fci_ret)
 
 		case FPP_CMD_L2_FLUSH_LEARNED:
 		{
-			ret = pfe_l2br_flush_learned(context->l2_bridge);
+			ret = pfe_l2br_flush_learned(fci_context->l2_bridge);
 			if (EOK != ret)
 			{
 				*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				NXP_LOG_DEBUG("Can't flush learned MAC table entries: %d\n", ret);
 			}
-			
+
 			break;
 		}
 
 		case FPP_CMD_L2_FLUSH_STATIC:
 		{
-			ret = pfe_l2br_flush_static(context->l2_bridge);
+			ret = pfe_l2br_flush_static(fci_context->l2_bridge);
 			if (EOK != ret)
 			{
 				*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				NXP_LOG_DEBUG("Can't flush static MAC table entries: %d\n", ret);
 			}
-			
+
 			break;
 		}
 
@@ -98,3 +99,4 @@ errno_t fci_l2br_flush_cmd(uint32_t code, uint16_t *fci_ret)
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_l2br_domains.c b/sw/fci/src/fci_l2br_domains.c
index a1114dd..2da2d32 100644
--- a/sw/fci/src/fci_l2br_domains.c
+++ b/sw/fci/src/fci_l2br_domains.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -25,10 +25,11 @@
 #include "fci_internal.h"
 #include "fci.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 static errno_t fci_l2br_domain_remove(pfe_l2br_domain_t *domain);
-static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *phy_if);
+static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *phy_if);
 uint32_t fci_l2br_static_entry_get_valid_fw_list(void);
 
 /**
@@ -43,7 +44,7 @@ uint32_t fci_l2br_static_entry_get_valid_fw_list(void);
  */
 errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	fpp_l2_bd_cmd_t *bd_cmd;
 	errno_t ret = EOK;
 	pfe_l2br_domain_t *domain = NULL;
@@ -61,7 +62,7 @@ errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -117,7 +118,7 @@ errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *
 			}
 
 			/*	Add new bridge domain */
-			ret = pfe_l2br_domain_create(context->l2_bridge, oal_ntohs(bd_cmd->vlan));
+			ret = pfe_l2br_domain_create(fci_context->l2_bridge, oal_ntohs(bd_cmd->vlan));
 			if (EPERM == ret)
 			{
 				NXP_LOG_ERROR("Domain %d already created\n", oal_ntohs(bd_cmd->vlan));
@@ -152,7 +153,7 @@ errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *
 			}
 
 			/*	Get the domain instance (by VLAN) */
-			domain = pfe_l2br_get_first_domain(context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
+			domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
 			if (NULL == domain)
 			{
 				/*	This shall never happen */
@@ -190,7 +191,7 @@ errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *
 				if (0U != (oal_ntohl(bd_cmd->if_list) & (1U << ii)))
 				{
 					/*	Only add interfaces which are known to platform interface database */
-					ret = pfe_if_db_get_first(context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);
+					ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);
 
 					if(EOK != ret)
 					{
@@ -261,21 +262,12 @@ errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_bd_cmd_t *
 						if (EOK != ret)
 						{
 							*fci_ret = FPP_ERR_INTERNAL_FAILURE;
+							NXP_LOG_ERROR("Domain %d: Failed to remove interface %d\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
 							break;
 						}
 						else
 						{
-							/*	Disable interface */
-							ret = fci_disable_if(phy_if);
-							if (EOK != ret)
-							{
-								NXP_LOG_ERROR("Unable to disable interface (%s): %d\n", pfe_phy_if_get_name(phy_if), ret);
-								*fci_ret = FPP_ERR_INTERNAL_FAILURE;
-							}
-							else
-							{
-								NXP_LOG_INFO("Domain %d: Interface %d removed\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
-							}
+							NXP_LOG_INFO("Domain %d: Interface %d removed\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
 						}
 					}
 				}
@@ -309,7 +301,7 @@ finalize_domain_registration:
 			}
 
 			/*	Get and delete bridge domain */
-			domain = pfe_l2br_get_first_domain(context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
+			domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
 			if (NULL == domain)
 			{
 				NXP_LOG_ERROR("Domain %d not found\n", oal_ntohs(bd_cmd->vlan));
@@ -336,7 +328,7 @@ finalize_domain_registration:
 
 		case FPP_ACTION_QUERY:
 		{
-			domain = pfe_l2br_get_first_domain(context->l2_bridge, L2BD_CRIT_ALL, NULL);
+			domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_ALL, NULL);
 			if (NULL == domain)
 			{
 				ret = EOK;
@@ -350,7 +342,7 @@ finalize_domain_registration:
 		{
 			if (NULL == domain)
 			{
-				domain = pfe_l2br_get_next_domain(context->l2_bridge);
+				domain = pfe_l2br_get_next_domain(fci_context->l2_bridge);
 				if (NULL == domain)
 				{
 					ret = EOK;
@@ -400,7 +392,7 @@ finalize_domain_registration:
 			bd_cmd->if_list = oal_htonl(pfe_l2br_domain_get_if_list(domain));
 			bd_cmd->untag_if_list = oal_htonl(pfe_l2br_domain_get_untag_if_list(domain));
 
-			fci_ret = FPP_ERR_OK;
+			*fci_ret = FPP_ERR_OK;
 			ret = EOK;
 
 			break;
@@ -434,7 +426,7 @@ finalize_domain_registration:
  */
 errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	errno_t ret = EOK;
 	fpp_l2_static_ent_cmd_t *br_ent_cmd;
 	pfe_l2br_static_entry_t *entry = NULL;
@@ -448,7 +440,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -485,7 +477,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 			}
 
 			(void)memcpy(mac, br_ent_cmd->mac, sizeof(pfe_mac_addr_t));
-			ret = pfe_l2br_static_entry_create(context->l2_bridge, oal_ntohs(br_ent_cmd->vlan), mac, oal_ntohl(br_ent_cmd->forward_list));
+			ret = pfe_l2br_static_entry_create(fci_context->l2_bridge, oal_ntohs(br_ent_cmd->vlan), mac, oal_ntohl(br_ent_cmd->forward_list));
 			if (EOK == ret) {
 				NXP_LOG_DEBUG("Static entry %02x:%02x:%02x:%02x:%02x:%02x added to vlan %d\n", mac[0], mac[1], mac[2], mac[3], mac[4], mac[5], oal_ntohs(br_ent_cmd->vlan));
 				*fci_ret = FPP_ERR_OK;
@@ -514,7 +506,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 			}
 
 			/* search for entry update fw list */
-			entry = pfe_l2br_static_entry_get_first(context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
+			entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
 			if (NULL == entry)
 			{
 				*fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
@@ -523,19 +515,19 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 			{
 				*fci_ret = FPP_ERR_OK;
 
-				if (EOK != pfe_l2br_static_entry_replace_fw_list(context->l2_bridge, entry, oal_ntohl(br_ent_cmd->forward_list)))
+				if (EOK != pfe_l2br_static_entry_replace_fw_list(fci_context->l2_bridge, entry, oal_ntohl(br_ent_cmd->forward_list)))
 				{
 					*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				}
-				if (EOK != pfe_l2br_static_entry_set_local_flag(context->l2_bridge, entry, br_ent_cmd->local))
+				if (EOK != pfe_l2br_static_entry_set_local_flag(fci_context->l2_bridge, entry, br_ent_cmd->local))
 				{
 					*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				}
-				if (EOK != pfe_l2br_static_entry_set_src_discard_flag(context->l2_bridge, entry, br_ent_cmd->src_discard))
+				if (EOK != pfe_l2br_static_entry_set_src_discard_flag(fci_context->l2_bridge, entry, br_ent_cmd->src_discard))
 				{
 					*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				}
-				if (EOK != pfe_l2br_static_entry_set_dst_discard_flag(context->l2_bridge, entry, br_ent_cmd->dst_discard))
+				if (EOK != pfe_l2br_static_entry_set_dst_discard_flag(fci_context->l2_bridge, entry, br_ent_cmd->dst_discard))
 				{
 					*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				}
@@ -545,7 +537,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 		case FPP_ACTION_DEREGISTER:
 		{
 			/* search for entry and delete if the entery exists */
-			entry = pfe_l2br_static_entry_get_first(context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
+			entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
 			if (NULL == entry)
 			{
 				*fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
@@ -554,7 +546,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 			{
 				*fci_ret = FPP_ERR_OK;
 
-				if (EOK != pfe_l2br_static_entry_destroy(context->l2_bridge, entry))
+				if (EOK != pfe_l2br_static_entry_destroy(fci_context->l2_bridge, entry))
 				{
 					*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				}
@@ -563,7 +555,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 		}
 		case FPP_ACTION_QUERY:
 		{
-			entry = pfe_l2br_static_entry_get_first(context->l2_bridge, L2SENT_CRIT_ALL, NULL, NULL);
+			entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_ALL, NULL, NULL);
 			if (NULL == entry)
 			{
 				ret = EOK;
@@ -576,7 +568,7 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 		{
 			if (NULL == entry)
 			{
-				entry = pfe_l2br_static_entry_get_next(context->l2_bridge);
+				entry = pfe_l2br_static_entry_get_next(fci_context->l2_bridge);
 				if (NULL == entry)
 				{
 					ret = EOK;
@@ -598,9 +590,9 @@ errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_l2_stat
 			/* FW list */
 			br_ent_cmd->forward_list = oal_htonl(pfe_l2br_static_entry_get_fw_list(entry));
 			/* misc flags */
-			(void)pfe_l2br_static_entry_get_local_flag(context->l2_bridge, entry, (bool_t *)&br_ent_cmd->local);
-			(void)pfe_l2br_static_entry_get_src_discard_flag(context->l2_bridge, entry, (bool_t *)&br_ent_cmd->src_discard);
-			(void)pfe_l2br_static_entry_get_dst_discard_flag(context->l2_bridge, entry, (bool_t *)&br_ent_cmd->dst_discard);
+			(void)pfe_l2br_static_entry_get_local_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->local);
+			(void)pfe_l2br_static_entry_get_src_discard_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->src_discard);
+			(void)pfe_l2br_static_entry_get_dst_discard_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->dst_discard);
 			*fci_ret = FPP_ERR_OK;
 			break;
 		}
@@ -623,7 +615,7 @@ uint32_t fci_l2br_static_entry_get_valid_fw_list(void)
 	uint32_t ii;
 	uint32_t session_id, valid_if_list = 0U;
 	errno_t ret = EOK;
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	pfe_if_db_entry_t *if_db_entry = NULL;
 
 	ret = pfe_if_db_lock(&session_id);
@@ -637,7 +629,7 @@ uint32_t fci_l2br_static_entry_get_valid_fw_list(void)
 	{
 			/*	Only add interfaces which are known to platform interface database */
 			if_db_entry = NULL;
-			ret = pfe_if_db_get_first(context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);
+			ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);
 			if (EOK != ret)
 			{
 				valid_if_list = 0;
@@ -665,11 +657,9 @@ uint32_t fci_l2br_static_entry_get_valid_fw_list(void)
  * @param[in]	phy_if Interface instance
  * @retval		EOK Success
  */
-static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *phy_if)
+static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *phy_if)
 {
-	fci_t *context = (fci_t *)&__context;
 	errno_t ret = EOK;
-	pfe_ct_phy_if_id_t id;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == domain)))
@@ -677,12 +667,6 @@ static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, pfe_phy_if_t
 		NXP_LOG_ERROR("NULL argument received\n");
 		return EINVAL;
 	}
-
-    if (unlikely(FALSE == context->fci_initialized))
-	{
-    	NXP_LOG_ERROR("Context not initialized\n");
-		return EPERM;
-	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
 	if (NULL != phy_if)
@@ -695,40 +679,9 @@ static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, pfe_phy_if_t
 		}
 		else
 		{
-			/*	Find out if there is another domain containing given physical interface */
-			if (NULL != pfe_l2br_get_first_domain(context->l2_bridge, L2BD_BY_PHY_IF, phy_if))
-			{
-				/*	Interface is still member of some bridge domain */
-				;
-			}
-			else
-			{
-				/*	Get ID (sanity check) */
-				id = pfe_phy_if_get_id(phy_if);
-
-				NXP_LOG_INFO("Interface %d is not member of any bridge domain. Setting default operational mode.\n", id);
-
-				ret = pfe_phy_if_set_op_mode(phy_if, IF_OP_DEFAULT);
-				if (EOK != ret)
-				{
-					NXP_LOG_DEBUG("Could not set interface operational mode\n");
-					return ret;
-				}
-				else
-				{
-					NXP_LOG_INFO("Interface %d: Disabling promiscuous mode\n", id);
-					ret = pfe_phy_if_promisc_disable(phy_if);
-					if (EOK != ret)
-					{
-						NXP_LOG_ERROR("Could not disable promiscuous mode: %d\n", ret);
-						return ret;
-					}
-				}
-			}
+			ret = pfe_l2br_domain_flush_by_if(domain, phy_if);
 		}
 	}
-	
-	(void)id;
 
 	return ret;
 }
@@ -740,7 +693,7 @@ static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, pfe_phy_if_t
  */
 static errno_t fci_l2br_domain_remove(pfe_l2br_domain_t *domain)
 {
-	pfe_phy_if_t *phy_if;
+	const pfe_phy_if_t *phy_if;
 	errno_t ret = EOK;
 	uint16_t vlan;
 
@@ -781,5 +734,6 @@ static errno_t fci_l2br_domain_remove(pfe_l2br_domain_t *domain)
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
 
 /** @}*/
diff --git a/sw/fci/src/fci_mirror.c b/sw/fci/src/fci_mirror.c
index fea464f..a7e7362 100644
--- a/sw/fci/src/fci_mirror.c
+++ b/sw/fci/src/fci_mirror.c
@@ -18,6 +18,7 @@
 #include "oal.h"
 #include "fci_mirror.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /**
@@ -31,7 +32,7 @@
  */
 errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fpp_mirror_cmd_t *mirror_cmd;
 	const char *str;
 	errno_t ret = EOK;
@@ -50,7 +51,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 		return EINVAL;
 	}
 
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -123,7 +124,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 			/* 1) Set egress port */
 
 			/* Lock interface db and get the requested interface */
-			ret = pfe_if_db_lock(&context->if_session_id);
+			ret = pfe_if_db_lock(&fci_context->if_session_id);
 			if(EOK != ret)
 			{
 				/* FCI command requested unfulfillable action. Respond with FCI error code. */
@@ -132,7 +133,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 				break;
 			}
 
-			ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, mirror_cmd->egress_phy_if, &entry);
+			(void)pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, mirror_cmd->egress_phy_if, &entry);
 			if (NULL != entry)
 			{
 				phy_if = pfe_if_db_entry_get_phy_if(entry);
@@ -141,7 +142,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 			if((NULL == entry) || (NULL == phy_if))
 			{
 				/* FCI command requested nonexistent entity. Respond with FCI error code. */
-				pfe_if_db_unlock(context->if_session_id);
+				(void)pfe_if_db_unlock(fci_context->if_session_id);
 				NXP_LOG_DEBUG("No interface '%s'\n", mirror_cmd->egress_phy_if);
 				*fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
 				ret = EOK;
@@ -154,13 +155,13 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 			if(EOK != ret)
 			{
 				/* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
-				pfe_if_db_unlock(context->if_session_id);
+				(void)pfe_if_db_unlock(fci_context->if_session_id);
 				NXP_LOG_DEBUG("Cannot set egress port for '%s'\n", mirror_cmd->name);
 				*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				break;
 			}
 
-			pfe_if_db_unlock(context->if_session_id);
+			(void)pfe_if_db_unlock(fci_context->if_session_id);
 
 			/* 2) Set filter to select frames */
 
@@ -233,7 +234,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 				{	/* Requested filter table (from FCI command) is not used anywhere yet. Good. Use it as filter. */
 
                     /* Add filter table to HW */
-					ret = fci_fp_db_push_table_to_hw(context->class, (char_t *)mirror_cmd->filter_table_name);
+					ret = fci_fp_db_push_table_to_hw(fci_context->class, (char_t *)mirror_cmd->filter_table_name);
 					addr = fci_fp_db_get_table_dmem_addr((char_t *)mirror_cmd->filter_table_name);
 
                     /* Update filter address of mirror */
@@ -262,7 +263,13 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 			mirror_cmd->m_actions = (fpp_modify_actions_t)oal_ntohl(mirror_cmd->m_actions);
 			if(MODIFY_ACT_NONE == mirror_cmd->m_actions)
 			{	/* No modifications */
-				pfe_mirror_set_actions(mirror, RT_ACT_NONE, NULL);
+				ret = pfe_mirror_set_actions(mirror, RT_ACT_NONE, NULL);
+                if(EOK != ret)
+                {
+                    NXP_LOG_ERROR("Failed to set modification action: MODIFY_ACT_NONE.\n");
+                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
+                    break;
+                }
 			}
 			else
 			{	/* Some actions to be set - add one by one */
@@ -280,7 +287,13 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 
 				/* Apply */
 				m_actions = (pfe_ct_route_actions_t) oal_htonl(m_actions);  /* PFE has modification actions in big endian. */
-				pfe_mirror_set_actions(mirror, m_actions, &m_args);
+				ret = pfe_mirror_set_actions(mirror, m_actions, &m_args);
+                if(EOK != ret)
+                {
+                    NXP_LOG_ERROR("Failed to set modification actions.\n");
+                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
+                    break;
+                }
 			}
 
 			break;
@@ -360,7 +373,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 
 			/* Get egress port name, step #1 - find the egress interface in the interface db */
 			egress_id = pfe_mirror_get_egress_port(mirror);
-			ret = pfe_if_db_lock(&context->if_session_id);
+			ret = pfe_if_db_lock(&fci_context->if_session_id);
 			if(EOK != ret)
 			{
 				/* FCI command requested unfulfillable action. Respond with FCI error code. */
@@ -369,7 +382,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 				break;
 			}
 
-            ret = pfe_if_db_get_single(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)egress_id, &entry);
+            (void)pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)egress_id, &entry);
 			if (NULL != entry)
 			{
 				phy_if = pfe_if_db_entry_get_phy_if(entry);
@@ -378,7 +391,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
             if((NULL == entry) || (NULL == phy_if))
 			{
 				/* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
-				(void)pfe_if_db_unlock(context->if_session_id);
+				(void)pfe_if_db_unlock(fci_context->if_session_id);
 				NXP_LOG_DEBUG("Cannot get egress interface of the mirror '%s'.\n", pfe_mirror_get_name(mirror));
 				*fci_ret = FPP_ERR_INTERNAL_FAILURE;
 				ret = ENOENT;
@@ -389,7 +402,7 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 			str = pfe_phy_if_get_name(phy_if);
 			(void)strncpy(reply_buf->egress_phy_if, str, (uint32_t)IFNAMSIZ - 1U);
 			reply_buf->egress_phy_if[(uint32_t)IFNAMSIZ - 1U] = '\0';  /* Ensure termination */
-			pfe_if_db_unlock(context->if_session_id);
+			(void)pfe_if_db_unlock(fci_context->if_session_id);
 
 			/* Get filter name */
 			(void)memset(reply_buf->filter_table_name, 0, IFNAMSIZ);
@@ -440,3 +453,4 @@ errno_t fci_mirror_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_mirror_cmd_t *repl
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/fci/src/fci_qos.c b/sw/fci/src/fci_qos.c
index dfdff4a..9d583ed 100644
--- a/sw/fci/src/fci_qos.c
+++ b/sw/fci/src/fci_qos.c
@@ -23,13 +23,13 @@
 #include "fci_internal.h"
 #include "fci.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /*
  * 	This is storage of scheduler algorithms ordered in way
  *	as defined by the FCI (see fpp_ext.h::fpp_qos_scheduler_cmd_t)
  */
-static const pfe_tmu_sched_algo_t sch_algos[] = {SCHED_ALGO_PQ, SCHED_ALGO_DWRR, SCHED_ALGO_RR, SCHED_ALGO_WRR};
 #ifdef NXP_LOG_ENABLED
 static const char_t *sch_algos_str[] = {"SCHED_ALGO_PQ", "SCHED_ALGO_DWRR", "SCHED_ALGO_RR", "SCHED_ALGO_WRR"};
 #endif /* NXP_LOG_ENABLED */
@@ -83,7 +83,7 @@ errno_t fci_qos_queue_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_queue_cmd_t
 	fpp_qos_queue_cmd_t *q;
 	errno_t ret = EOK;
 	pfe_phy_if_t *phy_if = NULL;
-	fci_t *fci = (fci_t *)&__context;
+	const fci_t *fci = (fci_t *)&__context;
 	uint8_t cnt, ii;
 	static const pfe_tmu_queue_mode_t fci_qmode_to_qmode[] =
 		{TMU_Q_MODE_INVALID, TMU_Q_MODE_DEFAULT, TMU_Q_MODE_TAIL_DROP, TMU_Q_MODE_WRED};
@@ -355,8 +355,10 @@ errno_t fci_qos_scheduler_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_schedul
 	fpp_qos_scheduler_cmd_t *sch;
 	errno_t ret = EOK;
 	pfe_phy_if_t *phy_if = NULL;
-	fci_t *fci = (fci_t *)&__context;
+	const fci_t *fci = (fci_t *)&__context;
 	uint8_t ii, cnt, queue;
+	uint32_t weight;
+	static const pfe_tmu_sched_algo_t sch_algos[] = {SCHED_ALGO_PQ, SCHED_ALGO_DWRR, SCHED_ALGO_RR, SCHED_ALGO_WRR};
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
@@ -635,18 +637,18 @@ errno_t fci_qos_scheduler_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_schedul
 					else
 					{
 						/*	Scheduler input 'ii' is connected to prepend scheduler output */
+						weight = pfe_tmu_sch_get_input_weight(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id, ii);
+						reply_buf->input_w[ii] = oal_htonl(weight);
 						reply_buf->input_src[ii] = 8U;
-						reply_buf->input_w[ii] = oal_htonl(pfe_tmu_sch_get_input_weight(fci->tmu,
-								pfe_phy_if_get_id(phy_if), sch->id, ii));
 						reply_buf->input_en |= ((uint32_t)1U << ii);
 					}
 				}
 				else
 				{
 					/*	Scheduler input 'ii' is connected to queue */
+					weight = pfe_tmu_sch_get_input_weight(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id, ii);
+					reply_buf->input_w[ii] = oal_htonl(weight);
 					reply_buf->input_src[ii] = queue;
-					reply_buf->input_w[ii] = oal_htonl(pfe_tmu_sch_get_input_weight(fci->tmu,
-							pfe_phy_if_get_id(phy_if), sch->id, ii));
 					reply_buf->input_en |= ((uint32_t)1U << ii);
 				}
 			}
@@ -684,6 +686,7 @@ errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_shaper_cmd
 	errno_t ret = EOK;
 	pfe_phy_if_t *phy_if = NULL;
 	const fci_t *fci = (fci_t *)&__context;
+	uint32_t isl;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
@@ -810,7 +813,7 @@ errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_shaper_cmd
 				NXP_LOG_DEBUG("Setting shaper %d credit limits %d-%d\n",
 						(int_t)shp->id, (int_t)oal_ntohl(shp->max_credit), (int_t)oal_ntohl(shp->min_credit));
 				ret = pfe_tmu_shp_set_limits(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id,
-						oal_ntohl(shp->max_credit), oal_ntohl(shp->min_credit));
+						(int32_t)oal_ntohl(shp->max_credit), (int32_t)oal_ntohl(shp->min_credit));
 				if (EOK != ret)
 				{
 					/* FCI command has wrong data. Respond with FCI error code. */
@@ -914,13 +917,13 @@ errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_shaper_cmd
 			else
 			{
 				/*	Ensure expected endianness */
-				reply_buf->max_credit = oal_htonl(reply_buf->max_credit);
-				reply_buf->min_credit = oal_htonl(reply_buf->min_credit);
+				reply_buf->max_credit = (int32_t)oal_htonl(reply_buf->max_credit);
+				reply_buf->min_credit = (int32_t)oal_htonl(reply_buf->min_credit);
 			}
 
 			/*	Get idle slope */
-			reply_buf->isl = oal_htonl(
-					pfe_tmu_shp_get_idle_slope(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id));
+			isl = pfe_tmu_shp_get_idle_slope(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
+			reply_buf->isl = oal_htonl(isl);
 
 			/*	Get shaper position */
 			reply_buf->position =
@@ -1613,8 +1616,8 @@ errno_t fci_qos_policer_shp_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_polic
 			shp_type = shp_cmd->type;
 			shp_mode = shp_cmd->mode;
 			shp_isl = oal_ntohl(shp_cmd->isl);
-			shp_max_credit = oal_ntohl(shp_cmd->max_credit);
-			shp_min_credit = oal_ntohl(shp_cmd->min_credit);
+			shp_max_credit = (int32_t)oal_ntohl(shp_cmd->max_credit);
+			shp_min_credit = (int32_t)oal_ntohl(shp_cmd->min_credit);
 
 			/* commit command to h/w */
 			ret = pfe_gpi_shp_set_type(gpi, shp_id, (pfe_iqos_shp_type_t)shp_type);
@@ -1693,8 +1696,8 @@ errno_t fci_qos_policer_shp_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_polic
 			reply_buf->type = shp_type;
 			reply_buf->mode = shp_mode;
 			reply_buf->isl = oal_htonl(shp_isl);
-			reply_buf->max_credit = oal_htonl(shp_max_credit);
-			reply_buf->min_credit = oal_htonl(shp_min_credit);
+			reply_buf->max_credit = (int32_t)oal_htonl(shp_max_credit);
+			reply_buf->min_credit = (int32_t)oal_htonl(shp_min_credit);
 
 			*reply_len = sizeof(*shp_cmd);
 			break;
@@ -1711,4 +1714,5 @@ errno_t fci_qos_policer_shp_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_qos_polic
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
 /** @}*/
diff --git a/sw/fci/src/fci_routes.c b/sw/fci/src/fci_routes.c
index 1f255e7..5ca5a65 100644
--- a/sw/fci/src/fci_routes.c
+++ b/sw/fci/src/fci_routes.c
@@ -26,6 +26,7 @@
 #include "fci_internal.h"
 #include "fci.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route);
@@ -39,7 +40,7 @@ static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route);
  */
 static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
 {
-	fci_t *context = (fci_t *)&__context;
+	const fci_t *fci_context = (fci_t *)&__context;
 	pfe_rtable_entry_t *entry;
 	errno_t ret;
 
@@ -50,14 +51,14 @@ static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
 		return;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return;
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-	entry = pfe_rtable_get_first(context->rtable, RTABLE_CRIT_BY_ROUTE_ID, &route->id);
+	entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_ROUTE_ID, &route->id);
 	while (NULL != entry)
 	{
 		ret = fci_connections_drop_one(entry);
@@ -66,7 +67,7 @@ static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
 			NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
 		}
 
-		entry = pfe_rtable_get_next(context->rtable);
+		entry = pfe_rtable_get_next(fci_context->rtable);
 	}
 }
 
@@ -82,7 +83,7 @@ static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
  */
 errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_buf, uint32_t *reply_len)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fpp_rt_cmd_t *rt_cmd;
 	bool_t is_ipv6 = FALSE;
 	errno_t ret = EOK;
@@ -101,7 +102,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -150,7 +151,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 			if (EOK == ret)
 			{
 				/*	Validate the interface */
-				ret = pfe_if_db_get_first(context->phy_if_db, session_id, IF_DB_CRIT_BY_NAME, (void *)rt_cmd->output_device, &if_entry);
+				ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_NAME, (void *)rt_cmd->output_device, &if_entry);
 				if(EOK != ret)
 				{
 					NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: DB is locked in different session, entry was not retrieved from DB\n");
@@ -189,7 +190,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 			}
 
 			/*	Add entry to database (values in network endian) */
-			ret = fci_rt_db_add(&context->route_db,	&ip, &src_mac, &dst_mac,
+			ret = fci_rt_db_add(&fci_context->route_db,	&ip, &src_mac, &dst_mac,
 								phy_if,
 								rt_cmd->id,
 								msg->client,
@@ -219,7 +220,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 		case FPP_ACTION_DEREGISTER:
 		{
 			/*	Validate the route */
-			rt_entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_BY_ID, (void *)&rt_cmd->id);
+			rt_entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (void *)&rt_cmd->id);
 			if (NULL == rt_entry)
 			{
 				NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Requested route %d not found\n", (int_t)oal_ntohl(rt_cmd->id));
@@ -253,7 +254,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 
 		case FPP_ACTION_QUERY:
 		{
-			rt_entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_ALL, NULL);
+			rt_entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
 			if (NULL == rt_entry)
 			{
 				ret = EOK;
@@ -267,7 +268,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 		{
 			if (NULL == rt_entry)
 			{
-				rt_entry = fci_rt_db_get_next(&context->route_db);
+				rt_entry = fci_rt_db_get_next(&fci_context->route_db);
 				if (NULL == rt_entry)
 				{
 					ret = EOK;
@@ -300,7 +301,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
 			reply_buf->id = rt_entry->id;
 			(void)strncpy(reply_buf->output_device, pfe_phy_if_get_name(rt_entry->iface), (uint32_t)IFNAMSIZ-1U);
 
-			fci_ret = FPP_ERR_OK;
+			*fci_ret = FPP_ERR_OK;
 			ret = EOK;
 
 			break;
@@ -335,7 +336,7 @@ errno_t fci_routes_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_rt_cmd_t *reply_bu
  */
 errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_msg_t msg;
 	fpp_rt_cmd_t *rt_cmd = NULL;
 	errno_t ret;
@@ -347,7 +348,7 @@ errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
 		return EINVAL;
 	}
 
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -366,7 +367,8 @@ errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
 	{
 		rt_cmd->id = route->id;
 
-		if (EOK != fci_core_client_send((fci_core_client_t *)route->refptr, &msg, NULL))
+		ret = fci_core_client_send((fci_core_client_t *)route->refptr, &msg, NULL);
+		if (EOK != ret)
 		{
 			NXP_LOG_ERROR("Could not notify FCI client\n");
 		}
@@ -378,7 +380,7 @@ errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
 	fci_routes_remove_related_connections(route);
 
 	/*	Remove the route */
-	ret = fci_rt_db_remove(&context->route_db, route);
+	ret = fci_rt_db_remove(&fci_context->route_db, route);
 	if (EOK != ret)
 	{
 		NXP_LOG_ERROR("Can't remove route: %d\n", ret);
@@ -394,12 +396,12 @@ errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
  */
 void fci_routes_drop_all(void)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *entry = NULL;
 	errno_t ret;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(FALSE == context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
 		NXP_LOG_ERROR("Context not initialized\n");
 		return;
@@ -408,7 +410,7 @@ void fci_routes_drop_all(void)
 
 	NXP_LOG_DEBUG("Removing all routes\n");
 
-	entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_ALL, NULL);
+	entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
 	while (NULL != entry)
 	{
 		ret = fci_routes_drop_one(entry);
@@ -417,7 +419,7 @@ void fci_routes_drop_all(void)
 			NXP_LOG_WARNING("Couldn't properly drop a route: %d\n", ret);
 		}
 
-		entry = fci_rt_db_get_next(&context->route_db);
+		entry = fci_rt_db_get_next(&fci_context->route_db);
 	}
 }
 
@@ -428,12 +430,12 @@ void fci_routes_drop_all(void)
  */
 void fci_routes_drop_all_ipv4(void)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *entry = NULL;
 	errno_t ret;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return;
@@ -442,7 +444,7 @@ void fci_routes_drop_all_ipv4(void)
 
 	NXP_LOG_DEBUG("Removing all IPv4 routes\n");
 
-	entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_ALL, NULL);
+	entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
 	while (NULL != entry)
 	{
 		if (entry->dst_ip.is_ipv4)
@@ -454,7 +456,7 @@ void fci_routes_drop_all_ipv4(void)
 			}
 		}
 
-		entry = fci_rt_db_get_next(&context->route_db);
+		entry = fci_rt_db_get_next(&fci_context->route_db);
 	}
 }
 
@@ -465,12 +467,12 @@ void fci_routes_drop_all_ipv4(void)
  */
 void fci_routes_drop_all_ipv6(void)
 {
-	fci_t *context = (fci_t *)&__context;
+	fci_t *fci_context = (fci_t *)&__context;
 	fci_rt_db_entry_t *entry = NULL;
 	errno_t ret;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return;
@@ -479,7 +481,7 @@ void fci_routes_drop_all_ipv6(void)
 
 	NXP_LOG_DEBUG("Removing all IPv6 routes\n");
 
-	entry = fci_rt_db_get_first(&context->route_db, RT_DB_CRIT_ALL, NULL);
+	entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
 	while (NULL != entry)
 	{
 		if (!entry->dst_ip.is_ipv4)
@@ -491,9 +493,10 @@ void fci_routes_drop_all_ipv6(void)
 			}
 		}
 
-		entry = fci_rt_db_get_next(&context->route_db);
+		entry = fci_rt_db_get_next(&fci_context->route_db);
 	}
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
 /** @}*/
diff --git a/sw/fci/src/fci_rt_db.c b/sw/fci/src/fci_rt_db.c
index 7d1d028..de2d927 100644
--- a/sw/fci/src/fci_rt_db.c
+++ b/sw/fci/src/fci_rt_db.c
@@ -25,6 +25,7 @@
 #include "linked_list.h"
 #include "fci_rt_db.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 static bool_t fci_rt_db_match_criterion(fci_rt_db_t *db, const fci_rt_db_entry_t *entry);
@@ -420,4 +421,5 @@ errno_t fci_rt_db_drop_all(fci_rt_db_t *db)
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
 /** @}*/
diff --git a/sw/fci/src/fci_spd.c b/sw/fci/src/fci_spd.c
index 7cda24c..85240e8 100644
--- a/sw/fci/src/fci_spd.c
+++ b/sw/fci/src/fci_spd.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2020-2021 NXP
+ *  Copyright 2020-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -19,11 +19,12 @@
 #include "fci.h"
 #include "fci_spd.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 errno_t fci_spd_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_spd_cmd_t *reply_buf, uint32_t *reply_len)
 {
-    fci_t *context = (fci_t *)&__context;
+    fci_t *fci_context = (fci_t *)&__context;
     errno_t ret = EOK;
     fpp_spd_cmd_t *spd_cmd;
     pfe_if_db_entry_t *pfe_if_db_entry = NULL;
@@ -38,7 +39,7 @@ errno_t fci_spd_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_spd_cmd_t *reply_buf,
 		return EINVAL;
 	}
 
-    if (unlikely(FALSE == context->fci_initialized))
+    if (unlikely(FALSE == fci_context->fci_initialized))
 	{
     	NXP_LOG_ERROR("Context not initialized\n");
 		return EPERM;
@@ -71,16 +72,16 @@ errno_t fci_spd_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_spd_cmd_t *reply_buf,
 
 	spd_cmd = (fpp_spd_cmd_t *)(msg->msg_cmd.payload);
     /* Get the physical interface reference - needed for all commands */
-    ret = pfe_if_db_lock(&context->if_session_id);
+    ret = pfe_if_db_lock(&fci_context->if_session_id);
     if (EOK != ret)
     {
         *fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
         NXP_LOG_DEBUG("DB lock failed\n");
         return ret;
     }
-    ret = pfe_if_db_get_first(context->phy_if_db, context->if_session_id, IF_DB_CRIT_BY_NAME, spd_cmd->name, &pfe_if_db_entry);
+    ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, spd_cmd->name, &pfe_if_db_entry);
     /* We first unlock the database and then examine the result */
-    if (EOK != pfe_if_db_unlock(context->if_session_id))
+    if (EOK != pfe_if_db_unlock(fci_context->if_session_id))
     {
         *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
         NXP_LOG_DEBUG("DB unlock failed\n");
@@ -219,3 +220,4 @@ errno_t fci_spd_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_spd_cmd_t *reply_buf,
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/libfci_cli/Makefile b/sw/libfci_cli/Makefile
index e8f340e..27d65a7 100644
--- a/sw/libfci_cli/Makefile
+++ b/sw/libfci_cli/Makefile
@@ -1,5 +1,5 @@
 # =========================================================================
-#  Copyright 2018-2021 NXP
+#  Copyright 2018-2022 NXP
 #
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
@@ -60,7 +60,7 @@ ifeq ($(TARGET_OS),LINUX)
 	GLOBAL_CCFLAGS := $(shell echo $(GLOBAL_CCFLAGS))
 	
 	CLI_TARGET_OS = "LNX"
-	CLI_DRV_VERSION = "BETA 0.9.7"
+	CLI_DRV_VERSION = "RTM 1.0.0 RC1"
 else
 #This branch by defaut means QNX.
 	LIBS += -L../xfci/libfci/build/$(PLATFORM)-$(BUILD_PROFILE) -l:libfci.a
diff --git a/sw/linux-pfeng/Makefile b/sw/linux-pfeng/Makefile
index f4a080c..90991f8 100644
--- a/sw/linux-pfeng/Makefile
+++ b/sw/linux-pfeng/Makefile
@@ -1,5 +1,5 @@
 #
-# Copyright 2018-2021 NXP
+# Copyright 2018-2022 NXP
 #
 # SPDX-License-Identifier:     BSD OR GPL-2.0
 #
@@ -16,9 +16,12 @@ PLATFORM ?= aarch64-fsl-linux
 PFE_CFG_MULTI_INSTANCE_SUPPORT ?= 0
 PFE_CFG_LINUX_TRACE ?= 0
 PFE_CFG_HIF_USE_BD_TRIGGER ?= 1
-PFE_CFG_BD_MEM = "pfe-bdr-pool"
-PFE_CFG_SYS_MEM = "pfe-bmu2-pool"
+PFE_CFG_BD_MEM ?= "pfe-bdr-pool"
+PFE_CFG_SYS_MEM ?= "pfe-bmu2-pool"
+PFE_CFG_RT_MEM ?= "pfe-rt-pool"
 PFE_CFG_LINUX_NO_SERDES_SUPPORT ?= 0
+PFE_CFG_BMU2_BUF_COUNT ?= 256
+PFE_CFG_LINUX_RES_MEM_ENABLE ?= 0
 
 # Warning for PFE_CFG_LINUX_TRACE=1:
 # The compile time checker doesn't work well with -Og
diff --git a/sw/linux-pfeng/pfeng-drv.c b/sw/linux-pfeng/pfeng-drv.c
index 788ede7..f84f044 100644
--- a/sw/linux-pfeng/pfeng-drv.c
+++ b/sw/linux-pfeng/pfeng-drv.c
@@ -90,7 +90,7 @@ MODULE_PARM_DESC(fw_class_name, "\t The name of CLASS firmware file (default: re
 
 static char *fw_util_name;
 module_param(fw_util_name, charp, 0444);
-MODULE_PARM_DESC(fw_util_name, "\t The name of UTIL firmware file (default: read from device-tree or " PFENG_FW_UTIL_NAME ")");
+MODULE_PARM_DESC(fw_util_name, "\t The name of UTIL firmware file (default: read from device-tree or " PFENG_FW_UTIL_NAME "). Use \"NONE\" to run without UTIL firmware.");
 
 static int l2br_vlan_id = 1;
 module_param(l2br_vlan_id, int, 0644);
@@ -588,7 +588,11 @@ static int pfeng_drv_probe(struct platform_device *pdev)
 		}
 	}
 
-	oal_mm_init(dev);
+	ret = oal_mm_init(dev);
+	if (ret) {
+		dev_err(dev, "OAL memory managment init failed\n");
+		goto err_drv;
+	}
 
 	/* Build CLASS firmware name */
 	if (fw_class_name && strlen(fw_class_name))
@@ -601,7 +605,7 @@ static int pfeng_drv_probe(struct platform_device *pdev)
 
 	/* Build UTIL firmware name */
 	if (fw_util_name && strlen(fw_util_name))
-		priv->fw_util_name = fw_util_name;
+		priv->fw_util_name = ((strlen(fw_util_name) == 4) && !strncmp(fw_util_name, "NONE", 4)) ? (NULL) : (fw_util_name);
 	if (!priv->fw_util_name || !strlen(priv->fw_util_name)) {
 		dev_info(dev, "UTIL firmware not requested. Disable UTIL\n");
 		priv->pfe_cfg->enable_util = false;
diff --git a/sw/linux-pfeng/pfeng.h b/sw/linux-pfeng/pfeng.h
index f360e44..d0b9d22 100644
--- a/sw/linux-pfeng/pfeng.h
+++ b/sw/linux-pfeng/pfeng.h
@@ -39,7 +39,7 @@
 #else
 #error Incorrect configuration!
 #endif
-#define PFENG_DRIVER_VERSION		"BETA 0.9.7"
+#define PFENG_DRIVER_VERSION		"RTM 1.0.0 RC1"
 
 #define PFENG_FW_CLASS_NAME		"s32g_pfe_class.fw"
 #define PFENG_FW_UTIL_NAME		"s32g_pfe_util.fw"
diff --git a/sw/oal/public/oal_mm.h b/sw/oal/public/oal_mm.h
index 54cf564..6f330d8 100644
--- a/sw/oal/public/oal_mm.h
+++ b/sw/oal/public/oal_mm.h
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -46,6 +46,7 @@
 #ifndef PUBLIC_OAL_MM_H_
 #define PUBLIC_OAL_MM_H_
 
+#if !defined(PFE_CFG_DETACHED_MINIHIF)
 /**
  * @brief		Initialize the memory management library
  * @details		The oal_mm must be initialized by this call before it can be used.
@@ -106,14 +107,6 @@ void *oal_mm_malloc_contig_named_aligned_cache(const char_t *pool, const addr_t
  */
 void oal_mm_free_contig(const void *vaddr);
 
-/**
- * @brief		Convert virtual address to physical
- * @details		Only applicable to memory allocated by oal_mm_alloc_config_xxx variants
- * @param[in]	vaddr The virtual address to be converted
- * @return		Physical address associated with the virtual one or NULL if failed
- */
-void *oal_mm_virt_to_phys_contig(void *vaddr);
-
 /**
  * @brief		Allocate memory
  * @details		This is intended to perform standard memory allocations (malloc-like).
@@ -129,6 +122,16 @@ void *oal_mm_malloc(const addr_t size);
  */
 void oal_mm_free(const void *vaddr);
 
+#endif /* PFE_CFG_DETACHED_MINIHIF */
+
+/**
+ * @brief		Convert virtual address to physical
+ * @details		Only applicable to memory allocated by oal_mm_alloc_config_xxx variants
+ * @param[in]	vaddr The virtual address to be converted
+ * @return		Physical address associated with the virtual one or NULL if failed
+ */
+void *oal_mm_virt_to_phys_contig(void *vaddr);
+
 /**
  * @brief		Convert virtual address to physical
  * @details		Only applicable to memory managed by oal_mm module.
diff --git a/sw/oal/public/oal_util_net.h b/sw/oal/public/oal_util_net.h
index 95a4d93..579ff64 100644
--- a/sw/oal/public/oal_util_net.h
+++ b/sw/oal/public/oal_util_net.h
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2019-2021 NXP
+ *  Copyright 2019-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -26,6 +26,8 @@
 #ifndef OAL_UTIL_NET_H_
 #define OAL_UTIL_NET_H_
 
+#include "oal_types.h"
+
 /*
  * QNX
  *
@@ -66,7 +68,7 @@
  *
  * @return		The pointer the to buffer, NULL if error occured
  */
-char_t *oal_util_net_inet_ntop(int af, const void *src, char_t *dst, uint32_t size);
+char_t *oal_util_net_inet_ntop(int32_t af, const void *src, char_t *dst, uint32_t size);
 
 #endif /* OAL_UTIL_NET_H_ */
 
diff --git a/sw/oal/src/oal_mm_linux.c b/sw/oal/src/oal_mm_linux.c
index 3bf411b..6974744 100644
--- a/sw/oal/src/oal_mm_linux.c
+++ b/sw/oal/src/oal_mm_linux.c
@@ -29,22 +29,49 @@
 #include "oal.h"
 #include "oal_mm.h"
 
+/* managed memory allocation types */
 enum pfe_kmem_type {
 	PFE_MEM_INVALID = 0,
 	PFE_MEM_KMALLOC,
 	PFE_MEM_DMA_ALLOC,
 	PFE_MEM_RESERVED_ALLOC,
 	PFE_MEM_BMU2_RESERVED_ALLOC,
+	PFE_MEM_RT_RESERVED_ALLOC,
 };
 
+/*
+ * Internal structure for managing oal_mm memory allocations
+ * One entry per (addr, size) range, stored in a hash table
+ * indexed by the virtual start address of the entry. May store
+ * a DMA coherent addr range, a special reserved memory range,
+ * or a stadard kmalloc'ed range perfromed via the oal_mm API.
+ */
 struct pfe_kmem {
 	struct hlist_node node;
-	enum pfe_kmem_type type;
 	void *addr;
 	addr_t size;
-	dma_addr_t dma_addr;
+	union {
+		dma_addr_t dma_addr;
+		phys_addr_t phys_addr;
+	};
+	enum pfe_kmem_type type;
+	bool_t is_dma;
 };
 
+/* 'no-map' reserved memory region types */
+enum pfeng_res_no_map_reg_id {
+	PFE_REG_BMU2 = 0,
+	PFE_REG_RT,
+	PFE_REG_COUNT
+};
+
+/*
+ * Reserved memory region configuration entry, populated based
+ * on info parsed from 'reserved-memory' device tree nodes.
+ * May hold system memory mapped ranges that require a gen pool
+ * allocator, or exclusive 'no-map' regions for single allocations,
+ * of type @pfeng_res_no_map_reg_id.
+ */
 struct pfe_reserved_mem {
 	struct list_head node;
 	char_t *name;
@@ -54,18 +81,27 @@ struct pfe_reserved_mem {
 	addr_t map_size;
 };
 
-static LIST_HEAD(pfe_reserved_mem_list);
-static void *bmu_start_va = NULL;
-static phys_addr_t bmu_start_pa;
-
 #define OAL_CACHE_ALLIGN	64
 
-/* struct device *dev associated with mm */
+/*
+ * Device associated with memory management, passed to @oal_mm_init().
+ * Must be the parent pfe device reference.
+ */
 static struct device *__dev = NULL;
 
-/* define hash table to store address */
+/* hash table for 'struct pfe_kmem' entries, indexed by virtual address */
 static DEFINE_HASHTABLE(pfe_addr_htable, 8);
 
+/* list of reserved memory ranges config params */
+static LIST_HEAD(pfe_reserved_mem_list);
+
+#ifdef PFE_CFG_PFE_MASTER
+static const char pfeng_res_no_map_name[PFE_REG_COUNT][20] = {
+	"pfe-bmu2-pool",
+	"pfe-rt-pool",
+};
+#endif
+
 static struct pfe_reserved_mem *__oal_mm_reserved_mem_get(const char_t *name)
 {
 	struct pfe_reserved_mem *res_mem = NULL;
@@ -87,9 +123,24 @@ static struct pfe_reserved_mem *__oal_mm_reserved_mem_get(const char_t *name)
 	return res_mem;
 }
 
-/**
- *	Allocate physically contiguous buffer physically aligned to "align" bytes.
- */
+static struct pfe_kmem *__oal_mm_get_vaddr_node(const void *vaddr)
+{
+	struct pfe_kmem *mem = NULL;
+	bool_t found = false;
+
+	hash_for_each_possible(pfe_addr_htable, mem, node, (uint64_t)vaddr) {
+		if ((uint64_t)vaddr == (uint64_t)mem->addr) {
+			found = true;
+			break;
+		}
+	}
+
+	if (!found)
+		mem = NULL;
+
+	return mem;
+}
+
 static void *__oal_mm_dma_alloc_htable(const addr_t size, const uint32_t align)
 {
 	struct pfe_kmem *hnode;
@@ -113,11 +164,12 @@ static void *__oal_mm_dma_alloc_htable(const addr_t size, const uint32_t align)
 		return NULL;
 	}
 
-	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 	hnode->type = PFE_MEM_DMA_ALLOC;
 	hnode->addr = vaddr;
 	hnode->size = size;
+	hnode->is_dma = true;
 	hnode->dma_addr = dma_addr;
+	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 
 	return vaddr;
 }
@@ -127,7 +179,6 @@ static void __oal_mm_dma_free_htable(struct pfe_kmem *hnode)
 	hnode->type = PFE_MEM_INVALID;
 	if (hnode->addr)
 		dma_free_coherent(__dev, hnode->size, hnode->addr, hnode->dma_addr);
-	kfree(hnode);
 }
 
 static void *__oal_mm_kmalloc_htable(const addr_t size)
@@ -145,9 +196,10 @@ static void *__oal_mm_kmalloc_htable(const addr_t size)
 		return NULL;
 	}
 
-	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 	hnode->type = PFE_MEM_KMALLOC;
 	hnode->addr = vaddr;
+	hnode->phys_addr = virt_to_phys(vaddr);
+	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 
 	return vaddr;
 }
@@ -157,9 +209,18 @@ static void __oal_mm_kfree_htable(struct pfe_kmem *hnode)
 	hnode->type = PFE_MEM_INVALID;
 	if (hnode->addr)
 		kfree(hnode->addr);
-	kfree(hnode);
 }
 
+/*
+ * Allocate inside a reserved memory region that is mapped in Linux's system memory, via memremap.
+ * The memory region is shared with PFE, so it must be in PFE's DMA domain. Objects allocated
+ * in this memory region need also to be efficiently accessed by the CPU, so, contrary to what
+ * the higher level plaform API suggests, this memory region is cacheable and H/W coherency
+ * b/w the CPUs and PFE is enabled on it. It's used to store buffer descriptors and PFE specific
+ * per-packet headers (i.e. in-band metadata that is read or written by PFE) whose processing on the
+ * CPU is performance critical. Since there are multiple such ojects (i.e. BD rings and headers)
+ * a generic allocator is used to manage allocation inside this reserved memory region.
+ */
 static void *__oal_mm_reserved_mem_alloc_htable(struct gen_pool *pool_alloc, const addr_t size, const uint32_t align)
 {
 	struct pfe_kmem *hnode;
@@ -180,10 +241,11 @@ static void *__oal_mm_reserved_mem_alloc_htable(struct gen_pool *pool_alloc, con
 		return NULL;
 	}
 
-	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 	hnode->type = PFE_MEM_RESERVED_ALLOC;
 	hnode->addr = vaddr;
 	hnode->size = size;
+	hnode->phys_addr = virt_to_phys(vaddr);
+	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)vaddr);
 
 	return vaddr;
 }
@@ -195,52 +257,52 @@ static void __oal_mm_reserved_mem_free_htable(struct pfe_kmem *hnode)
 	hnode->type = PFE_MEM_INVALID;
 	if (hnode->addr && res_mem->pool_alloc)
 		gen_pool_free(res_mem->pool_alloc, (unsigned long)hnode->addr, hnode->size);
-	kfree(hnode);
 }
 
-static void *__oal_mm_reserved_sys_mem_alloc_htable(struct pfe_reserved_mem *res_mem, const addr_t size, const uint32_t align)
+/*
+ * Return a "no-map" reserved region (not mapped in Linux's system memory) as the CPU
+ * should not access it at runtime. The region is mapped via ioremap, so it's contiguous
+ * and non-cacheable.
+ * These regions are reserved for PFE usage alone, and preconfigured by design (via DT).
+ * Such a region is destined for a single, usually large, object used by the accelerator,
+ * like the BMU2 buffer pool or the routing table.
+ */
+static void *__oal_mm_reserved_nomap_mem_alloc_htable(struct pfe_reserved_mem *res_mem, enum pfe_kmem_type type, const addr_t size, const uint32_t align)
 {
 	struct pfe_kmem *hnode;
 
 	if (!IS_ALIGNED(res_mem->map_start_pa, align)) {
-		NXP_LOG_ERROR("BMU2 buffer pool reserved mem region addr not aligned\n");
+		NXP_LOG_ERROR("%s reserved mem region addr not aligned\n", res_mem->name);
 		return NULL;
 	}
 
 	if (res_mem->map_size < size) {
-		NXP_LOG_ERROR("BMU2 buffer pool reserved mem region size exceeded\n");
+		NXP_LOG_ERROR("%s reserved mem region size exceeded\n", res_mem->name);
 		/* try default allocation */
 		return NULL;
 	}
 
-	if (bmu_start_va) {
-		NXP_LOG_ERROR("Allocation attempt in BMU2 exclusive zone\n");
+	if (__oal_mm_get_vaddr_node(res_mem->map_start_va)) {
+		NXP_LOG_ERROR("Allocation attempt in %s exclusive zone\n", res_mem->name);
 		/* try default allocation */
 		return NULL;
 	}
 
-	bmu_start_va = res_mem->map_start_va;
-	bmu_start_pa = res_mem->map_start_pa;
-
 	hnode = kzalloc(sizeof(struct pfe_kmem), GFP_KERNEL);
 	if (!hnode) {
-		bmu_start_va = NULL;
 		return NULL;
 	}
 
-	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)bmu_start_va);
-	hnode->type = PFE_MEM_BMU2_RESERVED_ALLOC;
-	hnode->addr = bmu_start_va;
+	hnode->type = type;
+	hnode->addr = res_mem->map_start_va;
 	hnode->size = size;
+	hnode->phys_addr = res_mem->map_start_pa;
+	hash_add(pfe_addr_htable, &hnode->node, (uint64_t)res_mem->map_start_va);
 
-	return bmu_start_va;
+	return res_mem->map_start_va;
 }
 
-static void __oal_mm_reserved_sys_mem_free_htable(struct pfe_kmem *hnode)
-{
-	bmu_start_va = NULL;
-	kfree(hnode);
-}
+/* External API */
 
 struct device *oal_mm_get_dev(void)
 {
@@ -260,8 +322,7 @@ void *oal_mm_malloc_contig_aligned_nocache(const addr_t size, const uint32_t ali
  */
 void *oal_mm_malloc_contig_aligned_cache(const addr_t size, const uint32_t align)
 {
-	/* All kmalloc memory is automatically aligned to at least 128B(or higher power of two) on arm64.
-	 * This should be replaced with genpool align allocator in future.*/
+	/* All kmalloc memory is automatically aligned to at least 128B(or higher power of two) on arm64. */
 	if (align && (ARCH_KMALLOC_MINALIGN % align)) {
 		NXP_LOG_ERROR("Alignment not supported\n");
 		return NULL;
@@ -276,16 +337,15 @@ void *oal_mm_malloc_contig_named_aligned_nocache(const char_t *pool, const addr_
 {
 	struct pfe_reserved_mem *res_mem;
 
-	if (strcmp(pool, PFE_CFG_BD_MEM) && strcmp(pool, PFE_CFG_SYS_MEM))
-		goto default_alloc;
-
-	/* use reserved memory */
+	/* try reserved memory */
 	res_mem = __oal_mm_reserved_mem_get(pool);
 	if (!res_mem)
 		goto default_alloc;
 
 	if (!strcmp(pool, PFE_CFG_SYS_MEM))
-		return __oal_mm_reserved_sys_mem_alloc_htable(res_mem, size, align);
+		return __oal_mm_reserved_nomap_mem_alloc_htable(res_mem, PFE_MEM_BMU2_RESERVED_ALLOC, size, align);
+	else if (!strcmp(pool, PFE_CFG_RT_MEM))
+		return __oal_mm_reserved_nomap_mem_alloc_htable(res_mem, PFE_MEM_RT_RESERVED_ALLOC, size, align);
 	else
 		return __oal_mm_reserved_mem_alloc_htable(res_mem->pool_alloc, size, align);
 
@@ -298,8 +358,7 @@ default_alloc:
  */
 void *oal_mm_malloc_contig_named_aligned_cache(const char_t *pool, const addr_t size, const uint32_t align)
 {
-	/* All kmalloc memory is automatically aligned to at least 128B(or higher power of two) on arm64.
-	 * This should be replaced with genpool align allocator in future.*/
+	/* All kmalloc memory is automatically aligned to at least 128B(or higher power of two) on arm64. */
 	if (align && (ARCH_KMALLOC_MINALIGN % align)) {
 		NXP_LOG_ERROR("Alignment not supported\n");
 		return NULL;
@@ -307,14 +366,18 @@ void *oal_mm_malloc_contig_named_aligned_cache(const char_t *pool, const addr_t
 	return __oal_mm_kmalloc_htable(size);
 }
 
-static struct pfe_kmem *__oal_mm_get_vaddr_node(const void *vaddr)
+void *oal_mm_virt_to_phys_contig(void *vaddr)
 {
-	struct pfe_kmem *mem = NULL;
+	struct pfe_kmem *mem = __oal_mm_get_vaddr_node(vaddr);
 
-	hash_for_each_possible(pfe_addr_htable, mem, node, (uint64_t)vaddr)
-		if (vaddr == mem->addr)
-			break;
-	return mem;
+	if (mem) {
+		if (mem->is_dma)
+			return (void *)mem->dma_addr;
+		else
+			return (void *)mem->phys_addr;
+	}
+
+	return (void *)virt_to_phys((volatile void *)vaddr);
 }
 
 /**
@@ -335,27 +398,26 @@ void oal_mm_free_contig(const void *vaddr)
 		return;
 	}
 
+	hash_del(&mem->node);
+
 	switch (mem->type) {
 		case PFE_MEM_KMALLOC:
-			hash_del(&mem->node);
 			__oal_mm_kfree_htable(mem);
 			break;
 		case PFE_MEM_DMA_ALLOC:
-			hash_del(&mem->node);
 			__oal_mm_dma_free_htable(mem);
 			break;
 		case PFE_MEM_RESERVED_ALLOC:
-			hash_del(&mem->node);
 			__oal_mm_reserved_mem_free_htable(mem);
 			break;
 		case PFE_MEM_BMU2_RESERVED_ALLOC:
-			hash_del(&mem->node);
-			__oal_mm_reserved_sys_mem_free_htable(mem);
+		case PFE_MEM_RT_RESERVED_ALLOC:
 			break;
 		default:
 			NXP_LOG_ERROR("invalid address node\n");
-			return;
 	}
+
+	kfree(mem);
 }
 
 /**
@@ -382,19 +444,6 @@ void oal_mm_free(const void *vaddr)
 	kfree((void *)vaddr);
 }
 
-void *oal_mm_virt_to_phys_contig(void *vaddr)
-{
-	struct pfe_kmem *mem = __oal_mm_get_vaddr_node(vaddr);
-
-	if (mem && mem->dma_addr)
-		return (void *)mem->dma_addr;
-
-	if (bmu_start_va == vaddr)
-		return (void *)bmu_start_pa;
-
-	return (void *)virt_to_phys((volatile void *)vaddr);
-}
-
 /**
  *	Try to find physical address associated with mapped virtual range
  */
@@ -446,11 +495,17 @@ uint32_t oal_mm_cache_get_line_size(void)
 }
 
 #ifdef PFE_CFG_PFE_MASTER
-static int pfeng_reserved_bmu2_pool_region_init(struct device *dev, int idx, struct reserved_mem **rmem_out)
+static int pfeng_reserved_no_map_region_init(struct device *dev, struct reserved_mem **rmem_out, int rmem_id, int *rmem_idx)
 {
 	struct device_node *mem_node;
 	struct reserved_mem *rmem;
-	void *base_va;
+	void __iomem *base_va;
+	char compatible[32];
+	int idx;
+
+	idx = of_property_match_string(dev->of_node, "memory-region-names", pfeng_res_no_map_name[rmem_id]);
+	if (idx < 0)
+		idx = *rmem_idx;
 
 	mem_node = of_parse_phandle(dev->of_node, "memory-region", idx);
 	if (!mem_node) {
@@ -458,33 +513,42 @@ static int pfeng_reserved_bmu2_pool_region_init(struct device *dev, int idx, str
 		goto out;
 	}
 
-	if (!of_device_is_compatible(mem_node, "fsl,pfe-bmu2-pool")) {
+	scnprintf(compatible, sizeof(compatible), "fsl,%s", pfeng_res_no_map_name[rmem_id]);
+	if (!of_device_is_compatible(mem_node, compatible)) {
 		/* don't fail probing if node not found */
-		dev_warn(dev, "fsl,pfe-bmu2-pool node missing\n");
+		dev_warn(dev, "%s node missing\n", compatible);
 		goto out;
 	}
 
 	rmem = of_reserved_mem_lookup(mem_node);
 	if (!rmem) {
 		dev_err(dev, "of_reserved_mem_lookup() returned NULL\n");
+		/* advance rmem iterator */
+		*rmem_idx = idx + 1;
 		goto out;
 	}
 
 	of_node_put(mem_node);
 
-	base_va = devm_memremap(dev, rmem->base, rmem->size, MEMREMAP_WC);
+	base_va = devm_ioremap_wc(dev, rmem->base, rmem->size);
 	if (!base_va) {
-		dev_err(dev, "PFE BMU2 pool mapping failed\n");
+		dev_err(dev, "%s mapping failed\n", pfeng_res_no_map_name[rmem_id]);
 		return -EINVAL;
 	}
 
+	memset_io(base_va, 0, rmem->size);
+
 	rmem->priv = base_va;
 	*rmem_out = rmem;
+	/* advance rmem iterator */
+	*rmem_idx = idx + 1;
+
+	dev_info(dev, "assigned reserved memory node %s\n", rmem->name);
 
 	return 0;
 
 out:
-	dev_warn(dev, "fallback to default BMU2 pool allocation\n");
+	dev_warn(dev, "fall back to default pool allocation\n");
 	of_node_put(mem_node);
 
 	return 0;
@@ -492,14 +556,19 @@ out:
 #endif /* PFE_CFG_PFE_MASTER */
 
 #if defined(PFE_CFG_PFE_MASTER) || defined(PFE_CFG_LINUX_RES_MEM_ENABLE)
-static int pfeng_reserved_bdr_pool_region_init(struct device *dev, int idx, struct gen_pool **pool_alloc)
+static int pfeng_reserved_bdr_pool_region_init(struct device *dev, struct gen_pool **pool_alloc, int rmem_idx)
 {
 	struct device_node *mem_node;
 	struct reserved_mem *rmem;
 	struct gen_pool *p;
 	void *base;
+	int idx;
 	int ret;
 
+	idx = of_property_match_string(dev->of_node, "memory-region-names", "pfe-bdr-pool");
+	if (idx < 0)
+		idx = rmem_idx;
+
 	mem_node = of_parse_phandle(dev->of_node, "memory-region", idx);
 	if (!mem_node) {
 		dev_warn(dev, "No memory-region found at index %d\n", idx);
@@ -543,6 +612,8 @@ static int pfeng_reserved_bdr_pool_region_init(struct device *dev, int idx, stru
 
 	*pool_alloc = p;
 
+	dev_info(dev, "assigned reserved memory node %s\n", rmem->name);
+
 	return 0;
 
 out:
@@ -551,6 +622,45 @@ out:
 
 	return 0;
 }
+
+static int pfeng_reserved_dma_shared_pool_region_init(struct device *dev, int *rmem_idx)
+{
+	int idx = of_property_match_string(dev->of_node, "memory-region-names", "pfe-shared-pool");
+	int ret;
+
+	if (idx < 0)
+		idx = *rmem_idx;
+
+	ret = of_reserved_mem_device_init_by_idx(dev, dev->of_node, idx);
+	if (ret) {
+		return ret;
+	}
+
+	/* advance rmem iterator */
+	*rmem_idx = idx + 1;
+
+	return 0;
+}
+
+static void pfeng_reserved_dma_shared_pool_region_release(struct device *dev)
+{
+	of_reserved_mem_device_release(dev);
+}
+#else
+static int pfeng_reserved_bdr_pool_region_init(struct device *dev, struct gen_pool **pool_alloc, int rmem_idx)
+{
+	dev_info(dev, "shared-dma-pool reserved region skipped\n");
+	return 0;
+}
+
+static int pfeng_reserved_dma_shared_pool_region_init(struct device *dev, int *rmem_idx)
+{
+	dev_info(dev, "pfe-bdr-pool reserved region skipped\n"); 
+	return 0;
+}
+
+#define pfeng_reserved_dma_shared_pool_region_release(dev) NULL
+
 #endif
 
 errno_t oal_mm_init(const void *devh)
@@ -558,47 +668,40 @@ errno_t oal_mm_init(const void *devh)
 	struct device *dev = (struct device *)devh;
 	struct pfe_reserved_mem *pfe_res_mem;
 	struct gen_pool *pool_alloc = NULL;
-	struct reserved_mem *rmem = NULL;
-	int idx = 0;
-	__maybe_unused int ret;
+	struct reserved_mem *rmem[PFE_REG_COUNT] = {NULL, NULL};
+	int rmem_idx = 0, i;
+	int ret;
 
 #ifdef PFE_CFG_PFE_MASTER
-	/* BMU2 region is required by MASTER only */
-	ret = pfeng_reserved_bmu2_pool_region_init(dev, idx, &rmem);
-	if (ret) {
-		dev_err(dev, "BMU2 pool reservation failed. Error %d\n", ret);
-		return -ENOMEM;
+	/* BMU2 and RT regions are required by MASTER only */
+	for (i = 0; i < PFE_REG_COUNT; i++) {
+		ret = pfeng_reserved_no_map_region_init(dev, &rmem[i], i, &rmem_idx);
+		if (ret) {
+			dev_err(dev, "%s reservation failed. Error %d\n",
+				pfeng_res_no_map_name[i], ret);
+			return ret;
+		}
 	}
-
-	if (rmem)
-		idx++;
 #endif /* PFE_CFG_PFE_MASTER */
 
-#if defined(PFE_CFG_PFE_MASTER) || defined(PFE_CFG_LINUX_RES_MEM_ENABLE)
-	ret = of_reserved_mem_device_init_by_idx(dev, dev->of_node, idx);
+	ret = pfeng_reserved_dma_shared_pool_region_init(dev, &rmem_idx);
 	if (ret) {
 		dev_err(dev, "shared-dma-pool reservation failed. Error %d\n", ret);
-		return -ENOMEM;
+		return ret;
 	}
-#else
-		dev_info(dev, "shared-dma-pool reserved region skipped\n");
-#endif
-	idx++;
 
-#if defined(PFE_CFG_PFE_MASTER) || defined(PFE_CFG_LINUX_RES_MEM_ENABLE)
-	ret = pfeng_reserved_bdr_pool_region_init(dev, idx, &pool_alloc);
+	ret = pfeng_reserved_bdr_pool_region_init(dev, &pool_alloc, rmem_idx);
 	if (ret) {
 		dev_err(dev, "BDR pool reservation failed. Error %d\n", ret);
-		return -ENOMEM;
+		goto err_bdr_pool_region_init;
 	}
-#else
-		dev_info(dev, "pfe-bdr-pool reserved region skipped\n"); 
-#endif
 
 	if (pool_alloc) {
 		pfe_res_mem = devm_kzalloc(dev, sizeof(*pfe_res_mem), GFP_KERNEL);
-		if (!pfe_res_mem)
-			return -ENOMEM;
+		if (!pfe_res_mem) {
+			ret = -ENOMEM;
+			goto err_alloc;
+		}
 
 		pfe_res_mem->name = PFE_CFG_BD_MEM;
 		pfe_res_mem->pool_alloc = pool_alloc;
@@ -606,15 +709,20 @@ errno_t oal_mm_init(const void *devh)
 		list_add(&pfe_res_mem->node, &pfe_reserved_mem_list);
 	}
 
-	if (rmem) {
+	for (i = 0; i < PFE_REG_COUNT; i++) {
+		if (!rmem[i])
+			continue;
+
 		pfe_res_mem = devm_kzalloc(dev, sizeof(*pfe_res_mem), GFP_KERNEL);
-		if (!pfe_res_mem)
-			return -ENOMEM;
+		if (!pfe_res_mem) {
+			ret = -ENOMEM;
+			goto err_alloc;
+		}
 
-		pfe_res_mem->name = PFE_CFG_SYS_MEM;
-		pfe_res_mem->map_start_va = rmem->priv;
-		pfe_res_mem->map_start_pa = rmem->base;
-		pfe_res_mem->map_size = rmem->size;
+		pfe_res_mem->name = (i == PFE_REG_RT) ? PFE_CFG_RT_MEM : PFE_CFG_SYS_MEM;
+		pfe_res_mem->map_start_va = rmem[i]->priv;
+		pfe_res_mem->map_start_pa = rmem[i]->base;
+		pfe_res_mem->map_size = rmem[i]->size;
 		INIT_LIST_HEAD(&pfe_res_mem->node);
 		list_add(&pfe_res_mem->node, &pfe_reserved_mem_list);
 	}
@@ -624,11 +732,17 @@ errno_t oal_mm_init(const void *devh)
 	hash_init(pfe_addr_htable);
 
 	return EOK;
+
+err_bdr_pool_region_init:
+err_alloc:
+	pfeng_reserved_dma_shared_pool_region_release(dev);
+
+	return ret;
 }
 
 void oal_mm_shutdown(void)
 {
-	of_reserved_mem_device_release(__dev);
+	pfeng_reserved_dma_shared_pool_region_release(__dev);
 	/* reserved_mem list nodes will be released by devm_ */
 	INIT_LIST_HEAD(&pfe_reserved_mem_list);
 
diff --git a/sw/oal/src/oal_util_net_linux.c b/sw/oal/src/oal_util_net_linux.c
index 48d7b22..14a289c 100644
--- a/sw/oal/src/oal_util_net_linux.c
+++ b/sw/oal/src/oal_util_net_linux.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2019-2020 NXP
+ *  Copyright 2019-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -38,9 +38,9 @@
 		ntohs(((struct in6_addr *)addr)->s6_addr16[6]), \
 		ntohs(((struct in6_addr *)addr)->s6_addr16[7])
 
-char_t *oal_util_net_inet_ntop(int af, const void *src, char_t *dst, uint32_t size)
+char_t *oal_util_net_inet_ntop(int32_t af, const void *src, char_t *dst, uint32_t size)
 {
-	int ret;
+	int32_t ret;
 
 	switch(af) {
 		case AF_INET:
diff --git a/sw/pfe_hif_drv/public/pfe_hif_drv.h b/sw/pfe_hif_drv/public/pfe_hif_drv.h
index 9934407..ca2953b 100644
--- a/sw/pfe_hif_drv/public/pfe_hif_drv.h
+++ b/sw/pfe_hif_drv/public/pfe_hif_drv.h
@@ -237,21 +237,17 @@ typedef struct pfe_hif_drv_tag pfe_hif_drv_t;
 typedef struct pfe_hif_pkt_tag pfe_hif_pkt_t;
 typedef errno_t (* pfe_hif_drv_client_event_handler)(pfe_hif_drv_client_t *client, void *arg, uint32_t event, uint32_t qno);
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-/*  Metadata prepended to every TX buffer. Its size shall be multiple of 4. */
-typedef struct __attribute__((packed, aligned(4)))
-{
-	boolean bDoTxIndication;
-	boolean bDoTS; /* Used in pfe_hif_drv to request timestamp on demand */
-} trTxMeta;
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 pfe_hif_drv_t *pfe_hif_drv_create(pfe_hif_chnl_t *channel);
 void pfe_hif_drv_destroy(pfe_hif_drv_t *hif_drv);
 errno_t pfe_hif_drv_init(pfe_hif_drv_t *hif_drv);
 errno_t pfe_hif_drv_start(pfe_hif_drv_t *hif_drv);
 void pfe_hif_drv_stop(pfe_hif_drv_t *hif_drv);
 void pfe_hif_drv_exit(pfe_hif_drv_t *hif_drv);
+pfe_hif_chnl_t *pfe_hif_drv_get_chnl(const pfe_hif_drv_t *hif_drv);
+void pfe_hif_drv_rx_job(void *arg);
+#if (TRUE == HIF_CFG_DETACH_TX_CONFIRMATION_JOB)
+void pfe_hif_drv_tx_job(void *arg);
+#endif /* HIF_CFG_DETACH_TX_CONFIRMATION_JOB */
 
 #ifdef PFE_CFG_MC_HIF
 void pfe_hif_drv_show_ring_status(pfe_hif_drv_t *hif_drv, bool_t rx, bool_t tx);
diff --git a/sw/pfe_platform/hw/s32g/pfe_class_csr.c b/sw/pfe_platform/hw/s32g/pfe_class_csr.c
index 6433258..97aef07 100644
--- a/sw/pfe_platform/hw/s32g/pfe_class_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_class_csr.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
diff --git a/sw/pfe_platform/hw/s32g/pfe_emac_csr.c b/sw/pfe_platform/hw/s32g/pfe_emac_csr.c
index 7aa0ab8..4df202c 100644
--- a/sw/pfe_platform/hw/s32g/pfe_emac_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_emac_csr.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -16,12 +16,13 @@
 static inline uint32_t reverse_bits_32(uint32_t u32Data)
 {
     uint8_t u8Index;
+    uint32_t u32DataTemp = u32Data;
 	uint32_t u32RevData = 0U;
 
 	for(u8Index = 0U; u8Index < 32U; u8Index++)
 	{
-		u32RevData = (u32RevData << 1U) | (u32Data & 0x1U);
-		u32Data >>= 1U;
+		u32RevData = (u32RevData << 1U) | (u32DataTemp & 0x1U);
+		u32DataTemp >>= 1U;
 	}
 
 	return u32RevData;
@@ -154,6 +155,9 @@ errno_t pfe_emac_cfg_init(addr_t base_va, pfe_emac_mii_mode_t mode,  pfe_emac_sp
 	reg &= ~TX_FLOW_CONTROL_ENABLE(1U);
 	hal_write32(reg, base_va + MAC_Q0_TX_FLOW_CTRL);
 	hal_write32(0U, base_va + MAC_INTERRUPT_ENABLE);
+	hal_write32(0xffffffffU, base_va + MMC_RX_INTERRUPT_MASK);
+	hal_write32(0xffffffffU, base_va + MMC_TX_INTERRUPT_MASK);
+	hal_write32(0xffffffffU, base_va + MMC_IPC_RX_INTERRUPT_MASK);
 	hal_write32(0U
 			| ARP_OFFLOAD_ENABLE(0U)
 			| SA_INSERT_REPLACE_CONTROL(CTRL_BY_SIGNALS)
@@ -958,14 +962,14 @@ void pfe_emac_cfg_get_tx_flow_control(addr_t base_va, bool_t* en)
 {
 	uint32_t reg = hal_read32(base_va + MAC_Q0_TX_FLOW_CTRL);
 
-	*en = reg & TX_FLOW_CONTROL_ENABLE(1);
+	*en = (0U == (reg & TX_FLOW_CONTROL_ENABLE(1))) ? FALSE : TRUE;
 }
 
 void pfe_emac_cfg_get_rx_flow_control(addr_t base_va, bool_t* en)
 {
 	uint32_t reg = hal_read32(base_va + MAC_RX_FLOW_CTRL);
 
-	*en = reg & RX_FLOW_CONTROL_ENABLE(1);
+	*en = (0U == (reg & RX_FLOW_CONTROL_ENABLE(1))) ? FALSE : TRUE;
 }
 
 /**
diff --git a/sw/pfe_platform/hw/s32g/pfe_emac_csr.h b/sw/pfe_platform/hw/s32g/pfe_emac_csr.h
index ad3acea..a8af5f1 100644
--- a/sw/pfe_platform/hw/s32g/pfe_emac_csr.h
+++ b/sw/pfe_platform/hw/s32g/pfe_emac_csr.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -84,6 +84,9 @@
 #define MMC_RX_INTERRUPT_MASK					0x070cU
 #define MMC_TX_INTERRUPT_MASK					0x0710U
 
+#define MMC_IPC_RX_INTERRUPT_MASK				0x800U
+#define MMC_IPC_RX_INTERRUPT					0x808U
+
 #define TX_OCTET_COUNT_GOOD_BAD					0x0714U
 #define TX_PACKET_COUNT_GOOD_BAD				0x0718U
 #define TX_BROADCAST_PACKETS_GOOD				0x071cU
diff --git a/sw/pfe_platform/hw/s32g/pfe_global_wsp.h b/sw/pfe_platform/hw/s32g/pfe_global_wsp.h
index ce1b0b5..47b0cc9 100644
--- a/sw/pfe_platform/hw/s32g/pfe_global_wsp.h
+++ b/sw/pfe_platform/hw/s32g/pfe_global_wsp.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2019-2021 NXP
+ *  Copyright 2019-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -56,6 +56,10 @@
 #define WSP_DBUG_BUS1			(0x98U)
 #define WSP_DBUG_BUS1_G3		(0xA4U)
 
+#define WSP_FAIL_STOP_MODE_INT_EN (0xc0U)
+#define WSP_FAIL_STOP_MODE_EN   (0xb4U)
+#define WSP_ECC_ERR_INT_EN      (0x130U)
+
 /* WSP_SYS_GENERIC_CONTROL bits */
 #define WSP_SYS_GEN_SOFT_RST_BIT					(1UL << 30U)
 
diff --git a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
index 90d3b45..d511bf8 100644
--- a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -248,12 +248,12 @@ void pfe_gpi_cfg_qos_clear_lru_entry_req(addr_t base_va, uint32_t addr)
 	igqos_class_write_lru_cmd(base_va, addr);
 }
 
-void pfe_gpi_cfg_qos_read_flow_entry_req(addr_t base_va, uint32_t addr)
+void pfe_gpi_cfg_qos_rd_fl_entry_req(addr_t base_va, uint32_t addr)
 {
 	igqos_class_read_flow_cmd(base_va, addr);
 }
 
-void pfe_gpi_cfg_qos_read_flow_entry_resp(addr_t base_va, uint32_t entry[])
+void pfe_gpi_cfg_qos_rd_fl_entry_resp(addr_t base_va, uint32_t entry[])
 {
 	igqos_class_read_entry_data(base_va, entry);
 }
diff --git a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.h b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.h
index 24d8b75..e2e7a71 100644
--- a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.h
+++ b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -287,8 +287,8 @@ bool_t pfe_gpi_cfg_qos_is_enabled(addr_t base_va);
 void pfe_gpi_cfg_qos_write_flow_entry_req(addr_t base_va, uint32_t addr, const uint32_t entry[]);
 void pfe_gpi_cfg_qos_clear_flow_entry_req(addr_t base_va, uint32_t addr);
 void pfe_gpi_cfg_qos_clear_lru_entry_req(addr_t base_va, uint32_t addr);
-void pfe_gpi_cfg_qos_read_flow_entry_req(addr_t base_va, uint32_t addr);
-void pfe_gpi_cfg_qos_read_flow_entry_resp(addr_t base_va, uint32_t entry[]);
+void pfe_gpi_cfg_qos_rd_fl_entry_req(addr_t base_va, uint32_t addr);
+void pfe_gpi_cfg_qos_rd_fl_entry_resp(addr_t base_va, uint32_t entry[]);
 bool_t pfe_gpi_cfg_qos_entry_ready(addr_t base_va);
 /* IGQOS WRED API */
 void pfe_gpi_cfg_wred_default_init(addr_t base_va);
diff --git a/sw/pfe_platform/hw/s32g/pfe_hif_csr.c b/sw/pfe_platform/hw/s32g/pfe_hif_csr.c
index 1f7f774..408b52d 100644
--- a/sw/pfe_platform/hw/s32g/pfe_hif_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_hif_csr.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -453,17 +453,6 @@ errno_t pfe_hif_cfg_init(addr_t base_va)
 #endif /* PFE_HIF_CFG_USE_BD_POLLING */
 
     /*    MICS */
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-    hal_write32(0U
-                | SEQ_NUM_CHECK_EN
-                /* | BDPRD_AXI_WRITE_DONE */
-                /* | DBPWR_AXI_WRITE_DONE */
-                /* | RXDXR_AXI_WRITE_DONE */
-                /* | TXDXR_AXI_WRITE_DONE */
-                | HIF_TIMEOUT_EN
-                | BD_START_SEQ_NUM(0x0U)
-                , base_va + HIF_MISC);
-#else
     hal_write32(0U
             /* | BDPRD_AXI_WRITE_DONE */
             /* | DBPWR_AXI_WRITE_DONE */
@@ -472,7 +461,6 @@ errno_t pfe_hif_cfg_init(addr_t base_va)
             | HIF_TIMEOUT_EN
             | BD_START_SEQ_NUM(0x0U)
             , base_va + HIF_MISC);
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
 
 	hal_write32(100000000U, base_va + HIF_TIMEOUT_REG);
 	hal_write32(0x33221100U, base_va + HIF_RX_QUEUE_MAP_CH_NO_ADDR);
@@ -884,42 +872,6 @@ bool_t pfe_hif_chnl_cfg_is_tx_dma_active(addr_t base_va, uint32_t channel_id)
 	}
 }
 
-/**
- * @brief		Get current RX ring sequence number
- * @param[in]	base_va Base address of HIF channel register space (virtual)
- * @param[in]	channel_id Channel identifier
- * @return		The sequence number
- */
-uint16_t pfe_hif_chnl_cfg_get_rx_seqnum(addr_t base_va, uint32_t channel_id)
-{
-	if (0U == hal_read32(base_va + HIF_RX_PKT_CNT0_CHn(channel_id)))
-	{
-		return 0U;
-	}
-	else
-	{
-		return (uint16_t)((hal_read32(base_va + HIF_RX_STATUS_0_CHn(channel_id)) + 1U) & 0xffffU);
-	}
-}
-
-/**
- * @brief		Get current TX ring sequence number
- * @param[in]	base_va Base address of HIF channel register space (virtual)
- * @param[in]	channel_id Channel identifier
- * @return		The sequence number
- */
-uint16_t pfe_hif_chnl_cfg_get_tx_seqnum(addr_t base_va, uint32_t channel_id)
-{
-	if (0U == hal_read32(base_va + HIF_TX_PKT_CNT1_CHn(channel_id)))
-	{
-		return 0U;
-	}
-	else
-	{
-		return (uint16_t)((hal_read32(base_va + HIF_TX_STATUS_1_CHn(channel_id)) + 1U) & 0xffffU);
-	}
-}
-
 /**
  * @brief		RX BDP FIFO status
  * @param[in]	base_va Base address of HIF channel register space (virtual)
diff --git a/sw/pfe_platform/hw/s32g/pfe_hif_csr.h b/sw/pfe_platform/hw/s32g/pfe_hif_csr.h
index dac39ed..6d9fb4f 100644
--- a/sw/pfe_platform/hw/s32g/pfe_hif_csr.h
+++ b/sw/pfe_platform/hw/s32g/pfe_hif_csr.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -275,8 +275,6 @@ void pfe_hif_chnl_cfg_set_rx_wb_table(addr_t base_va, uint32_t channel_id, const
 void pfe_hif_chnl_cfg_set_tx_wb_table(addr_t base_va, uint32_t channel_id, const void *wb_tbl_pa, uint32_t tbl_len);
 bool_t pfe_hif_chnl_cfg_is_rx_dma_active(addr_t base_va, uint32_t channel_id);
 bool_t pfe_hif_chnl_cfg_is_tx_dma_active(addr_t base_va, uint32_t channel_id);
-uint16_t pfe_hif_chnl_cfg_get_rx_seqnum(addr_t base_va, uint32_t channel_id);
-uint16_t pfe_hif_chnl_cfg_get_tx_seqnum(addr_t base_va, uint32_t channel_id);
 bool_t pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(addr_t base_va, uint32_t channel_id);
 bool_t pfe_hif_chnl_cfg_is_tx_bdp_fifo_empty(addr_t base_va, uint32_t channel_id);
 errno_t pfe_hif_chnl_cfg_set_rx_irq_coalesce(addr_t base_va, uint32_t channel_id, uint32_t frames, uint32_t cycles);
diff --git a/sw/pfe_platform/hw/s32g/pfe_platform_master.c b/sw/pfe_platform/hw/s32g/pfe_platform_master.c
index 6080e4f..40e291c 100644
--- a/sw/pfe_platform/hw/s32g/pfe_platform_master.c
+++ b/sw/pfe_platform/hw/s32g/pfe_platform_master.c
@@ -663,6 +663,26 @@ void  pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32_t id, void *bu
 			break;
 		}
 
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_LOG_IF_IS_LOOPBACK:
+		{
+			pfe_platform_rpc_pfe_log_if_is_loopback_ret_t rpc_ret = {0};
+
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_LOG_IF_IS_LOOPBACK\n");
+
+			if (EOK == ret)
+			{
+				rpc_ret.status = pfe_log_if_is_loopback(log_if_arg);
+			}
+
+			/*	Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16_t)sizeof(rpc_ret)))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
 		case (uint32_t)PFE_PLATFORM_RPC_PFE_LOG_IF_LOOPBACK_ENABLE:
 		{
 			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_LOG_IF_LOOPBACK_ENABLE\n");
@@ -821,12 +841,31 @@ void  pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32_t id, void *bu
 			break;
 		}
 
-		case (uint32_t)PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS:
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_LOG_IF_SET_EGRESS_IFS:
 		{
-			pfe_platform_rpc_pfe_log_if_get_egress_ret_t rpc_ret = {0};
+			pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t *arg_p = (pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t *)buf;
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_LOG_IF_SET_EGRESS_IFS\n");
+
+			if (EOK == ret)
+			{
+				ret = pfe_log_if_set_egress_ifs(log_if_arg, (uint32_t)arg_p->phy_if_id);
+			}
+
+			/*	Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS_IFS:
+		{
+			pfe_platform_rpc_pfe_log_if_get_egress_ifs_ret_t rpc_ret = {0};
 			uint32_t egress = 0U;
 
-			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS\n");
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS_IFS\n");
 
 			if (EOK == ret)
 			{
@@ -1073,6 +1112,42 @@ void  pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32_t id, void *bu
 			break;
 		}
 
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE:
+		{
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE\n");
+
+			if (EOK == ret)
+			{
+				ret = pfe_phy_if_loadbalance_enable(phy_if_arg);
+			}
+
+			/*      Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE:
+		{
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE\n");
+
+			if (EOK == ret)
+			{
+				ret = pfe_phy_if_loadbalance_disable(phy_if_arg);
+			}
+
+			/*      Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
 		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE:
 		{
 			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE\n");
@@ -1195,6 +1270,48 @@ void  pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32_t id, void *bu
 			break;
 		}
 
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE:
+		{
+			pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t *)buf;
+
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE\n");
+
+			if (EOK == ret)
+			{
+				ret = pfe_phy_if_set_block_state(phy_if_arg, rpc_arg->block_state);
+			}
+
+			/*	Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
+		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE:
+		{
+			pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t rpc_ret = {IF_BS_FORWARDING};
+			pfe_ct_block_state_t block_state = IF_BS_FORWARDING;
+			
+			NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE\n");
+
+			if (EOK == ret)
+			{
+				ret = pfe_phy_if_get_block_state(phy_if_arg, &block_state);
+				rpc_ret.state = block_state;
+			}
+
+			/*	Report execution status to caller */
+			if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16_t)sizeof(rpc_ret)))
+			{
+				NXP_LOG_ERROR("Could not send RPC response\n");
+			}
+
+			break;
+		}
+
 		case (uint32_t)PFE_PLATFORM_RPC_PFE_PHY_IF_HAS_LOG_IF:
 		{
 			pfe_platform_rpc_pfe_phy_if_has_log_if_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_has_log_if_arg_t *)buf;
@@ -1599,8 +1716,8 @@ static errno_t pfe_platform_create_gpi(pfe_platform_t *platform)
 
 	if (TRUE == pfe_feature_mgr_is_available("gpi_checksum_fix"))
 	{
-        aseq_len = 0x50U;
-        NXP_LOG_INFO("Using GPI ASEQ LEN 0x50\n");
+		aseq_len = 0x50U;
+		NXP_LOG_INFO("Using GPI ASEQ LEN 0x50\n");
 	}
 
 	/*	GPI1 */
@@ -1940,7 +2057,7 @@ static void pfe_platform_destroy_l2_bridge(pfe_platform_t *platform)
 {
 	if (NULL != platform->l2_bridge)
 	{
-		pfe_l2br_destroy(platform->l2_bridge);
+		(void)pfe_l2br_destroy(platform->l2_bridge);
 		platform->l2_bridge = NULL;
 	}
 
@@ -2580,7 +2697,7 @@ errno_t pfe_platform_create_ifaces(pfe_platform_t *platform)
 	{
 		char_t *name;
 		pfe_ct_phy_if_id_t id;
-		pfe_mac_addr_t mac;
+		pfe_mac_addr_t __attribute__((aligned(4))) mac;
 		struct
 		{
 			pfe_emac_t *emac;
@@ -2657,7 +2774,7 @@ errno_t pfe_platform_create_ifaces(pfe_platform_t *platform)
 						if (EOK != pfe_phy_if_bind_emac(phy_if, phy_ifs[ii].phy.emac))
 						{
 							NXP_LOG_ERROR("Can't bind interface with EMAC (%s)\n", phy_ifs[ii].name);
-                			pfe_phy_if_destroy(phy_if);
+							pfe_phy_if_destroy(phy_if);
 							phy_if = NULL;
 							return ENODEV;
 						}
@@ -2835,7 +2952,7 @@ static void pfe_platform_destroy_ifaces(pfe_platform_t *platform)
  */
 errno_t pfe_platform_soft_reset(const pfe_platform_t *platform)
 {
-	void *addr_gen, *addr_dbug;
+	addr_t addr_gen, addr_dbug;
 	uint32_t regval;
 	bool_t run_on_g3 = FALSE;
 	uint32_t timeout = 1000U;
@@ -2847,7 +2964,7 @@ errno_t pfe_platform_soft_reset(const pfe_platform_t *platform)
 		run_on_g3 = TRUE;
 	}
 
-	addr_gen = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_SYS_GENERIC_CONTROL + (addr_t)(pfe.cbus_baseaddr));
+	addr_gen = (addr_t)(pfe.cbus_baseaddr) + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_SYS_GENERIC_CONTROL;
 	regval = hal_read32(addr_gen);
 
 	/* Clear the soft reset done */
@@ -2866,7 +2983,7 @@ errno_t pfe_platform_soft_reset(const pfe_platform_t *platform)
 	if (TRUE == run_on_g3)
 	{
 		/* Wait for soft reset done */
-		addr_dbug = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_DBUG_BUS1_G3 + (addr_t)(pfe.cbus_baseaddr));
+		addr_dbug = (addr_t)(pfe.cbus_baseaddr) + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_DBUG_BUS1_G3;
 		do
 		{
 			regval = hal_read32(addr_dbug) & WSP_DBUG_BUS1_SOFT_RST_DONE_BIT_G3;
@@ -2905,7 +3022,8 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 	errno_t ret = EOK;
 	uint32_t *addr;
 	uint32_t val;
-	uint32_t *ii;
+	/*	Prevent LMEM initialization loop optimization to memset() at -O3 */
+	volatile uint32_t *ii;
 
 	(void)memset(&pfe, 0, sizeof(pfe_platform_t));
 	pfe.fci_created = FALSE;
@@ -2917,7 +3035,7 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 	if (NULL_ADDR == pfe.cbus_baseaddr)
 	{
 		NXP_LOG_ERROR("Can't map PPFE CBUS\n");
-        ret = EINVAL;
+		ret = EINVAL;
 		goto exit;
 	}
 	else
@@ -2927,10 +3045,21 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 
 	/* Initialize the features */
 	ret = pfe_feature_mgr_init((void *)pfe.cbus_baseaddr);
-    if (EOK != ret)
+	if (EOK != ret)
 	{
 		NXP_LOG_ERROR("Initialize the features failed.\n");
-        goto exit;
+		goto exit;
+	}
+
+	if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
+	{
+		NXP_LOG_WARNING("Fail-Stop mode disabled\n");
+		addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_FAIL_STOP_MODE_INT_EN + (addr_t)(pfe.cbus_baseaddr));
+		hal_write32(0x0, addr);
+		addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_FAIL_STOP_MODE_EN + (addr_t)(pfe.cbus_baseaddr));
+		hal_write32(0x0, addr);
+		addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_ECC_ERR_INT_EN + (addr_t)(pfe.cbus_baseaddr));
+		hal_write32(0x0, addr);
 	}
 
 	/*	Initialize LMEM TODO: Get LMEM size from global WSP_LMEM_SIZE register */
@@ -3006,7 +3135,7 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 
 	/* Initialize the FW features */
 	ret = pfe_feature_mgr_add_modules(pfe.classifier, pfe.util, pfe.tmu);
-    if (EOK != ret)
+	if (EOK != ret)
 	{
 		goto exit;
 	}
@@ -3081,13 +3210,13 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 	{
 		uint8_t flg = 0U;
 
-#ifndef PFE_CFG_MULTI_INSTANCE_SUPPORT
+#ifndef PFE_CFG_ERR051211_WORKAROUND_ENABLE
 		/*	Deactivate in non Master-Slave build */
 		if (EOK != pfe_feature_mgr_set_val("err051211_workaround", 0U))
 		{
 			NXP_LOG_WARNING("Error disabling err051211_workaround feature\n");
 		}
-#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
+#endif /* PFE_CFG_ERR051211_WORKAROUND_ENABLE */
 
 		ret = pfe_feature_mgr_get_val("err051211_workaround", &flg);
 		if (EOK == ret)
@@ -3102,7 +3231,8 @@ errno_t pfe_platform_init(const pfe_platform_config_t *config)
 		/* Check HIF RX Ring size in relation to err051211_workaround. */
 		if (PFE_HIF_RX_RING_CFG_LENGTH < PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH)
 		{
-			NXP_LOG_WARNING("HIF RX Rings are too small for FW feature err051211_workaround to fully work. The feature requires HIF RX Rings with at least %u slots, but rings currently have only %u slots.",
+			NXP_LOG_WARNING("HIF RX Rings are too small for FW feature err051211_workaround to fully work.");
+			NXP_LOG_WARNING("The feature requires HIF RX Rings with at least %u slots, but rings currently have only %u slots.",
 							(uint_t)PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH, (uint_t)PFE_HIF_RX_RING_CFG_LENGTH);
 		}
 	}
@@ -3217,7 +3347,7 @@ static void pfe_platform_destroy_group2(void)
 	pfe_spd_acc_destroy(pfe.phy_if_db);
 #endif
 	pfe_platform_destroy_ifaces(&pfe);
-    pfe_mirror_deinit();
+	pfe_mirror_deinit();
 	pfe_platform_destroy_class(&pfe);
 	pfe_platform_destroy_util(&pfe);
 	pfe_platform_destroy_tmu(&pfe);
@@ -3267,7 +3397,7 @@ errno_t pfe_platform_remove(void)
 		}
 	}
 
-	pfe.cbus_baseaddr = 0x0ULL;
+	pfe.cbus_baseaddr = (addr_t)0x0ULL;
 	pfe.probed = FALSE;
 
 	return EOK;
diff --git a/sw/pfe_platform/hw/s32g/pfe_platform_slave.c b/sw/pfe_platform/hw/s32g/pfe_platform_slave.c
index 7d150da..3ffb91a 100644
--- a/sw/pfe_platform/hw/s32g/pfe_platform_slave.c
+++ b/sw/pfe_platform/hw/s32g/pfe_platform_slave.c
@@ -442,7 +442,7 @@ static errno_t pfe_platform_create_fci(pfe_platform_t *platform)
 {
 	errno_t ret = EOK;
 
-	ret = fci_init(NULL, "pfe_fci");
+	ret = fci_init(NULL, "pfe_fci_slave");
 	if (EOK != ret)
 	{
 		NXP_LOG_ERROR("Could not create the FCI endpoint\n");
diff --git a/sw/pfe_platform/hw/s32g/pfe_tmu_csr.c b/sw/pfe_platform/hw/s32g/pfe_tmu_csr.c
index 09409f1..47f6817 100644
--- a/sw/pfe_platform/hw/s32g/pfe_tmu_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_tmu_csr.c
@@ -86,9 +86,9 @@ void pfe_tmu_reclaim_init(addr_t cbus_base_va)
 	hal_write32(0x1U, cbus_base_va + TMU_CNTX_ACCESS_CTRL);
 
 	/*	Initialize queues */
-	for (ii=0U; ii < TLITE_PHYS_CNT; ii++)
+	for (ii = 0U; ii < (uint32_t)TLITE_PHYS_CNT; ii++)
 	{
-		for (queue=0U; queue<TLITE_PHY_QUEUES_CNT; queue++)
+		for (queue = 0U; queue < (uint8_t)TLITE_PHY_QUEUES_CNT; queue++)
 		{
 			hal_write32(((ii & 0x1fUL) << 8U) | ((uint32_t)queue & 0x7UL), cbus_base_va + TMU_PHY_QUEUE_SEL);
 			hal_nop();
@@ -115,7 +115,7 @@ void pfe_tmu_reclaim_init(addr_t cbus_base_va)
 		}
 
 		/* Initialize internal TMU FIFO (length is hard coded in verilog)*/
-		for(ii = 0U; ii < TLITE_INQ_FIFODEPTH; ii++)
+		for(ii = 0U; ii < (uint32_t)TLITE_INQ_FIFODEPTH; ii++)
 		{
 			hal_write32(0UL, cbus_base_va + TMU_PHY_INQ_PKTINFO);
 		}
@@ -147,20 +147,21 @@ errno_t pfe_tmu_q_reset_tail_drop_policy(addr_t cbus_base_va)
 	uint32_t ii;
 	errno_t ret;
 
-	for (ii = 0U; ii < TLITE_PHYS_CNT; ii++)
+	for (ii = 0U; ii < (uint32_t)TLITE_PHYS_CNT; ii++)
 	{
-		if (PFE_PHY_IF_ID_EMAC2 >= ii)
-		{   /* EMACs - for endpoint performance improvement */
-			ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], 0, TLITE_OPT_Q0_SIZE);
+		if ((uint32_t)PFE_PHY_IF_ID_EMAC2 >= ii)
+		{
+            /* EMACs - for endpoint performance improvement */
+			ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], 0U, TLITE_OPT_Q0_SIZE);
 			if (EOK != ret)
 			{
 				NXP_LOG_ERROR("Can't set the default queue size for PHY#%u queue 0: %d\n", (uint_t)ii, (int_t)ret);
 				return ret;
 			}
 
-			for (queue = 1U; queue < TLITE_PHY_QUEUES_CNT; queue++)
+			for (queue = 1U; queue < (uint8_t)TLITE_PHY_QUEUES_CNT; queue++)
 			{
-				ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, TLITE_OPT_Q1_7_SIZE);
+				ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, (uint16_t)TLITE_OPT_Q1_7_SIZE);
 				if (EOK != ret)
 				{
 					NXP_LOG_ERROR("Can't set the default queue size for PHY#%u queue %hhu: %d\n", (uint_t)ii, queue, (int_t)ret);
@@ -168,7 +169,7 @@ errno_t pfe_tmu_q_reset_tail_drop_policy(addr_t cbus_base_va)
 				}
 			}
 		}
-		else if(PFE_PHY_IF_ID_HIF == ii)
+		else if((uint32_t)PFE_PHY_IF_ID_HIF == ii)
 		{   /* HIF - special case for ERR051211 workaround */
 			for (queue = 0U; queue < TLITE_PHY_QUEUES_CNT; queue++)
 			{
@@ -182,9 +183,9 @@ errno_t pfe_tmu_q_reset_tail_drop_policy(addr_t cbus_base_va)
 		}
 		else
 		{   /* Other: UTIL, HIF_NOCPY */
-			for (queue = 0U; queue < TLITE_PHY_QUEUES_CNT; queue++)
+			for (queue = 0U; queue < (uint8_t)TLITE_PHY_QUEUES_CNT; queue++)
 			{
-				ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, TLITE_MAX_Q_SIZE);
+				ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, (uint16_t)TLITE_MAX_Q_SIZE);
 				if (EOK != ret)
 				{
 					NXP_LOG_ERROR("Can't set the default queue size for PHY#%u queue %hhu: %d\n", (uint_t)ii, queue, (int_t)ret);
@@ -236,7 +237,7 @@ errno_t pfe_tmu_cfg_init(addr_t cbus_base_va, const pfe_tmu_cfg_t *cfg)
 	hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + UTIL_INQ_PKTPTR, cbus_base_va + TMU_PHY5_INQ_ADDR); /* UTIL */
 
 	/*	Context memory initialization */
-	for (ii=0U; ii < TLITE_PHYS_CNT; ii++)
+	for (ii = 0U; ii < (uint32_t)TLITE_PHYS_CNT; ii++)
 	{
 		/* NOTE: Do not access the direct registers here it may result in bus fault.*/
 
@@ -255,7 +256,7 @@ errno_t pfe_tmu_cfg_init(addr_t cbus_base_va, const pfe_tmu_cfg_t *cfg)
 			 - Scheduler 0 is not used
 			 - Queue[n]->SCH1.input[n]
 		*/
-		for (queue=0U; queue<TLITE_PHY_QUEUES_CNT; queue++)
+		for (queue = 0U; queue < (uint8_t)TLITE_PHY_QUEUES_CNT; queue++)
 		{
 			/*	Scheduler 1 */
 			ret = pfe_tmu_sch_cfg_bind_queue(cbus_base_va, phy_if_id_temp[ii], 1U, queue, queue);
@@ -281,9 +282,9 @@ errno_t pfe_tmu_cfg_init(addr_t cbus_base_va, const pfe_tmu_cfg_t *cfg)
 		}
 
 		/*	Set default queue mode */
-		for (queue=0U; queue<TLITE_PHY_QUEUES_CNT; queue++)
+		for (queue = 0U; queue < (uint8_t)TLITE_PHY_QUEUES_CNT; queue++)
 		{
-			if(PFE_PHY_IF_ID_HIF == ii)
+			if((uint32_t)PFE_PHY_IF_ID_HIF == ii)
 			{   /* HIF - special case for ERR051211 workaround */
 				ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, TLITE_HIF_MAX_Q_SIZE);
 			}
@@ -797,7 +798,7 @@ errno_t pfe_tmu_q_mode_set_tail_drop(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy
 	}
 
 	/*	curQ_Qmax[8:0], curQ_Qmin[8:0], curQ_cfg[1:0] are @ position 4 per queue */
-	reg = ((uint32_t)max << 11U) | ((uint32_t)0U << 2U) | ((uint32_t)0x1U << 0U);
+	reg = ((uint32_t)max << (uint32_t)11U) | ((uint32_t)0U << (uint32_t)2U) | ((uint32_t)0x1U << 0U);
 	return pfe_tmu_cntx_mem_write(cbus_base_va, phy, (8U * queue_temp) + 4U, reg);
 }
 
diff --git a/sw/pfe_platform/hw/s32g/pfe_tmu_csr.h b/sw/pfe_platform/hw/s32g/pfe_tmu_csr.h
index 3a7cb7f..1c8cb31 100644
--- a/sw/pfe_platform/hw/s32g/pfe_tmu_csr.h
+++ b/sw/pfe_platform/hw/s32g/pfe_tmu_csr.h
@@ -197,12 +197,14 @@
 #define TLITE_INQ_FIFODEPTH		256U
 
 /* Max number of buffers in ALL queues for one phy is 255, queues are 8 */
-#define TLITE_MAX_ENTRIES		(TLITE_INQ_FIFODEPTH - 1)
-#define TLITE_MAX_Q_SIZE		(TLITE_MAX_ENTRIES / 8)
-#define TLITE_HIF_MAX_Q_SIZE	16 /* Agreed default hardcoded value for ERR051211 workaround */
-#define TLITE_HIF_MAX_ENTRIES	(2 * TLITE_HIF_MAX_Q_SIZE)
+
+#define TLITE_MAX_ENTRIES		(TLITE_INQ_FIFODEPTH - 1U)
+#define TLITE_MAX_Q_SIZE		((uint16_t)TLITE_MAX_ENTRIES / 8U)
+#define TLITE_HIF_MAX_Q_SIZE	16U /* Agreed default hardcoded value for ERR051211 workaround */
+#define TLITE_HIF_MAX_ENTRIES	(2U * TLITE_HIF_MAX_Q_SIZE)
+
 #define TLITE_OPT_Q0_SIZE		150U /* optimal size for the default queue (q0) */
-#define TLITE_OPT_Q1_7_SIZE		((TLITE_MAX_ENTRIES - TLITE_OPT_Q0_SIZE) / 8)
+#define TLITE_OPT_Q1_7_SIZE		((uint16_t)((uint16_t)TLITE_MAX_ENTRIES - TLITE_OPT_Q0_SIZE) / 8U)
 
 /*	Implementation of the pfe_tmu_phy_cfg_t */
 struct pfe_tmu_phy_cfg_tag
diff --git a/sw/pfe_platform/public/pfe_gpi.h b/sw/pfe_platform/public/pfe_gpi.h
index 2caee2b..bac72b5 100644
--- a/sw/pfe_platform/public/pfe_gpi.h
+++ b/sw/pfe_platform/public/pfe_gpi.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -30,7 +30,7 @@ typedef enum __attribute__((packed))
 
     PFE_IQOS_FLOW_TYPE_MAX = PFE_IQOS_FLOW_TYPE_VLAN,
     /* Ensure proper size */
-    PFE_IQOS_FLOW_TYPE_MAX_ = (uint16_t)(1U << 15U)
+    PFE_IQOS_FLOW_TYPE_RESERVED = (uint16_t)(1U << 15U)
 } pfe_iqos_flow_type_t;
 ct_assert(sizeof(pfe_iqos_flow_type_t) == sizeof(uint16_t));
 
@@ -47,7 +47,7 @@ typedef enum __attribute__((packed))
 
     PFE_IQOS_ARG_MAX = PFE_IQOS_ARG_DPORT,
     /* Ensure proper size */
-    PFE_IQOS_ARG_MAX_ = (uint16_t)(1U << 15U)
+    PFE_IQOS_ARG_RESERVED = (uint16_t)(1U << 15U)
 } pfe_iqos_flow_arg_type_t;
 ct_assert(sizeof(pfe_iqos_flow_arg_type_t) == sizeof(uint16_t));
 
diff --git a/sw/pfe_platform/public/pfe_hif_ring_linux.h b/sw/pfe_platform/public/pfe_hif_ring_linux.h
index 457114d..882751f 100644
--- a/sw/pfe_platform/public/pfe_hif_ring_linux.h
+++ b/sw/pfe_platform/public/pfe_hif_ring_linux.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -12,7 +12,7 @@
 
 typedef struct pfe_hif_ring_tag pfe_hif_ring_t;
 
-pfe_hif_ring_t *pfe_hif_ring_create(bool_t rx, uint16_t seqnum, bool_t nocpy) __attribute__((cold));
+pfe_hif_ring_t *pfe_hif_ring_create(bool_t rx, bool_t nocpy) __attribute__((cold));
 uint32_t pfe_hif_ring_get_len(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
 errno_t pfe_hif_ring_destroy(pfe_hif_ring_t *ring) __attribute__((cold));
 void *pfe_hif_ring_get_base_pa(const pfe_hif_ring_t *ring) __attribute__((pure, cold));
diff --git a/sw/pfe_platform/public/pfe_idex.h b/sw/pfe_platform/public/pfe_idex.h
index e1bc3fd..d309353 100644
--- a/sw/pfe_platform/public/pfe_idex.h
+++ b/sw/pfe_platform/public/pfe_idex.h
@@ -26,8 +26,11 @@ typedef void (*pfe_idex_tx_conf_free_cbk_t)(void *frame);
 
 errno_t pfe_idex_init(pfe_hif_drv_t *hif_drv, pfe_ct_phy_if_id_t master, pfe_hif_t *hif, pfe_idex_rpc_cbk_t cbk, void *arg, pfe_idex_tx_conf_free_cbk_t txcf_cbk);
 errno_t pfe_idex_rpc(pfe_ct_phy_if_id_t dst_phy, uint32_t id, const void *buf, uint16_t buf_len, void *resp, uint16_t resp_len);
-errno_t pfe_idex_master_rpc(uint32_t id, void *buf, uint16_t buf_len, void *resp, uint16_t resp_len);
+errno_t pfe_idex_master_rpc(uint32_t id, const void *buf, uint16_t buf_len, void *resp, uint16_t resp_len);
 errno_t pfe_idex_set_rpc_ret_val(errno_t retval, void *resp, uint16_t resp_len);
 void pfe_idex_fini(void);
+#if (defined(PFE_CFG_TARGET_OS_AUTOSAR) && (FALSE == PFE_CFG_HIF_IRQ_ENABLED))
+void pfe_idex_ihc_poll(void);
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR && PFE_CFG_HIF_IRQ_ENABLED */
 
 #endif /* PUBLIC_PFE_IDEX_H_ */
diff --git a/sw/pfe_platform/public/pfe_l2br.h b/sw/pfe_platform/public/pfe_l2br.h
index 4d7ab42..3e40cb2 100644
--- a/sw/pfe_platform/public/pfe_l2br.h
+++ b/sw/pfe_platform/public/pfe_l2br.h
@@ -48,6 +48,7 @@ errno_t pfe_l2br_domain_set_ucast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_
 errno_t pfe_l2br_domain_set_mcast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t hit, pfe_ct_l2br_action_t miss);
 errno_t pfe_l2br_domain_add_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *iface, bool_t tagged);
 errno_t pfe_l2br_domain_del_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface);
+errno_t pfe_l2br_domain_flush_by_if(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface);
 pfe_phy_if_t *pfe_l2br_domain_get_first_if(pfe_l2br_domain_t *domain, pfe_l2br_domain_if_get_crit_t crit, void *arg);
 pfe_phy_if_t *pfe_l2br_domain_get_next_if(pfe_l2br_domain_t *domain);
 errno_t pfe_l2br_domain_get_vlan(const pfe_l2br_domain_t *domain, uint16_t *vlan);
diff --git a/sw/pfe_platform/public/pfe_platform_rpc.h b/sw/pfe_platform/public/pfe_platform_rpc.h
index 243129c..9a1b5d1 100644
--- a/sw/pfe_platform/public/pfe_platform_rpc.h
+++ b/sw/pfe_platform/public/pfe_platform_rpc.h
@@ -43,7 +43,11 @@ typedef enum __attribute__((packed))
 	PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE = 115U,		/* Arg: pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE = 116U,             /* Arg: pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE = 117U,            /* Arg: pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t, Ret: None */
-	PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_LAST = PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE, /* last entry compatible with generic phy_if structure for args*/
+	PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE = 118U,          /* Arg: pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t, Ret: None */
+	PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE = 119U,         /* Arg: pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t, Ret: None */
+	PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE = 120U,				/* Arg: pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t, Ret: None */
+	PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE = 121U,				/* Arg: pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t */
+	PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_LAST = PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE, /* last entry compatible with generic phy_if structure for args*/
 
 	/* Lock for atomic operations */
 	PFE_PLATFORM_RPC_PFE_IF_LOCK = 190U,						/* Arg: None, Ret: None */
@@ -67,7 +71,7 @@ typedef enum __attribute__((packed))
 	PFE_PLATFORM_RPC_PFE_LOG_IF_PROMISC_ENABLE = 213U,		/* Arg: pfe_platform_rpc_pfe_log_if_promisc_enable_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_PROMISC_DISABLE = 214U,		/* Arg: pfe_platform_rpc_pfe_log_if_promisc_disable_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_IS_PROMISC = 215U,			/* Arg: pfe_platform_rpc_pfe_log_if_is_promisc_arg_t, Ret: pfe_platform_rpc_pfe_log_if_is_enabled_ret_t */
-	PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS = 216U,			/* Arg: pfe_platform_rpc_pfe_log_if_get_egress_arg_t, Ret: pfe_platform_rpc_pfe_log_if_get_egress_ret_t */
+	PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS_IFS = 216U,		/* Arg: pfe_platform_rpc_pfe_log_if_get_egress_ifs_arg_t, Ret: pfe_platform_rpc_pfe_log_if_get_egress_ifs_ret_t */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_IS_MATCH_OR = 217U,			/* Arg: pfe_platform_rpc_pfe_log_if_is_match_or_arg_t, Ret: pfe_platform_rpc_pfe_log_if_is_match_or_ret_t */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_SET_MATCH_OR = 218U,		/* Arg: pfe_platform_rpc_pfe_log_if_set_match_or_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_SET_MATCH_AND = 219U,		/* Arg: pfe_platform_rpc_pfe_log_if_set_match_andr_arg_t, Ret: None */
@@ -80,7 +84,10 @@ typedef enum __attribute__((packed))
 	PFE_PLATFORM_RPC_PFE_LOG_IF_IS_DISCARD = 226U,			/* Arg: pfe_platform_rpc_pfe_log_if_is_discard_arg_t, Ret: pfe_platform_rpc_pfe_log_if_is_discard_ret_t */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_DISCARD_ENABLE = 227U,		/* Arg: pfe_platform_rpc_pfe_log_if_discard_enable_arg_t, Ret: None */
 	PFE_PLATFORM_RPC_PFE_LOG_IF_DISCARD_DISABLE = 228U,		/* Arg: pfe_platform_rpc_pfe_log_if_discard_disable_arg_t, Ret: None */
-	PFE_PLATFORM_RPC_PFE_LOG_IF_ID_COMPATIBLE_LAST = PFE_PLATFORM_RPC_PFE_LOG_IF_DISCARD_DISABLE, /* last entry compatible with generic log_if structure for args*/
+	PFE_PLATFORM_RPC_PFE_LOG_IF_SET_EGRESS_IFS = 229U,		/* Arg: pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t, Ret: None */
+	PFE_PLATFORM_RPC_PFE_LOG_IF_IS_LOOPBACK = 230U,			/* Arg: pfe_platform_rpc_pfe_log_if_is_loopback_arg_t, Ret: pfe_platform_rpc_pfe_log_if_is_loopback_ret_t */
+
+	PFE_PLATFORM_RPC_PFE_LOG_IF_ID_COMPATIBLE_LAST = PFE_PLATFORM_RPC_PFE_LOG_IF_IS_LOOPBACK, /* last entry compatible with generic log_if structure for args*/
 
 #if defined(PFE_CFG_FCI_ENABLE)
 	PFE_PLATFORM_RPC_PFE_FCI_PROXY = 300U					/* Arg: pfe_platform_rpc_pfe_fci_proxy_arg_t, Ret: pfe_platform_rpc_pfe_fci_proxy_ret_t */
@@ -139,8 +146,8 @@ typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_promis
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_promisc_disable_arg_t, log_if_id));
 typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_is_promisc_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_is_promisc_arg_t, log_if_id));
-typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_get_egress_arg_t;
-ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_get_egress_arg_t, log_if_id));
+typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_get_egress_ifs_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_get_egress_ifs_arg_t, log_if_id));
 typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_is_match_or_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_is_match_or_arg_t, log_if_id));
 typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_set_match_and_arg_t;
@@ -163,6 +170,8 @@ typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_is_dis
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_is_discard_arg_t, log_if_id));
 typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_loopback_disable_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_loopback_disable_arg_t, log_if_id));
+typedef pfe_platform_rpc_pfe_log_if_generic_t pfe_platform_rpc_pfe_log_if_is_loopback_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_is_loopback_arg_t, log_if_id));
 
 typedef struct __attribute__((packed, aligned(4)))
 {
@@ -183,6 +192,7 @@ typedef pfe_platform_rpc_pfe_log_if_is_enabled_ret_t pfe_platform_rpc_pfe_log_if
 typedef pfe_platform_rpc_pfe_log_if_is_enabled_ret_t pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t;
 typedef pfe_platform_rpc_pfe_log_if_is_enabled_ret_t pfe_platform_rpc_pfe_phy_if_is_enabled_ret_t;
 typedef pfe_platform_rpc_pfe_log_if_is_enabled_ret_t pfe_platform_rpc_pfe_log_if_is_discard_ret_t;
+typedef pfe_platform_rpc_pfe_log_if_is_enabled_ret_t pfe_platform_rpc_pfe_log_if_is_loopback_ret_t;
 
 typedef struct __attribute__((packed, aligned(4)))
 {
@@ -247,6 +257,8 @@ typedef struct __attribute__((packed, aligned(4)))
 } pfe_platform_rpc_pfe_log_if_add_egress_if_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_add_egress_if_arg_t, log_if_id));
 
+typedef pfe_platform_rpc_pfe_log_if_add_egress_if_arg_t pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t, log_if_id));
 typedef pfe_platform_rpc_pfe_log_if_add_egress_if_arg_t pfe_platform_rpc_pfe_log_if_del_egress_if_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_log_if_del_egress_if_arg_t, log_if_id));
 
@@ -284,6 +296,12 @@ typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loo
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t, phy_if_id));
 typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t, phy_if_id));
+typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t, phy_if_id));
+typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t, phy_if_id));
+typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t, phy_if_id));
 
 typedef struct __attribute__((packed, aligned(4)))
 {
@@ -314,6 +332,15 @@ typedef struct __attribute__((packed, aligned(4)))
 } pfe_platform_rpc_pfe_phy_if_set_op_mode_arg_t;
 ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_set_op_mode_arg_t, phy_if_id));
 
+typedef struct __attribute__((packed, aligned(4)))
+{
+	/* Physical interface ID */
+	pfe_ct_phy_if_id_t phy_if_id;
+	/* Block state */
+	pfe_ct_block_state_t block_state;
+} pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t;
+ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t, phy_if_id));
+
 typedef struct __attribute__((packed, aligned(4)))
 {
 	/*	Physical interface ID */
@@ -327,14 +354,20 @@ typedef struct __attribute__((packed, aligned(4)))
 {
 	/*	Mask of egress interfaces */
 	uint32_t egress;
-} pfe_platform_rpc_pfe_log_if_get_egress_ret_t;
+} pfe_platform_rpc_pfe_log_if_get_egress_ifs_ret_t;
 
-typedef struct __attribute__((packed, aligned(4))) pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t
+typedef struct __attribute__((packed, aligned(4)))
 {
 	/*	Current operation mode */
 	pfe_ct_if_op_mode_t mode;
 } pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t;
 
+typedef struct __attribute__((packed, aligned(4)))
+{
+	/* Current block state */
+	pfe_ct_block_state_t state;
+} pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t;
+
 typedef struct __attribute__((packed, aligned(4)))
 {
 	/*	Current phy if statistics */
diff --git a/sw/pfe_platform/public/pfe_rtable.h b/sw/pfe_platform/public/pfe_rtable.h
index 4618871..e0e0d16 100644
--- a/sw/pfe_platform/public/pfe_rtable.h
+++ b/sw/pfe_platform/public/pfe_rtable.h
@@ -138,6 +138,6 @@ errno_t pfe_rtable_entry_get_id5t(const pfe_rtable_entry_t *entry, uint32_t *id5
 errno_t pfe_rtable_entry_set_dstif_id(pfe_rtable_entry_t *entry, pfe_ct_phy_if_id_t if_id);
 
 void pfe_rtable_do_timeouts(pfe_rtable_t *rtable);
-uint32_t pfe_rtable_get_text_statistics(pfe_rtable_t *rtable, char_t *buf, uint32_t buf_len, uint8_t verb_level);
-
+uint32_t pfe_rtable_get_text_statistics(const pfe_rtable_t *rtable, char_t *buf, uint32_t buf_len, uint8_t verb_level);
+errno_t pfe_rtable_get_stats(const pfe_rtable_t *rtable, pfe_ct_conntrack_stats_t *stat, uint8_t conntrack_index);
 #endif /* PUBLIC_PFE_RTABLE_H_ */
diff --git a/sw/pfe_platform/src/pfe_class.c b/sw/pfe_platform/src/pfe_class.c
index a7ca0be..27cca44 100644
--- a/sw/pfe_platform/src/pfe_class.c
+++ b/sw/pfe_platform/src/pfe_class.c
@@ -64,6 +64,7 @@ errno_t pfe_class_isr(const pfe_class_t *class)
 #ifdef PFE_CFG_FCI_ENABLE
 	pfe_ct_buffer_t buf;
 	fci_msg_t msg;
+	errno_t ret;
 #endif /* PFE_CFG_FCI_ENABLE */
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -101,7 +102,8 @@ errno_t pfe_class_isr(const pfe_class_t *class)
 			else
 			{
 				(void)memcpy(&msg.msg_cmd.payload, buf.payload, buf.len);
-				if (EOK != fci_core_client_send_broadcast(&msg, NULL))
+				ret = fci_core_client_send_broadcast(&msg, NULL);
+				if (EOK != ret)
 				{
 					NXP_LOG_ERROR("Can't report data to FCI clients\n");
 				}
@@ -1233,7 +1235,7 @@ errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat)
 	pfe_ct_pe_mmap_t mmap;
 	uint32_t i = 0U, j = 0U;
 	errno_t ret = EOK;
-	uint32_t buff_len = 0;
+	uint32_t buff_len = 0U;
 	pfe_ct_classify_stats_t * stats = NULL;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
@@ -1274,7 +1276,8 @@ errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat)
 		pfe_class_alg_stats_endian(&stats[i].ip_router);
 		pfe_class_alg_stats_endian(&stats[i].vlan_bridge);
 		pfe_class_alg_stats_endian(&stats[i].log_if);
-		for (j = 0; j < PFE_PHY_IF_ID_MAX + 1; j++)
+
+		for (j = 0U; j < ((uint32_t)PFE_PHY_IF_ID_MAX + 1U); j++)
 		{
 			pfe_class_ihc_stats_endian(&stats[i].hif_to_hif[j]);
 		}
@@ -1284,7 +1287,8 @@ errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat)
 		pfe_class_sum_pe_algo_stats(&stat->ip_router, &stats[i].ip_router);
 		pfe_class_sum_pe_algo_stats(&stat->vlan_bridge, &stats[i].vlan_bridge);
 		pfe_class_sum_pe_algo_stats(&stat->log_if, &stats[i].log_if);
-		for (j = 0; j < PFE_PHY_IF_ID_MAX + 1; j++)
+
+		for (j = 0U; j < ((uint32_t)PFE_PHY_IF_ID_MAX + 1U); j++)
 		{
 			pfe_class_sum_pe_ihc_stats(&stat->hif_to_hif[j], &stats[i].hif_to_hif[j]);
 		}
@@ -1303,20 +1307,6 @@ errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat)
                           |((uint32_t)1U << (uint32_t)PFE_PHY_IF_ID_HIF3)\
                           |((uint32_t)1U << (uint32_t)PFE_PHY_IF_ID_HIF_NOCPY))
 
-char_t phyif_name[][20] =
-{
-        "EMAC0",
-        "EMAC1",
-        "EMAC2",
-        "HIF",
-        "HIF_NOCPY",
-        "UTIL",
-        "HIF0",
-        "HIF1",
-        "HIF2",
-        "HIF3"
-};
-
 /**
  * @brief		Return CLASS runtime statistics in text form
  * @details		Function writes formatted text into given buffer.
@@ -1336,6 +1326,19 @@ uint32_t pfe_class_get_text_statistics(pfe_class_t *class, char_t *buf, uint32_t
 	pfe_ct_pe_stats_t *pe_stats;
 	pfe_ct_classify_stats_t c_alg_stats;
 	pfe_ct_version_t fw_ver;
+	char_t phyif_name[][20] =
+	{
+        "EMAC0",
+        "EMAC1",
+        "EMAC2",
+        "HIF",
+        "HIF_NOCPY",
+        "UTIL",
+        "HIF0",
+        "HIF1",
+        "HIF2",
+        "HIF3"
+	};
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely(NULL == class))
@@ -1489,9 +1492,10 @@ uint32_t pfe_class_get_text_statistics(pfe_class_t *class, char_t *buf, uint32_t
 	len += oal_util_snprintf(buf + len, buf_len - len, "- Global Flexible filter -\n");
 	len += pfe_class_fp_stat_to_str(&c_alg_stats.flexible_filter, buf + len, buf_len - len, verb_level);
 	len += oal_util_snprintf(buf + len, buf_len - len, "- InterHIF -\n");
-	for (j = 0; j < PFE_PHY_IF_ID_MAX + 1; j++)
+
+	for (j = 0U; j < ((uint32_t)PFE_PHY_IF_ID_MAX + 1U); j++)
 	{
-		if ( ((uint32_t)(1 << j)) & HIF_CHANNELS_MASK)
+		if (0U != (((uint32_t)1U << j) & (uint32_t)HIF_CHANNELS_MASK))
 		{
 			len += oal_util_snprintf(buf + len, buf_len - len, "Interface: %s\n", phyif_name[j]);
 			len += pfe_class_ihc_stat_to_str(&c_alg_stats.hif_to_hif[j], buf + len, buf_len - len, verb_level);
diff --git a/sw/pfe_platform/src/pfe_feature_mgr.c b/sw/pfe_platform/src/pfe_feature_mgr.c
index 1d178fb..6a1ce39 100644
--- a/sw/pfe_platform/src/pfe_feature_mgr.c
+++ b/sw/pfe_platform/src/pfe_feature_mgr.c
@@ -25,7 +25,11 @@
 |FCI|----uses-------------/    |                 ----------             |  |
 -----                          |                                        V  V
                                |                                     ----------------
-                               \------------------------------uses-->|pfe_fw_feature|
+                               |------------------------------uses-->|pfe_fw_feature|
+                               |                                     ----------------
+                               |
+                               |                                     ----------------
+                               \------------------------------uses-->|pfe_hw_feature|
                                                                      ----------------
 */
 
@@ -793,12 +797,14 @@ errno_t pfe_feature_mgr_get_def_val(const char *feature_name, uint8_t *val)
 
 	/* The data shall be consistent between util and class thus it is enough to read
 	   them from class */
-	if(EOK == pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name))
+	   
+	ret = pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name);
+	if(EOK == ret)
 	{
 		ret = pfe_fw_feature_get_def_val(fw_feature_class, val);
 	}
 
-	return ret;
+	return ret;   
 }
 
 /**
@@ -841,12 +847,13 @@ errno_t pfe_feature_mgr_get_desc(const char *feature_name, const char **desc)
 
 	/* The data shall be consistent between util and class thus it is enough to read
 	   them from class */
-	if(EOK == pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name))
+	ret = pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name);
+	if(EOK == ret)
 	{
 		ret = pfe_fw_feature_get_desc(fw_feature_class, desc);
 	}
-
-	return ret;
+	
+	return ret; 
 }
 
 /**
@@ -894,7 +901,8 @@ errno_t pfe_feature_mgr_get_variant(const char *feature_name, uint8_t *val)
 
 	/* The data shall be consistent between util and class thus it is enough to read
 	   them from class */
-	if(EOK == pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name))
+	ret = pfe_class_get_feature(feature_mgr->class, &fw_feature_class, feature_name);
+	if(EOK == ret)
 	{
 		ret = pfe_fw_feature_get_flags(fw_feature_class, &tmp);
 		if(EOK == ret)
@@ -902,7 +910,7 @@ errno_t pfe_feature_mgr_get_variant(const char *feature_name, uint8_t *val)
 			*val = (uint8_t)tmp & ((uint8_t)F_PRESENT | (uint8_t)F_RUNTIME);
 		}
 	}
-
+	
 	return ret;
 }
 
diff --git a/sw/pfe_platform/src/pfe_gpi.c b/sw/pfe_platform/src/pfe_gpi.c
index e0a6de1..ac70df2 100644
--- a/sw/pfe_platform/src/pfe_gpi.c
+++ b/sw/pfe_platform/src/pfe_gpi.c
@@ -21,7 +21,7 @@
 	uint32_t name[SIZE]
 
 /* PFE uses the value of 32 to represent the 6 bit encoding of the IP address mask of 0 */
-#define IGQOS_IP_MASK_0 32
+#define IGQOS_IP_MASK_0 32U
 
 struct pfe_gpi_tag
 {
@@ -425,9 +425,9 @@ static uint8_t igqos_class_get_next_active(pfe_gpi_t *gpi)
  */
 static uint8_t igqos_ip_mask_hw_encode(uint8_t ip_m)
 {
-	if (0 != ip_m)
+	if (0U != ip_m)
 	{
-		return ip_m - 1;
+		return ip_m - 1U;
 	}
 	else
 	{
@@ -439,11 +439,11 @@ static uint8_t igqos_ip_mask_hw_decode(uint8_t ip_m)
 {
 	if (IGQOS_IP_MASK_0 != ip_m)
 	{
-		return ip_m + 1;
+		return ip_m + 1U;
 	}
 	else
 	{
-		return 0;
+		return 0U;
 	}
 }
 
@@ -491,8 +491,8 @@ static void igqos_convert_entry_to_flow(const uint32_t entry[], pfe_iqos_flow_sp
 	val = entry[6];
 	args->tos_m |= (uint8_t)entry_arg_get_upper(TOS_M, val);
 	args->l4proto_m = (uint8_t)entry_arg_get(PROT_M, val);
-	args->sip_m = igqos_ip_mask_hw_decode(entry_arg_get(SIP_M, val));
-	args->dip_m = igqos_ip_mask_hw_decode(entry_arg_get(DIP_M, val));
+	args->sip_m = igqos_ip_mask_hw_decode((uint8_t)entry_arg_get(SIP_M, val));
+	args->dip_m = igqos_ip_mask_hw_decode((uint8_t)entry_arg_get(DIP_M, val));
 
 	if (entry_arg_get(ACT_DROP, val) == 1U)
 	{
@@ -665,11 +665,11 @@ errno_t pfe_gpi_qos_get_flow(const pfe_gpi_t *gpi, uint8_t id, pfe_iqos_flow_spe
 	}
 	else
 	{
-		pfe_gpi_cfg_qos_read_flow_entry_req(gpi->gpi_base_va, id);
+		pfe_gpi_cfg_qos_rd_fl_entry_req(gpi->gpi_base_va, id);
 		ret = igqos_entry_ready_timeout(gpi);
 		if (ret == EOK)
 		{
-			pfe_gpi_cfg_qos_read_flow_entry_resp(gpi->gpi_base_va, class_table_entry);
+			pfe_gpi_cfg_qos_rd_fl_entry_resp(gpi->gpi_base_va, class_table_entry);
 			igqos_convert_entry_to_flow(class_table_entry, flow);
 		}
 	}
diff --git a/sw/pfe_platform/src/pfe_hif_chnl_linux.c b/sw/pfe_platform/src/pfe_hif_chnl_linux.c
index 2939db5..a8a442f 100644
--- a/sw/pfe_platform/src/pfe_hif_chnl_linux.c
+++ b/sw/pfe_platform/src/pfe_hif_chnl_linux.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -1872,7 +1872,6 @@ __attribute__((cold)) static errno_t pfe_hif_chnl_set_tx_ring(pfe_hif_chnl_t *ch
 static __attribute__((cold)) errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl)
 {
 	pfe_hif_ring_t *tx_ring, *rx_ring;
-	uint16_t seqnum;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely(NULL == chnl))
@@ -1899,14 +1898,7 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl)
 		goto free_and_fail;
 	}
 
-	/*	Get current valid RX ring sequence number */
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	seqnum = pfe_hif_chnl_cfg_get_rx_seqnum(chnl->cbus_base_va, chnl->id);
-	NXP_LOG_DEBUG("Using initial RX ring seqnum 0x%x\n", seqnum);
-#else
-	seqnum = 0U;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-	rx_ring = pfe_hif_ring_create(TRUE, seqnum, (PFE_HIF_CHNL_NOCPY_ID == chnl->id));
+	rx_ring = pfe_hif_ring_create(TRUE, (PFE_HIF_CHNL_NOCPY_ID == chnl->id));
 	if (NULL == rx_ring)
 	{
 		NXP_LOG_ERROR("Couldn't create RX BD ring\n");
@@ -1928,14 +1920,7 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl)
 		goto free_and_fail;
 	}
 
-	/*	Get current valid TX ring sequence number */
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	seqnum = pfe_hif_chnl_cfg_get_tx_seqnum(chnl->cbus_base_va, chnl->id);
-	NXP_LOG_DEBUG("Using initial TX ring seqnum 0x%x\n", seqnum);
-#else
-	seqnum = 0U;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-	tx_ring = pfe_hif_ring_create(FALSE, seqnum, (PFE_HIF_CHNL_NOCPY_ID == chnl->id));
+	tx_ring = pfe_hif_ring_create(FALSE, (PFE_HIF_CHNL_NOCPY_ID == chnl->id));
 	if (NULL == tx_ring)
 	{
 		NXP_LOG_ERROR("Couldn't create TX BD ring\n");
diff --git a/sw/pfe_platform/src/pfe_hif_ring_linux.c b/sw/pfe_platform/src/pfe_hif_ring_linux.c
index 6f7ece1..2838fde 100644
--- a/sw/pfe_platform/src/pfe_hif_ring_linux.c
+++ b/sw/pfe_platform/src/pfe_hif_ring_linux.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2021 NXP
+ *  Copyright 2018-2022 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -230,9 +230,6 @@ struct __attribute__((aligned (HAL_CACHE_LINE_SIZE), packed)) pfe_hif_ring_tag
 	/*	Every 'enqueue' and 'dequeue' access */
 	void *base_va;				/*	Ring base address (virtual) */
 	void *wb_tbl_base_va;		/*	Write-back table base address (virtual) */
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	uint16_t seqnum;			/*	Current sequence number */
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
 
 	/*	Every 'enqueue' access */
 	uint32_t write_idx;			/*	BD index to be written */
@@ -278,7 +275,7 @@ struct __attribute__((aligned (HAL_CACHE_LINE_SIZE), packed)) pfe_hif_ring_tag
 __attribute__((hot)) static inline void inc_write_index_std(pfe_hif_ring_t *ring);
 __attribute__((hot)) static inline void dec_write_index_std(pfe_hif_ring_t *ring);
 __attribute__((hot)) static inline void inc_read_index_std(pfe_hif_ring_t *ring);
-__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(uint16_t seqnum, bool_t rx);
+__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(bool_t rx);
 static inline errno_t pfe_hif_ring_enqueue_buf_std(pfe_hif_ring_t *ring, const void *buf_pa, uint32_t length, bool_t lifm);
 static inline errno_t pfe_hif_ring_dequeue_buf_std(pfe_hif_ring_t *ring, void **buf_pa, uint32_t *length, bool_t *lifm);
 static inline errno_t pfe_hif_ring_dequeue_plain_std(pfe_hif_ring_t *ring, bool_t *lifm);
@@ -286,7 +283,7 @@ __attribute__((cold)) static void pfe_hif_ring_invalidate_std(const pfe_hif_ring
 #if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
 __attribute__((hot)) static inline void inc_write_index_nocpy(pfe_hif_ring_t *ring);
 __attribute__((hot)) static inline void inc_read_index_nocpy(pfe_hif_ring_t *ring);
-__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_nocpy(uint16_t seqnum, bool_t rx);
+__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_nocpy(bool_t rx);
 static inline errno_t pfe_hif_ring_enqueue_buf_nocpy(pfe_hif_ring_t *ring, const void *buf_pa, uint32_t length, bool_t lifm);
 static inline errno_t pfe_hif_ring_dequeue_buf_nocpy(pfe_hif_ring_t *ring, void **buf_pa, uint32_t *length, bool_t *lifm);
 static inline errno_t pfe_hif_ring_dequeue_plain_nocpy(pfe_hif_ring_t *ring, bool_t *lifm);
@@ -631,14 +628,6 @@ static inline errno_t pfe_hif_ring_enqueue_buf_std(pfe_hif_ring_t *ring, const v
 			tmp_ctrl_seq_w0 &= ~HIF_RING_BD_W0_LIFM;
 		}
 
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-		/* Discard old SEQ */
-		tmp_ctrl_seq_w0 &= ~(HIF_RING_BD_W0_BD_SEQNUM_MASK << HIF_RING_BD_W0_BD_SEQNUM_OFFSET);
-		/* Set new SEQ counter */
-		tmp_ctrl_seq_w0 |= HIF_RING_BD_W0_BD_SEQNUM(ring->seqnum);
-		ring->seqnum++;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-
 #ifdef EQ_DQ_RX_DEBUG
 		if (ring->is_rx)
 		{
@@ -773,23 +762,14 @@ static inline errno_t pfe_hif_ring_dequeue_buf_std(pfe_hif_ring_t *ring, void **
 
 	/*	BD must be ENABLED. This indicates that SW has previously enqueued it. */
 	tmp_bd_ctrl_seq_w0 = ring->rd_bd->ctrl_seqnum_w0;
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	tmp_wb_bd_seq_buf_w1 = ring->rd_wb_bd->seqnum_buflen_w1;
-#endif
 
-	if (unlikely(0U == (tmp_bd_ctrl_seq_w0 & HIF_RING_BD_W0_DESC_EN))
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-		|| (HIF_RING_WB_BD_W1_WB_BD_BUFFLEN_GET(tmp_wb_bd_seq_buf_w1) != HIF_RING_BD_W0_BD_SEQNUM_GET(tmp_ctrl_seq_w0))
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-		)
+	if (unlikely(0U == (tmp_bd_ctrl_seq_w0 & HIF_RING_BD_W0_DESC_EN)))
 	{
 		return EAGAIN;
 	}
 	else
 	{
-#ifndef PFE_CFG_HIF_SEQNUM_CHECK
 		tmp_wb_bd_seq_buf_w1 = ring->rd_wb_bd->seqnum_buflen_w1;
-#endif
 
 		/*	1.) Process the BD data. */
 		*buf_pa = (void *)(addr_t)(ring->rd_bd->data);
@@ -908,9 +888,6 @@ static inline errno_t pfe_hif_ring_dequeue_plain_std(pfe_hif_ring_t *ring, bool_
 {
 	uint32_t tmp_bd_ctrl_seq_w0;
 	uint32_t tmp_wb_bd_ctrl_w0;
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	uint32_t tmp_wb_bd_seq_buf_w1;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely(NULL == ring))
@@ -932,16 +909,8 @@ static inline errno_t pfe_hif_ring_dequeue_plain_std(pfe_hif_ring_t *ring, bool_
 	/* Perform single read */
 	tmp_bd_ctrl_seq_w0 = ring->rd_bd->ctrl_seqnum_w0;
 
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	tmp_wb_bd_seq_buf_w1 = ring->rd_wb_bd->seqnum_buflen_w1;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-
 	/*	BD must be ENABLED. This indicates that SW has previously enqueued it. */
-	if ((0U == (tmp_bd_ctrl_seq_w0 & HIF_RING_BD_W0_DESC_EN))
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-		|| (HIF_RING_WB_BD_W1_WB_BD_BUFFLEN_GET(tmp_wb_bd_seq_buf_w1) != HIF_RING_BD_W0_BD_SEQNUM_GET(tmp_ctrl_seq_w0))
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-		)
+	if ((0U == (tmp_bd_ctrl_seq_w0 & HIF_RING_BD_W0_DESC_EN)))
 	{
 		return EAGAIN;
 	}
@@ -1031,9 +1000,6 @@ __attribute__((cold)) errno_t pfe_hif_ring_drain_buf(pfe_hif_ring_t *ring, void
 				*buf_pa = (void *)(addr_t)ring->wr_bd->data;
 				ring->wr_bd->ctrl_seqnum_w0 &= ~HIF_RING_BD_W0_DESC_EN;
 				ring->wr_wb_bd->rsvd_ctrl_w0 |= HIF_RING_WB_BD_W0_DESC_EN;
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-				ring->seqnum--;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
 				dec_write_index_std(ring);
 			}
 			else
@@ -1166,9 +1132,6 @@ __attribute__((cold)) uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *n
 	len += (uint32_t)oal_util_snprintf(buf + len, size - len, "Ring %s: len %d\n", name, RING_LEN);
 	len += (uint32_t)oal_util_snprintf(buf + len, size - len, "  Type: %s\n", ring->is_rx ? "RX" : "TX");
 	len += (uint32_t)oal_util_snprintf(buf + len, size - len, "  Index w/r: %d/%d (%d/%d)\n", ring->write_idx & RING_LEN_MASK, ring->read_idx & RING_LEN_MASK, ring->write_idx, ring->read_idx);
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	len += (uint32_t)oal_util_snprintf(buf + len, size - len, "  Seqn: 0x%x\n", ring->seqnum);
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
 
 	if(verb_level >= 8) {
 		/* BD ring */
@@ -1232,12 +1195,11 @@ __attribute__((cold)) uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *n
 /**
  * @brief		Create new PFE buffer descriptor ring
  * @param[in]	rx If TRUE the ring is RX, if FALSE the the ring is TX
- * @param[in]	seqnum Initial sequence number
  * @param[in]	nocpy If TRUE then ring will be treated as HIF NOCPY variant
  * @return		The new ring instance or NULL if the call has failed
  * @note		Must not be preempted by any of the remaining API functions
  */
-__attribute__((cold)) pfe_hif_ring_t *pfe_hif_ring_create(bool_t rx, uint16_t seqnum, bool_t nocpy)
+__attribute__((cold)) pfe_hif_ring_t *pfe_hif_ring_create(bool_t rx, bool_t nocpy)
 {
 #if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
 	if (TRUE == nocpy)
@@ -1248,12 +1210,12 @@ __attribute__((cold)) pfe_hif_ring_t *pfe_hif_ring_create(bool_t rx, uint16_t se
 #else
 	if (TRUE == nocpy)
 	{
-		return pfe_hif_ring_create_nocpy(seqnum, rx);
+		return pfe_hif_ring_create_nocpy(rx);
 	}
 	else
 #endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
 	{
-		return pfe_hif_ring_create_std(seqnum, rx);
+		return pfe_hif_ring_create_std(rx);
 	}
 }
 
@@ -1380,7 +1342,7 @@ free_and_fail:
 /**
  * @brief		The "standard" HIF variant
  */
-__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(uint16_t seqnum, bool_t rx)
+__attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(bool_t rx)
 {
 	pfe_hif_ring_t *ring;
 	uint32_t ii, size;
@@ -1389,10 +1351,6 @@ __attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(uint16_t se
 	char_t *variant_str;
 #endif /* PFE_CFG_VERBOSITY_LEVEL */
 
-#ifndef PFE_CFG_HIF_SEQNUM_CHECK
-	(void)seqnum;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-
 	/*	Allocate the ring structure */
 	ring = oal_mm_malloc_contig_aligned_cache(sizeof(pfe_hif_ring_t), HAL_CACHE_LINE_SIZE);
 	if (NULL == ring)
@@ -1444,10 +1402,6 @@ __attribute__((cold)) static pfe_hif_ring_t *pfe_hif_ring_create_std(uint16_t se
 
 	ring->base_pa = oal_mm_virt_to_phys_contig(ring->base_va);
 
-#ifdef PFE_CFG_HIF_SEQNUM_CHECK
-	ring->seqnum = seqnum;
-#endif /* PFE_CFG_HIF_SEQNUM_CHECK */
-
 	/*	Allocate memory for write-back descriptors */
 	size = RING_LEN * sizeof(pfe_hif_wb_bd_t);
 	ring->wb_tbl_base_va = oal_mm_malloc_contig_named_aligned_nocache(PFE_CFG_BD_MEM, size, ii);
diff --git a/sw/pfe_platform/src/pfe_hw_feature.c b/sw/pfe_platform/src/pfe_hw_feature.c
index 98c2623..cad6d94 100644
--- a/sw/pfe_platform/src/pfe_hw_feature.c
+++ b/sw/pfe_platform/src/pfe_hw_feature.c
@@ -73,7 +73,7 @@ errno_t pfe_hw_feature_init_all(const uint32_t *cbus_base, pfe_hw_feature_t **hw
 	if (NULL != feature)
 	{
 		/*      Detect S32G silicon version */
-		val = hal_read32((void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_VERSION + (addr_t)cbus_base));
+		val = hal_read32((addr_t)CBUS_GLOBAL_CSR_BASE_ADDR + (addr_t)WSP_VERSION + (addr_t)cbus_base);
 		if(0x00050300U == val)
 		{       /* S32G2 */
 			NXP_LOG_INFO("Silicon S32G2\n");
diff --git a/sw/pfe_platform/src/pfe_idex.c b/sw/pfe_platform/src/pfe_idex.c
index 7a4affb..46455d5 100644
--- a/sw/pfe_platform/src/pfe_idex.c
+++ b/sw/pfe_platform/src/pfe_idex.c
@@ -15,6 +15,14 @@
 #include "pfe_idex.h"
 #include "pfe_platform_cfg.h"
 
+#if defined(PFE_CFG_TARGET_OS_LINUX)
+    #define IDEX_IS_NOCPY FALSE
+#elif defined(PFE_CFG_TARGET_OS_QNX)
+    #define IDEX_IS_NOCPY (4 == PFE_CFG_LOCAL_IF)
+#else
+    #define IDEX_IS_NOCPY (4 == PFE_CFG_LOCAL_IF_VALUE)
+#endif
+
 /**
  * @brief	IDEX request timeout in seconds
  */
@@ -201,7 +209,7 @@ typedef struct
 static pfe_idex_t pfe_idex = {0};
 
 static void pfe_idex_do_rx(pfe_hif_drv_client_t *client, pfe_idex_t *idex);
-static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex);
+static void pfe_idex_do_tx_conf(const pfe_hif_drv_client_t *client, const pfe_idex_t *idex);
 static pfe_idex_request_t *pfe_idex_request_get_by_id(pfe_idex_seqnum_t seqnum);
 static errno_t pfe_idex_request_set_state(pfe_idex_seqnum_t seqnum, pfe_idex_request_state_t state);
 static errno_t pfe_idex_request_finalize(pfe_idex_seqnum_t seqnum, void *resp_buf, uint16_t resp_len);
@@ -235,7 +243,7 @@ static errno_t pfe_idex_ihc_handler(pfe_hif_drv_client_t *client, void *arg, uin
 		case EVENT_TXDONE_IND:
 		{
 			/*	Run TX routine */
-			pfe_idex_do_tx(client, &pfe_idex);
+			pfe_idex_do_tx_conf(client, &pfe_idex);
 			break;
 		}
 
@@ -407,9 +415,9 @@ static void pfe_idex_do_rx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 /**
  * @brief		TX confirmations processing
  */
-static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
+static void pfe_idex_do_tx_conf(const pfe_hif_drv_client_t *client, const pfe_idex_t *idex)
 {
-	pfe_idex_frame_header_t *idex_header;
+	const pfe_idex_frame_header_t *idex_header;
 	void *ref_ptr;
 
 	while (TRUE)
@@ -434,7 +442,7 @@ static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 
 				NXP_LOG_DEBUG("Request %u transmitted\n", (uint_t)oal_ntohl(req_header->seqnum));
 		#endif /* IDEX_CFG_VERBOSE */
-
+		#if (FALSE == IDEX_IS_NOCPY)
 				if (NULL == idex->txc_free_cbk)
 				{
 					oal_mm_free_contig(ref_ptr);
@@ -443,7 +451,7 @@ static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 				{
 					idex->txc_free_cbk(ref_ptr);
 				}
-
+		#endif
 				break;
 			}
 
@@ -454,7 +462,7 @@ static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 
 				NXP_LOG_DEBUG("Response %u transmitted\n", (uint_t)oal_ntohl(resp_header->seqnum));
 		#endif /* IDEX_CFG_VERBOSE */
-
+		#if (FALSE == IDEX_IS_NOCPY)
 				if (NULL == idex->txc_free_cbk)
 				{
 					oal_mm_free_contig(ref_ptr);
@@ -463,7 +471,7 @@ static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 				{
 					idex->txc_free_cbk(ref_ptr);
 				}
-
+		#endif
 				break;
 			}
 
@@ -476,6 +484,22 @@ static void pfe_idex_do_tx(pfe_hif_drv_client_t *client, pfe_idex_t *idex)
 	}
 }
 
+#if (defined(PFE_CFG_TARGET_OS_AUTOSAR) && (FALSE == PFE_CFG_HIF_IRQ_ENABLED))
+/**
+ * @brief		IHC client polling
+ * @details		Called by MainFunction when client-related event happens (packet received, packet
+ * 				transmitted).
+ */
+void pfe_idex_ihc_poll(void)
+{
+	/*	Run TX routine */
+    pfe_idex_do_tx_conf(pfe_idex.ihc_client, &pfe_idex);
+	/*	Run RX routine */
+    pfe_idex_do_rx(pfe_idex.ihc_client, &pfe_idex);
+
+}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR && PFE_CFG_HIF_IRQ_ENABLED */
+
 /**
  * @brief		Get request by sequence number
  * @note		Every request can be identified by its unique sequence number.
@@ -675,6 +699,9 @@ static errno_t pfe_idex_request_send(pfe_ct_phy_if_id_t dst_phy, pfe_idex_reques
 	uint32_t timeout_us = 1500U * 1000U;
 	/*	Wait 1ms */
 	const uint32_t timeout_step = 1000U;
+#if (defined(PFE_CFG_TARGET_OS_AUTOSAR) && (FALSE == PFE_CFG_HIF_IRQ_ENABLED))
+	pfe_hif_drv_t *hif_drv;
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR && PFE_CFG_HIF_IRQ_ENABLED */
 
 	/*	1.) Create the request instance with room for request payload */
 	req = oal_mm_malloc_contig_aligned_nocache((addr_t)(sizeof(pfe_idex_request_t)) + (addr_t)data_len, 0U);
@@ -746,8 +773,16 @@ static errno_t pfe_idex_request_send(pfe_ct_phy_if_id_t dst_phy, pfe_idex_reques
 		/*	4.) Block until response is received or timeout occurred. RX and
 		 	 	TX processing is expected to be done asynchronously in
 		 	 	pfe_idex_ihc_handler(). */
+#if (defined(PFE_CFG_TARGET_OS_AUTOSAR) && (FALSE == PFE_CFG_HIF_IRQ_ENABLED))
+		hif_drv = pfe_hif_drv_client_get_drv(idex->ihc_client);
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR && PFE_CFG_HIF_IRQ_ENABLED */
 		for ( ; timeout_us>0U; timeout_us-=timeout_step)
 		{
+#if (defined(PFE_CFG_TARGET_OS_AUTOSAR) && (FALSE == PFE_CFG_HIF_IRQ_ENABLED))
+			pfe_hif_drv_tx_job(hif_drv);
+			pfe_hif_drv_rx_job(hif_drv);
+			pfe_idex_ihc_poll();
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR && PFE_CFG_HIF_IRQ_ENABLED */
 			if (IDEX_MASTER_DISCOVERY == type)
 			{
 				NXP_LOG_ERROR("Not implemented\n");
@@ -829,21 +864,47 @@ static errno_t pfe_idex_send_frame(pfe_ct_phy_if_id_t dst_phy, pfe_idex_frame_ty
 	errno_t ret;
 	hif_drv_sg_list_t sg_list = { 0U };
 	uint16_t data_len_tmp = data_len;
-#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
+#if (TRUE == IDEX_IS_NOCPY)
+	pfe_hif_drv_t *hif_drv;
+	pfe_hif_chnl_t *hif_chnl;
 	uint16_t buf_offset;
-#endif
+#endif /* IDEX_IS_NOCPY */
 
 	/*	Get IDEX frame buffer */
+#if (TRUE == IDEX_IS_NOCPY)
+	hif_drv = pfe_hif_drv_client_get_drv(pfe_idex.ihc_client);
+	if (NULL == hif_drv)
+	{
+		NXP_LOG_ERROR("Get hif_drv instance associated with the client failed\n");
+		return ENOENT;
+	}
+	hif_chnl = pfe_hif_drv_get_chnl(hif_drv);
+	if (NULL == hif_chnl)
+	{
+		NXP_LOG_ERROR("Get channel associated with the hif_drv instance failed\n");
+		return ENOENT;
+	}
+	idex_hdr = (pfe_idex_frame_header_t *)pfe_hif_chnl_bmu_alloc_buf_va(hif_chnl);
+#else
 	idex_hdr = oal_mm_malloc_contig_named_aligned_cache(
 								PFE_CFG_TX_MEM,
 								(addr_t)(sizeof(pfe_idex_frame_header_t)) + (addr_t)data_len_tmp,
 								0U);
+#endif /* IDEX_IS_NOCPY */
 	if (NULL == idex_hdr)
 	{
 		NXP_LOG_ERROR("Memory allocation failed\n");
 		return ENOMEM;
 	}
-
+#if (TRUE == IDEX_IS_NOCPY)
+	idex_hdr_pa = pfe_hif_chnl_bmu_get_buf_pa(hif_chnl, (addr_t)idex_hdr);
+	if (NULL == idex_hdr_pa)
+	{
+		NXP_LOG_ERROR("VA to PA conversion failed\n");
+		pfe_hif_chnl_bmu_free_buf(hif_chnl, (addr_t)idex_hdr);
+		return ENOMEM;
+	}
+#else
 	idex_hdr_pa = oal_mm_virt_to_phys_contig(idex_hdr);
 	if (NULL == idex_hdr_pa)
 	{
@@ -851,33 +912,26 @@ static errno_t pfe_idex_send_frame(pfe_ct_phy_if_id_t dst_phy, pfe_idex_frame_ty
 		oal_mm_free_contig(idex_hdr);
 		return ENOMEM;
 	}
+#endif /* IDEX_IS_NOCPY */
 
 	/*	Fill the header */
 	idex_hdr->dst_phy_if = dst_phy;
 	idex_hdr->type = type;
 	/* TX buffer for HIF NOCPY is allocated directly from BMU2.
 	The whole IDEX frame needs to fit into it, so the IDEX header and payload are copied into the TX buffer. */
-#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
-	if (PFE_PHY_IF_ID_HIF_NOCPY == pfe_idex.master_phy_if)
-	{
-		buf_offset = PFE_CFG_LMEM_HDR_SIZE + 256U + sizeof(pfe_ct_hif_tx_hdr_t);
-		(void)memcpy((void *)((addr_t)idex_hdr + buf_offset), idex_hdr, sizeof(pfe_idex_frame_header_t));
-	}
-#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
+#if (TRUE == IDEX_IS_NOCPY)
+	buf_offset = PFE_CFG_LMEM_HDR_SIZE + 256U + sizeof(pfe_ct_hif_tx_hdr_t);
+	(void)memcpy((void *)((addr_t)idex_hdr + buf_offset), idex_hdr, sizeof(pfe_idex_frame_header_t));
+#endif /* IDEX_IS_NOCPY */
 
 	/*	Add payload */
 	payload = (void *)((addr_t)idex_hdr + sizeof(pfe_idex_frame_header_t));
-#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
-	if (PFE_PHY_IF_ID_HIF_NOCPY == pfe_idex.master_phy_if)
-	{
-		(void)memcpy((void *)((addr_t)payload + buf_offset), data, data_len_tmp);
-		data_len_tmp = data_len + sizeof(pfe_ct_hif_tx_hdr_t);
-	}
-	else
-#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
-	{
-		(void)memcpy(payload, data, data_len_tmp);
-	}
+#if (TRUE == IDEX_IS_NOCPY)
+	(void)memcpy((void *)((addr_t)payload + buf_offset), data, data_len_tmp);
+	data_len_tmp = data_len + sizeof(pfe_ct_hif_tx_hdr_t);
+#else
+	(void)memcpy(payload, data, data_len_tmp);
+#endif /* IDEX_IS_NOCPY */
 
 	/*	Build SG list
 	 	TODO: The SG list could be used as reference to all buffers and used to
@@ -894,7 +948,11 @@ static errno_t pfe_idex_send_frame(pfe_ct_phy_if_id_t dst_phy, pfe_idex_frame_ty
 	if (EOK != ret)
 	{
 		NXP_LOG_ERROR("IDEX frame TX failed. Err %u\n", ret);
+#if (TRUE == IDEX_IS_NOCPY)
+		pfe_hif_chnl_bmu_free_buf(hif_chnl, (addr_t)idex_hdr);
+#else
 		oal_mm_free_contig(idex_hdr);
+#endif /* IDEX_IS_NOCPY */
 	}
 	else
 	{
@@ -1079,7 +1137,7 @@ void pfe_idex_fini(void)
  * 				indicating no memory condition ENOMEM will be returned.
  * @return		EOK if success, error code otherwise
  */
-errno_t pfe_idex_master_rpc(uint32_t id, void *buf, uint16_t buf_len, void *resp, uint16_t resp_len)
+errno_t pfe_idex_master_rpc(uint32_t id, const void *buf, uint16_t buf_len, void *resp, uint16_t resp_len)
 {
 	const pfe_idex_t *idex = &pfe_idex;
 
@@ -1193,35 +1251,40 @@ errno_t pfe_idex_set_rpc_ret_val(errno_t retval, void *resp, uint16_t resp_len)
 	void *payload;
 	errno_t ret;
 
-	/*	Construct response message */
 	rpc_resp = oal_mm_malloc((addr_t)(sizeof(pfe_idex_msg_rpc_t)) + (addr_t)resp_len);
-
-	rpc_req = (pfe_idex_msg_rpc_t *)((addr_t)idex->cur_req + sizeof(pfe_idex_request_t));
-
-	rpc_resp->rpc_id = rpc_req->rpc_id; /* Already in correct endian */
-	rpc_resp->plen = oal_htons(resp_len);
-	rpc_resp->rpc_ret = oal_htonl(retval);
-
-	payload = (void *)((addr_t)rpc_resp + sizeof(pfe_idex_msg_rpc_t));
-	(void)memcpy(payload, resp, resp_len);
-
-	/*	Send the response */
-	ret = pfe_idex_send_response(
-									idex->cur_req_phy_id,	/* Destination */
-									idex->cur_req->type,	/* Response type */
-									idex->cur_req->seqnum,	/* Response sequence number */
-									rpc_resp,				/* Response payload */
-									(sizeof(pfe_idex_msg_rpc_t) + resp_len) /* Response payload length */
-								);
-	if (EOK != ret)
+	if (NULL == rpc_resp)
 	{
-		NXP_LOG_ERROR("IDEX RPC response failed\n");
+		NXP_LOG_ERROR("Failed to allocate memory\n");
+		ret = ENOMEM;
+	}
+	else
+	{
+		rpc_req = (pfe_idex_msg_rpc_t *)((addr_t)idex->cur_req + sizeof(pfe_idex_request_t));
+	
+		/*	Construct response message */
+		rpc_resp->rpc_id = rpc_req->rpc_id; /* Already in correct endian */
+		rpc_resp->plen = oal_htons(resp_len);
+		rpc_resp->rpc_ret = oal_htonl(retval);
+	
+		payload = (void *)((addr_t)rpc_resp + sizeof(pfe_idex_msg_rpc_t));
+		(void)memcpy(payload, resp, resp_len);
+	
+		/*	Send the response */
+		ret = pfe_idex_send_response(
+										idex->cur_req_phy_id,	/* Destination */
+										idex->cur_req->type,	/* Response type */
+										idex->cur_req->seqnum,	/* Response sequence number */
+										rpc_resp,				/* Response payload */
+										(sizeof(pfe_idex_msg_rpc_t) + resp_len) /* Response payload length */
+									);
+		if (EOK != ret)
+		{
+			NXP_LOG_ERROR("IDEX RPC response failed\n");
+		}
+	
+		/*	Dispose the response buffer */
+		oal_mm_free(rpc_resp);
 	}
-
-	/*	Dispose the response buffer */
-	oal_mm_free(rpc_resp);
-	rpc_resp = NULL;
-
 	return ret;
 }
 
diff --git a/sw/pfe_platform/src/pfe_l2br.c b/sw/pfe_platform/src/pfe_l2br.c
index b521df5..23dcc0d 100644
--- a/sw/pfe_platform/src/pfe_l2br.c
+++ b/sw/pfe_platform/src/pfe_l2br.c
@@ -154,6 +154,7 @@ static bool_t pfe_l2br_domain_match_if_criterion(const pfe_l2br_domain_t *domain
 static bool_t pfe_l2br_domain_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_domain_t *domain);
 static bool_t pfe_l2br_static_entry_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t *static_ent);
 static errno_t pfe_l2br_set_mac_aging_timeout(pfe_class_t *class, const uint16_t timeout);
+static errno_t pfe_l2br_static_entry_destroy_nolock(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent);
 
 /**
  * @brief		Write bridge domain structure to classifier memory
@@ -1062,6 +1063,111 @@ errno_t pfe_l2br_domain_del_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *if
 	return EOK;
 }
 
+/**
+ * @brief		Flush all MAC table entries of given bridge domain which are related to target interface.
+ * @param[in]	domain The L2 bridge domain instance
+ * @param[in]	iface The interface
+ * @retval		EOK if success, error code if failure
+ */
+errno_t pfe_l2br_domain_flush_by_if(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface)
+{
+	errno_t ret = EOK;
+	errno_t ret_query = EOK;
+	pfe_l2br_table_entry_t *entry = NULL;
+	pfe_l2br_static_entry_t *sentry = NULL;
+	pfe_l2br_table_iterator_t *l2t_iter = NULL;
+	LLIST_t *item, *dummy = NULL;
+	uint32_t iface_bitflag = 0U;
+	const pfe_l2br_t *bridge = NULL;
+	uint16_t entry_vlan = 0U;
+	pfe_ct_mac_table_result_t entry_action_data = {.val = 0U};
+
+	#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely((NULL == domain) || (NULL == domain->bridge) || (NULL == iface)))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+	#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+	bridge = domain->bridge;
+	if (EOK != oal_mutex_lock(bridge->mutex))
+	{
+		NXP_LOG_ERROR("Mutex lock failed\n");
+		return EPERM;
+	}
+
+	/*	Initalize auxiliary tools for MAC table searching */
+	iface_bitflag = (uint32_t)1 << (uint32_t)pfe_phy_if_get_id(iface);
+	entry = pfe_l2br_table_entry_create(bridge->mac_table);
+	l2t_iter = pfe_l2br_iterator_create();
+
+	/*	Flush interface-related static entries */
+	if (FALSE == LLIST_IsEmpty(&bridge->static_entries))
+	{
+		LLIST_ForEachRemovable(item, dummy, &bridge->static_entries)
+		{
+			/*	Get static entry */
+			sentry = LLIST_Data(item, pfe_l2br_static_entry_t, list_entry);
+			if (sentry == NULL)
+			{
+				NXP_LOG_ERROR("NULL static entry detected!\n");
+			}
+			else
+			{
+				/*	Check static entry */
+				if ((sentry->vlan == domain->vlan) && (0U != (sentry->u.action_data.item.forward_list & iface_bitflag)))
+				{
+					/*	Remove static entry. LLIST_Remove() is inside... */
+					ret = pfe_l2br_static_entry_destroy_nolock(bridge, sentry);
+					if (EOK != ret)
+					{
+						NXP_LOG_ERROR("Unable to remove static entry: %d\n", ret);
+					}
+				}
+			}
+		}
+	}
+	
+	/*	Flush interface-related dynamic entries */
+	if (EOK == ret)
+	{
+		ret_query = pfe_l2br_table_get_first(bridge->mac_table, l2t_iter, L2BR_TABLE_CRIT_VALID, entry);
+		while (EOK == ret_query)
+		{
+			entry_vlan = (uint16_t)pfe_l2br_table_entry_get_vlan(entry);
+			entry_action_data.val = (uint32_t)pfe_l2br_table_entry_get_action_data(entry);
+
+			/*	Check entry */
+			if ((entry_vlan == domain->vlan) && (0U != (entry_action_data.item.forward_list & iface_bitflag)))
+			{
+				/*	Remove entry */
+				ret = pfe_l2br_table_del_entry(bridge->mac_table, entry);
+				if (EOK != ret)
+				{
+					NXP_LOG_ERROR("Could not delete MAC table entry: %d\n", ret);
+				}
+			}
+
+			/* Get the next entry */
+			ret_query = pfe_l2br_table_get_next(bridge->mac_table, l2t_iter, entry);
+		}
+	}
+
+	if (EOK != oal_mutex_unlock(bridge->mutex))
+	{
+		NXP_LOG_ERROR("Mutex unlock failed\n");
+	}
+
+	/*	Release entry storage */
+	(void)pfe_l2br_table_entry_destroy(entry);
+
+	/*  Release iterator */
+	(void)pfe_l2br_iterator_destroy(l2t_iter);
+
+	return ret;
+}
+
 /**
  * @brief		Get list of associated physical interfaces
  * @param[in]	domain The domain instance
diff --git a/sw/pfe_platform/src/pfe_log_if.c b/sw/pfe_platform/src/pfe_log_if.c
index d8725df..cc26393 100644
--- a/sw/pfe_platform/src/pfe_log_if.c
+++ b/sw/pfe_platform/src/pfe_log_if.c
@@ -1672,7 +1672,7 @@ errno_t pfe_log_if_loopback_enable(pfe_log_if_t *iface)
 	}
 
 	tmp = iface->log_if_class.flags;
-	iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32_t)tmp | IF_FL_LOOPBACK);
+	iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32_t)tmp | (uint32_t)IF_FL_LOOPBACK);
 
 	ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
 	if (EOK != ret)
diff --git a/sw/pfe_platform/src/pfe_log_if_slave.c b/sw/pfe_platform/src/pfe_log_if_slave.c
index 0a011e0..9b5db74 100644
--- a/sw/pfe_platform/src/pfe_log_if_slave.c
+++ b/sw/pfe_platform/src/pfe_log_if_slave.c
@@ -808,6 +808,42 @@ errno_t pfe_log_if_flush_mac_addrs(pfe_log_if_t *iface, pfe_mac_db_crit_t crit,
 	return ret;
 }
 
+/**
+ * @brief			Set mask of egress interfaces
+ * @param[in]		iface The interface instance
+ * @param[in]		egress mask (in host format), constructed like
+ * 					egress |= 1 << phy_if_id (for each configured phy_if)
+ * @retval			EOK Success
+ */
+errno_t pfe_log_if_set_egress_ifs(pfe_log_if_t *iface, uint32_t egress)
+{
+	errno_t ret = EOK;
+	pfe_platform_rpc_pfe_log_if_set_egress_ifs_arg_t req = {0};
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == iface))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+#endif /* GLOBAL_CFG_NULL_ARG_CHECK */
+
+	req.log_if_id = iface->id;
+	req.phy_if_id = egress;
+
+	(void)pfe_log_if_db_lock();
+
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_LOG_IF_SET_EGRESS_IFS, &req, sizeof(req), NULL, 0U);
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("Can't set egress interfaces: %d\n", ret);
+	}
+
+	(void)pfe_log_if_db_unlock();
+
+	return ret;
+}
+
 /**
  * @brief			Get mask of egress interfaces
  * @param[in]		iface The interface instance
@@ -818,8 +854,8 @@ errno_t pfe_log_if_flush_mac_addrs(pfe_log_if_t *iface, pfe_mac_db_crit_t crit,
 errno_t pfe_log_if_get_egress_ifs(pfe_log_if_t *iface, uint32_t *egress)
 {
 	errno_t ret = EOK;
-	pfe_platform_rpc_pfe_log_if_get_egress_arg_t req = {0};
-	pfe_platform_rpc_pfe_log_if_get_egress_ret_t rpc_ret = {0};
+	pfe_platform_rpc_pfe_log_if_get_egress_ifs_arg_t req = {0};
+	pfe_platform_rpc_pfe_log_if_get_egress_ifs_ret_t rpc_ret = {0};
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == iface) || (NULL == egress)))
@@ -833,7 +869,7 @@ errno_t pfe_log_if_get_egress_ifs(pfe_log_if_t *iface, uint32_t *egress)
 
 	(void)pfe_log_if_db_lock();
 
-	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS, &req, sizeof(req), &rpc_ret, sizeof(rpc_ret));
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_LOG_IF_GET_EGRESS_IFS, &req, sizeof(req), &rpc_ret, sizeof(rpc_ret));
 	if (EOK != ret)
 	{
 		NXP_LOG_DEBUG("Can't get egress interfaces: %d\n", ret);
@@ -1158,6 +1194,45 @@ __attribute__((pure)) bool_t pfe_log_if_is_promisc(pfe_log_if_t *iface)
 	}
 }
 
+/**
+ * @brief               Check if interface is in loopback mode
+ * @param[in]   iface The interface instance
+ * @return              TRUE if loopback mode is enabled, FALSE otherwise
+ */
+__attribute__((pure)) bool_t pfe_log_if_is_loopback(pfe_log_if_t *iface)
+{
+	pfe_platform_rpc_pfe_log_if_is_loopback_arg_t req = {0};
+	pfe_platform_rpc_pfe_log_if_is_loopback_ret_t rpc_ret = {0};
+	errno_t ret;
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == iface))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return FALSE;
+	}
+#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+	req.log_if_id = iface->id;
+
+	(void)pfe_log_if_db_lock();
+
+	/*	Query the master driver */
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_LOG_IF_IS_LOOPBACK, &req, sizeof(req), &rpc_ret, sizeof(rpc_ret));
+
+	(void)pfe_log_if_db_unlock();
+
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("Can't get loopback status: %d\n", ret);
+		return FALSE;
+	}
+	else
+	{
+		return rpc_ret.status;
+	}
+}
+
 /**
  * @brief		Enable loopback mode
  * @param[in]	iface The interface instance
diff --git a/sw/pfe_platform/src/pfe_pe.c b/sw/pfe_platform/src/pfe_pe.c
index 54947f0..afb1f92 100644
--- a/sw/pfe_platform/src/pfe_pe.c
+++ b/sw/pfe_platform/src/pfe_pe.c
@@ -963,7 +963,20 @@ static void pfe_pe_memcpy_from_host_to_dmem_32_nolock(
 		/*	Write unaligned bytes to align the destination address */
 		offset = BYTES_TO_4B_ALIGNMENT(dst_temp);
 		offset = (len < offset) ? len : offset;
-		val = *(uint32_t *)src_byteptr;
+		/* Check if src_byteptr is 4 bytes alignment */
+		if (((uintptr_t)src_byteptr & 0x3U) == 0U)
+		{
+			/* src_byteptr aligns 4 bytes */
+			val = *(uint32_t *)src_byteptr;
+		}
+		else
+		{
+			/* src_byteptr doesn't align 4 bytes : access each byte */
+			val =  ((uint32_t)*(src_byteptr + 0U)) << 0U;
+			val += ((uint32_t)*(src_byteptr + 1U)) << 8U;
+			val += ((uint32_t)*(src_byteptr + 2U)) << 16U;
+			val += ((uint32_t)*(src_byteptr + 3U)) << 24U;
+		}
 		pfe_pe_mem_write(pe, PFE_PE_DMEM, val, dst_temp, (uint8_t)offset);
 		src_byteptr += offset;
 		dst_temp = dst_addr + offset;
@@ -1277,20 +1290,27 @@ static errno_t pfe_pe_load_dmem_section_nolock(pfe_pe_t *pe, const void *sdata,
 				{
 		#if defined(FW_WRITE_CHECK_EN)
 					void *buf = oal_mm_malloc(size);
+					if (NULL == buf)
+					{
+						ret = ENOMEM;
+					}
+					else
+					{
 		#endif /* FW_WRITE_CHECK_EN */
 
-					/*	Write section data */
-					pe->fw_load_ops->pe_memcpy(pe, PFE_PE_DMEM, addr - pe->dmem_elf_base_va, sdata, size);
+						/*	Write section data */
+						pe->fw_load_ops->pe_memcpy(pe, PFE_PE_DMEM, addr - pe->dmem_elf_base_va, sdata, size);
 
 		#if defined(FW_WRITE_CHECK_EN)
-					pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, buf, addr, size);
+						pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, buf, addr, size);
 
-					if (0 != memcmp(buf, sdata, size))
-					{
-						NXP_LOG_ERROR("DMEM data inconsistent\n");
-					}
+						if (0 != memcmp(buf, sdata, size))
+						{
+							NXP_LOG_ERROR("DMEM data inconsistent\n");
+						}
 
-					oal_mm_free(buf);
+						oal_mm_free(buf);
+					}
 		#endif /* FW_WRITE_CHECK_EN */
 
 					break;
@@ -1373,21 +1393,27 @@ static errno_t pfe_pe_load_imem_section_nolock(pfe_pe_t *pe, const void *data, a
 		{
 #if defined(FW_WRITE_CHECK_EN)
 			void *buf = oal_mm_malloc(size);
+			if (NULL == buf)
+			{
+				ret = ENOMEM;
+			}
+			else
+			{
 #endif /* FW_WRITE_CHECK_EN */
 
-			/*	Write section data */
-			pe->fw_load_ops->pe_memcpy(pe, PFE_PE_IMEM, addr - pe->imem_elf_base_va, data, size);
+				/*	Write section data */
+				pe->fw_load_ops->pe_memcpy(pe, PFE_PE_IMEM, addr - pe->imem_elf_base_va, data, size);
 
 #if defined(FW_WRITE_CHECK_EN)
-			pfe_pe_memcpy_from_imem_to_host_32_nolock(pe, buf, addr, size);
+				pfe_pe_memcpy_from_imem_to_host_32_nolock(pe, buf, addr, size);
 
-			if (0 != memcmp(buf, data, size))
-			{
-				NXP_LOG_ERROR("IMEM data inconsistent\n");
-			}
+				if (0 != memcmp(buf, data, size))
+				{
+					NXP_LOG_ERROR("IMEM data inconsistent\n");
+				}
 
-			oal_mm_free(buf);
-			buf = NULL;
+				oal_mm_free(buf);
+			}
 #endif /* FW_WRITE_CHECK_EN */
 
 			break;
@@ -1843,6 +1869,10 @@ errno_t pfe_pe_load_firmware(pfe_pe_t **pe, uint32_t pe_num, const void *elf)
 		{
 			ret = ENOMEM;
 			pfe_pe_free_mem(pe, pe_num);
+			if (NULL != tmp_mmap)
+			{
+				oal_mm_free(tmp_mmap);
+			}
 			return ret;
 		}
 		else
@@ -1869,6 +1899,14 @@ errno_t pfe_pe_load_firmware(pfe_pe_t **pe, uint32_t pe_num, const void *elf)
 		{
 			ret = ENOMEM;
 			pfe_pe_free_mem(pe, pe_num);
+			if (NULL != tmp_mmap)
+			{
+				oal_mm_free(tmp_mmap);
+			}
+			if (NULL != messages_mem)
+			{
+				oal_mm_free(messages_mem);
+			}
 			return ret;
 		}
 		else
@@ -1888,6 +1926,18 @@ errno_t pfe_pe_load_firmware(pfe_pe_t **pe, uint32_t pe_num, const void *elf)
 		NXP_LOG_DEBUG("Unexpected .elf format (little endian)\n");
 		ret = EINVAL;
 		pfe_pe_free_mem(pe, pe_num);
+		if (NULL != tmp_mmap)
+		{
+			oal_mm_free(tmp_mmap);
+		}
+		if (NULL != messages_mem)
+		{
+			oal_mm_free(messages_mem);
+		}
+		if (NULL != features_mem)
+		{
+			oal_mm_free(features_mem);
+		}
 		return ret;
 	}
 
@@ -1895,6 +1945,18 @@ errno_t pfe_pe_load_firmware(pfe_pe_t **pe, uint32_t pe_num, const void *elf)
 	ret = pfe_pe_upload_sections(pe, pe_num, elf_file);
 	if (EOK != ret)
 	{
+		if (NULL != tmp_mmap)
+		{
+			oal_mm_free(tmp_mmap);
+		}
+		if (NULL != messages_mem)
+		{
+			oal_mm_free(messages_mem);
+		}
+		if (NULL != features_mem)
+		{
+			oal_mm_free(features_mem);
+		}
 		return ret;
 	}
 
diff --git a/sw/pfe_platform/src/pfe_phy_if.c b/sw/pfe_platform/src/pfe_phy_if.c
index b2906b7..4201aa4 100644
--- a/sw/pfe_platform/src/pfe_phy_if.c
+++ b/sw/pfe_platform/src/pfe_phy_if.c
@@ -1593,7 +1593,7 @@ bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface)
 		NXP_LOG_DEBUG("mutex lock failed\n");
 	}
 
-	ret = (0U != (oal_ntohl(iface->phy_if_class.flags) & IF_FL_PROMISC));
+	ret = (0U != (oal_ntohl(iface->phy_if_class.flags) & (uint32_t)IF_FL_PROMISC));
 
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
diff --git a/sw/pfe_platform/src/pfe_phy_if_slave.c b/sw/pfe_platform/src/pfe_phy_if_slave.c
index 0c418b6..fc0c145 100644
--- a/sw/pfe_platform/src/pfe_phy_if_slave.c
+++ b/sw/pfe_platform/src/pfe_phy_if_slave.c
@@ -474,6 +474,108 @@ errno_t pfe_phy_if_set_op_mode(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode)
 	return ret;
 }
 
+/**
+ * @brief Set the block state
+ * @param[in] iface The interface instance
+ * @param[out] block_state Block state to set
+ * @return EOK on success or an error code
+ */
+errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t block_state)
+{
+	errno_t ret;
+	pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t arg = {0};
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == iface))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_lock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex lock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	(void)pfe_phy_if_db_lock();
+
+	/*	Ask the master driver to change the block state */
+	arg.phy_if_id = iface->id;
+	arg.block_state = block_state;
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE, &arg, sizeof(arg), NULL, 0U);
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE failed: %d\n", ret);
+	}
+
+	(void)pfe_phy_if_db_unlock();
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_unlock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex unlock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	return ret;
+}
+
+/**
+ * @brief Get the block state
+ * @param[in] iface The interface instance
+ * @param[out] block_state Current block state
+ * @return EOK On success or an error code
+ */
+errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *block_state)
+{
+	errno_t ret = EOK;
+	pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t arg = {0};
+	pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t rpc_ret = {0};
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely((NULL == iface) || (NULL == block_state)))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+#endif /* GLOBAL_CFG_NULL_ARG_CHECK */
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_lock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex lock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	(void)pfe_phy_if_db_lock();
+
+	/*	Ask the master driver to get the block state */
+	arg.phy_if_id = iface->id;
+
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE, &arg, sizeof(arg), &rpc_ret, sizeof(rpc_ret));
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE failed: %d\n", ret);
+	}
+	else
+	{
+		*block_state = rpc_ret.state;
+	}
+
+	(void)pfe_phy_if_db_unlock();
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_unlock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex unlock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	return ret;
+}
 /**
  * @brief		Bind interface with EMAC
  * @param[in]	iface The interface instance
@@ -1071,6 +1173,102 @@ errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface)
 	return ret;
 }
 
+/**
+ * @brief		Enable loadbalance mode
+ * @param[in]	iface The interface instance
+ * @retval		EOK Success
+ * @retval		EINVAL Invalid or missing argument
+ */
+errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface)
+{
+	errno_t ret = EOK;
+	pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t arg = {0};
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == iface))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_lock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex lock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	(void)pfe_phy_if_db_lock();
+
+	/* Ask the master driver to enable the loadbalance mode */
+	arg.phy_if_id = iface->id;
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE, &arg, sizeof(arg), NULL, 0U);
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE failed: %d\n", ret);
+	}
+
+	(void)pfe_phy_if_db_unlock();
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_unlock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex unlock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	return ret;
+}
+
+/**
+ * @brief		Disable loadbalance mode
+ * @param[in]	iface The interface instance
+ * @retval		EOK Success
+ * @retval		EINVAL Invalid or missing argument
+ */
+errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface)
+{
+	errno_t ret = EOK;
+	pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t arg = {0};
+
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == iface))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return EINVAL;
+	}
+#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_lock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex lock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	(void)pfe_phy_if_db_lock();
+
+	/* Ask the master driver to disable the loadbalance mode */
+	arg.phy_if_id = iface->id;
+	ret = pfe_idex_master_rpc(PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE, &arg, sizeof(arg), NULL, 0U);
+	if (EOK != ret)
+	{
+		NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE failed: %d\n", ret);
+	}
+
+	(void)pfe_phy_if_db_unlock();
+
+#ifndef PFE_CFG_TARGET_OS_AUTOSAR
+	if (EOK != oal_mutex_unlock(&iface->lock))
+	{
+		NXP_LOG_DEBUG("mutex unlock failed\n");
+	}
+#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
+
+	return ret;
+}
+
 /**
  * @brief		Enable ALLMULTI mode
  * @param[in]	iface The interface instance
diff --git a/sw/pfe_platform/src/pfe_rtable.c b/sw/pfe_platform/src/pfe_rtable.c
index 6ba0a9b..83e7dae 100644
--- a/sw/pfe_platform/src/pfe_rtable.c
+++ b/sw/pfe_platform/src/pfe_rtable.c
@@ -159,7 +159,7 @@ enum pfe_rtable_worker_signals
 };
 #endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) */
 
-static uint8_t stats_index[PFE_CFG_CONN_STATS_SIZE + 1];
+static uint8_t stats_tbl_index[PFE_CFG_CONN_STATS_SIZE + 1];
 
 static uint32_t pfe_get_crc32_be(uint32_t crc, uint8_t *data, uint16_t len);
 static void pfe_rtable_invalidate(pfe_rtable_t *rtable);
@@ -191,13 +191,13 @@ static uint8_t pfe_rtable_get_free_stats_index(const pfe_rtable_t *rtable)
 {
 	/* Index 0 is the default one. All conntracks that have no space
 	   in the table will be counted on default index */
-	uint8_t index = 1;
+	uint8_t index = 1U;
 
 	while (index < rtable->conntrack_stats_table_size)
 	{
-		if (stats_index[index] == 0U)
+		if (stats_tbl_index[index] == 0U)
 		{
-			stats_index[index] = 1U;
+			stats_tbl_index[index] = 1U;
 			break;
 		}
 		index ++;
@@ -218,9 +218,9 @@ static uint8_t pfe_rtable_get_free_stats_index(const pfe_rtable_t *rtable)
  */
 static void pfe_rtable_free_stats_index(uint8_t index)
 {
-	if (index < PFE_CFG_CONN_STATS_SIZE + 1)
+	if (index < (PFE_CFG_CONN_STATS_SIZE + 1U))
 	{
-		stats_index[index] = 0U;
+		stats_tbl_index[index] = 0U;
 	}
 }
 
@@ -1672,6 +1672,7 @@ errno_t pfe_rtable_add_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
 	pfe_ct_rtable_entry_t *new_phys_entry_va = NULL, *new_phys_entry_pa = NULL, *last_phys_entry_va = NULL;
     errno_t ret;
     pfe_l2br_domain_t *domain;
+	uint8_t index;
 
 #if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
 	pfe_ct_rtable_flags_t valid_tmp;
@@ -1707,7 +1708,8 @@ errno_t pfe_rtable_add_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
 	hash = pfe_rtable_entry_get_hash(entry, hash_type, (rtable->htable_size - 1U));
 	entry->temp_phys_entry->flags = RT_FL_NONE;
 	entry->temp_phys_entry->status &= ~(uint8_t)RT_STATUS_ACTIVE;
-	entry->temp_phys_entry->conntrack_stats_index = oal_htons((uint16_t)pfe_rtable_get_free_stats_index(rtable));
+	index = pfe_rtable_get_free_stats_index(rtable);
+	entry->temp_phys_entry->conntrack_stats_index = oal_htons((uint16_t)index);
 
 	/* Add vlan stats index into the phy_entry structure */
 	if (0U != (oal_ntohl(entry->temp_phys_entry->actions) & ((uint32_t)RT_ACT_ADD_VLAN_HDR | (uint32_t)RT_ACT_MOD_VLAN_HDR)))
@@ -1936,9 +1938,9 @@ static errno_t pfe_rtable_del_entry_nolock(pfe_rtable_t *rtable, pfe_rtable_entr
 	{
 		/*	Invalidate the found entry. This will disable the whole chain. */
 		entry->phys_entry->flags = RT_FL_NONE;
-		if ( entry->temp_phys_entry->conntrack_stats_index != 0)
+		if ( entry->temp_phys_entry->conntrack_stats_index != 0U)
 		{
-			pfe_rtable_clear_stats(rtable, oal_ntohs(entry->temp_phys_entry->conntrack_stats_index));
+			(void)pfe_rtable_clear_stats(rtable, oal_ntohs(entry->temp_phys_entry->conntrack_stats_index));
 			pfe_rtable_free_stats_index(oal_ntohs(entry->temp_phys_entry->conntrack_stats_index));
 		}
 
@@ -2405,9 +2407,9 @@ pfe_rtable_t *pfe_rtable_create(pfe_class_t *class, addr_t htable_base_va, uint3
 
 				rtable->conntrack_stats_table_size = PFE_CFG_CONN_STATS_SIZE;
 
-				(void)memset(&stats_index, 0, sizeof(stats_index));
+				(void)memset(&stats_tbl_index, 0, sizeof(stats_tbl_index));
 
-				rtable->conntrack_stats_table_addr = pfe_rtable_create_stats_table(class ,PFE_CFG_CONN_STATS_SIZE + 1);
+				rtable->conntrack_stats_table_addr = pfe_rtable_create_stats_table(class ,PFE_CFG_CONN_STATS_SIZE + 1U);
 
 				if ((NULL_ADDR == rtable->htable_base_va) || (NULL_ADDR == rtable->pool_base_va))
 				{
@@ -3040,13 +3042,13 @@ errno_t pfe_rtable_clear_stats(const pfe_rtable_t *rtable, uint8_t conntrack_ind
  * @param[in]	verb_level 	Verbosity level
  * @return		Number of bytes written to the buffer
  */
-uint32_t pfe_rtable_get_text_statistics(pfe_rtable_t *rtable, char_t *buf, uint32_t buf_len, uint8_t verb_level)
+uint32_t pfe_rtable_get_text_statistics(const pfe_rtable_t *rtable, char_t *buf, uint32_t buf_len, uint8_t verb_level)
 {
 	uint32_t len = 0U;
 	errno_t ret;
 	pfe_ct_conntrack_stats_t stats = {0};
 	LLIST_t *item;
-	pfe_rtable_entry_t *entry;
+	const pfe_rtable_entry_t *entry;
 
 	/* We keep unused parameter verb_level for consistency with rest of the *_get_text_statistics() functions */
 	(void)verb_level;
@@ -3070,7 +3072,7 @@ uint32_t pfe_rtable_get_text_statistics(pfe_rtable_t *rtable, char_t *buf, uint3
 	{
 		entry = LLIST_Data(item, pfe_rtable_entry_t, list_entry);
 
-		if (oal_ntohs(entry->phys_entry->conntrack_stats_index) != 0)
+		if (oal_ntohs(entry->phys_entry->conntrack_stats_index) != 0U)
 		{
 			ret = pfe_rtable_get_stats(rtable, &stats, oal_ntohs(entry->phys_entry->conntrack_stats_index));
 
diff --git a/sw/pfe_platform/src/pfe_spd.c b/sw/pfe_platform/src/pfe_spd.c
index 1ea2a8e..adea252 100644
--- a/sw/pfe_platform/src/pfe_spd.c
+++ b/sw/pfe_platform/src/pfe_spd.c
@@ -9,9 +9,10 @@
 
 #include "pfe_spd.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
-static pfe_ct_ipsec_spd_t *pfe_spds[PFE_PHY_IF_ID_MAX] = {NULL};
+static pfe_ct_ipsec_spd_t *pfe_spds[PFE_PHY_IF_ID_MAX];
 static pfe_class_t *class_ptr = NULL;
 
 /*
@@ -260,8 +261,7 @@ errno_t pfe_spd_add_rule(pfe_phy_if_t *phy_if, uint16_t position, pfe_ct_spd_ent
                Copy data from existing database to the new one leaving space for the new entry
                Copy the new entry into the reserved space */
             if(position >= old_count)
-            {   /* Adding to the last position */
-                position = (uint16_t)old_count;
+            {
                 (void)memcpy(&entries[0], &old_entries[0], old_count * sizeof(pfe_ct_spd_entry_t));
                 (void)memcpy(&entries[old_count], entry, sizeof(pfe_ct_spd_entry_t));
             }
@@ -440,3 +440,4 @@ errno_t pfe_spd_get_rule(const pfe_phy_if_t *phy_if, uint16_t position, pfe_ct_s
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/pfe_platform/src/pfe_spd_acc.c b/sw/pfe_platform/src/pfe_spd_acc.c
index b4447f6..3884f4b 100644
--- a/sw/pfe_platform/src/pfe_spd_acc.c
+++ b/sw/pfe_platform/src/pfe_spd_acc.c
@@ -14,6 +14,7 @@
 #include "pfe_spd.h"
 #include "pfe_spd_acc.h"
 
+#ifdef PFE_CFG_PFE_MASTER
 #ifdef PFE_CFG_FCI_ENABLE
 
 /* HW acceleration of the SPD entry search must be supported by a proper configuration
@@ -350,3 +351,4 @@ errno_t pfe_spd_acc_get_rule(const pfe_phy_if_t *phy_if, uint16_t position, pfe_
 }
 
 #endif /* PFE_CFG_FCI_ENABLE */
+#endif /* PFE_CFG_PFE_MASTER */
diff --git a/sw/pfe_platform/src/pfe_tmu.c b/sw/pfe_platform/src/pfe_tmu.c
index 0422f5b..8edcd4a 100644
--- a/sw/pfe_platform/src/pfe_tmu.c
+++ b/sw/pfe_platform/src/pfe_tmu.c
@@ -108,7 +108,7 @@ static errno_t get_sum_of_queue_lengths(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t
 		}
 		else
 		{
-			pfe_tmu_queue_get_mode(tmu, phy, i, &tmp_min, &tmp_max);
+			(void)pfe_tmu_queue_get_mode(tmu, phy, i, &tmp_min, &tmp_max);
 			tmp_sum += tmp_max;
 		}
 	}
@@ -118,13 +118,13 @@ static errno_t get_sum_of_queue_lengths(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t
 	{	/* HIF */
 		if (TLITE_HIF_MAX_ENTRIES < tmp_sum)
 		{
-			NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for HIF interface.", tmp_sum, TLITE_HIF_MAX_ENTRIES);
+			NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for HIF interface.", (uint_t)tmp_sum, TLITE_HIF_MAX_ENTRIES);
 			ret_val = ENOSPC;
 		}
 		else if ((TRUE == pfe_feature_mgr_is_available("err051211_workaround")) && 
 				 (PFE_HIF_RX_RING_CFG_LENGTH < (tmp_sum + PFE_TMU_ERR051211_Q_OFFSET)))
 		{
-			NXP_LOG_ERROR("err051211_workaround is active and \"sum of queue lengths (%u) + Q_OFFSET (%u)\" exceeds HIF RX Ring length (%u).", tmp_sum, PFE_TMU_ERR051211_Q_OFFSET, PFE_HIF_RX_RING_CFG_LENGTH);
+			NXP_LOG_ERROR("err051211_workaround is active and \"sum of queue lengths (%u) + Q_OFFSET (%u)\" exceeds HIF RX Ring length (%u).", (uint_t)tmp_sum, PFE_TMU_ERR051211_Q_OFFSET, PFE_HIF_RX_RING_CFG_LENGTH);
 			ret_val = ENOSPC;
 		}
 		else
@@ -136,7 +136,7 @@ static errno_t get_sum_of_queue_lengths(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t
 	{	/* EMAC and 'others' */
 		if (TLITE_MAX_ENTRIES < tmp_sum)
 		{
-			NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for EMAC/UTIL/HIF_NOCPY interface.", tmp_sum, TLITE_MAX_ENTRIES);
+			NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for EMAC/UTIL/HIF_NOCPY interface.", (uint_t)tmp_sum, TLITE_MAX_ENTRIES);
 			ret_val = ENOSPC;
 		}
 		else
@@ -588,7 +588,7 @@ errno_t pfe_tmu_queue_set_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uin
 	/* Check and set mode + lengths */
 	if (min > max)
 	{
-		NXP_LOG_ERROR("Wrong queue lengths: min queue length (%u) is larger than max queue length (%u)\n", min, max);
+		NXP_LOG_ERROR("Wrong queue lengths: min queue length (%u) is larger than max queue length (%u)\n", (uint_t)min, (uint_t)max);
 		ret_val = EINVAL;
 	}
 	else if (EOK != pfe_tmu_check_queue(tmu, phy, queue))
@@ -790,7 +790,7 @@ errno_t pfe_tmu_queue_reset_tail_drop_policy(const pfe_tmu_t *tmu)
 	if (unlikely(NULL == tmu))
 	{
 		NXP_LOG_ERROR("NULL argument received\n");
-		return 0U;
+		return (errno_t)0;
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
@@ -823,11 +823,11 @@ errno_t pfe_tmu_queue_err051211_sync(const pfe_tmu_t *tmu)
 	/*	Pre-compute safe default HIF queue length (in case it is needed). Consider the following two limits:
 			--> Size of HIF RX Ring
 			--> Max allowed queue size for HIF */
-	default_max = (PFE_HIF_RX_RING_CFG_LENGTH >= PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH) ? ((PFE_HIF_RX_RING_CFG_LENGTH - PFE_TMU_ERR051211_Q_OFFSET) / 2U) : (1UL);
+	default_max = (PFE_HIF_RX_RING_CFG_LENGTH >= PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH) ? (((uint32_t)PFE_HIF_RX_RING_CFG_LENGTH - PFE_TMU_ERR051211_Q_OFFSET) / 2U) : (1U);
 	default_max = (default_max >= TLITE_HIF_MAX_Q_SIZE) ? (TLITE_HIF_MAX_Q_SIZE) : (default_max);
 
 	/* Check all HIF interfaces and update data in FW. */
-	for (phy = PFE_PHY_IF_ID_HIF0; (PFE_PHY_IF_ID_HIF3 >= phy); phy = (pfe_ct_phy_if_id_t)(phy + 1U))
+	for (phy = PFE_PHY_IF_ID_HIF0; (PFE_PHY_IF_ID_HIF3 >= phy); phy = (pfe_ct_phy_if_id_t)((uint16_t)phy + 1U))
 	{
 		uint8_t queue = 0U;
 		const uint8_t queue_cnt = pfe_tmu_queue_get_cnt(tmu, phy);
@@ -836,16 +836,17 @@ errno_t pfe_tmu_queue_err051211_sync(const pfe_tmu_t *tmu)
 		if (ENOSPC == get_sum_of_queue_lengths(tmu, phy, 0xFF, 0xFF, &sum))
 		{
 			/* Reset queue lengths and then set them all to default_max length. This will update data in FW as well. */
-			set_all_queues_to_min_length(tmu, phy);
+			(void)set_all_queues_to_min_length(tmu, phy);
 			for (queue = 0U; (queue_cnt > queue); queue++)
 			{
 				mode = pfe_tmu_queue_get_mode(tmu, phy, queue, &min, &max);
-				pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, default_max);
+				(void)pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, default_max);
 			}
 
-			NXP_LOG_WARNING("Every TMU queue of physical interface id=%d was set to length %u, because err051211_workaround got activated "
-							"and \"original sum of queue lengths (%u) + Q_OFFSET (%u)\" for the given interface was exceeding HIF RX Ring length (%u).", 
-							phy, default_max, sum, (uint_t)PFE_TMU_ERR051211_Q_OFFSET, (uint_t)PFE_HIF_RX_RING_CFG_LENGTH);
+			NXP_LOG_WARNING("Every TMU queue of physical interface id=%d was set to length %u, because err051211_workaround got activated.",
+							phy, (uint_t)default_max);
+			NXP_LOG_WARNING("\"Original sum of queue lengths (%u) + Q_OFFSET (%u)\" for the given interface was exceeding HIF RX Ring length (%u).",
+							(uint_t)sum, (uint_t)PFE_TMU_ERR051211_Q_OFFSET, (uint_t)PFE_HIF_RX_RING_CFG_LENGTH);
 		}
 		else
 		{
@@ -853,7 +854,7 @@ errno_t pfe_tmu_queue_err051211_sync(const pfe_tmu_t *tmu)
 			for (queue = 0U; (queue_cnt > queue); queue++)
 			{
 				mode = pfe_tmu_queue_get_mode(tmu, phy, queue, &min, &max);
-				pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, max);
+				(void)pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, max);
 			}
 		}
 	}
diff --git a/sw/pfe_platform/src/pfe_util.c b/sw/pfe_platform/src/pfe_util.c
index 27852b4..0e4df11 100644
--- a/sw/pfe_platform/src/pfe_util.c
+++ b/sw/pfe_platform/src/pfe_util.c
@@ -684,63 +684,71 @@ uint32_t pfe_util_get_text_statistics(const pfe_util_t *util, char_t *buf, uint3
 	pfe_ct_pe_mmap_t mmap;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == util))
+	if (unlikely(NULL == buf))
 	{
 		NXP_LOG_ERROR("NULL argument received\n");
 		return 0U;
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-	/* FW version */
-	if (EOK == pfe_util_get_fw_version(util, &fw_ver))
+	if (NULL == util)
 	{
-		len += oal_util_snprintf(buf + len, buf_len - len, "FIRMWARE VERSION\t%u.%u.%u (api:%.32s)\n",
-			fw_ver.major, fw_ver.minor, fw_ver.patch, fw_ver.cthdr);
+		/* NULL ptr to UTIL is allowed. Driver does not have to load UTIL FW. */
+		len += oal_util_snprintf(buf + len, buf_len - len, "UTIL Firmware not loaded.\n");
 	}
 	else
 	{
-		len += oal_util_snprintf(buf + len, buf_len - len, "FIRMWARE VERSION <unknown>\n");
-	}
-
-	len += pfe_util_cfg_get_text_stat(util->cbus_base_va, buf + len, buf_len - len, verb_level);
+		/* FW version */
+		if (EOK == pfe_util_get_fw_version(util, &fw_ver))
+		{
+			len += oal_util_snprintf(buf + len, buf_len - len, "FIRMWARE VERSION\t%u.%u.%u (api:%.32s)\n",
+				fw_ver.major, fw_ver.minor, fw_ver.patch, fw_ver.cthdr);
+		}
+		else
+		{
+			len += oal_util_snprintf(buf + len, buf_len - len, "FIRMWARE VERSION <unknown>\n");
+		}
 
-	/*	Get PE info per PE */
-	for (ii=0U; ii<util->pe_num; ii++)
-	{
-		ipsec_state_t state = { 0 };
-		uint32_t text_stat_len = 0U;
+		len += pfe_util_cfg_get_text_stat(util->cbus_base_va, buf + len, buf_len - len, verb_level);
 
-		if (EOK == pfe_pe_get_mmap(util->pe[ii], &mmap))
+		/*	Get PE info per PE */
+		for (ii=0U; ii<util->pe_num; ii++)
 		{
-			text_stat_len = pfe_pe_get_text_statistics(util->pe[ii], buf + len, buf_len - len, verb_level);
-			if (0U == text_stat_len)
-			{
-				len = 0U;
-				break;
-			}
-			else
+			ipsec_state_t state = { 0 };
+			uint32_t text_stat_len = 0U;
+
+			if (EOK == pfe_pe_get_mmap(util->pe[ii], &mmap))
 			{
-				len += text_stat_len;
-				/* IPsec statistics */
-				pfe_pe_memcpy_from_dmem_to_host_32(util->pe[ii], &state, oal_ntohl(mmap.util_pe.ipsec_state), sizeof(state));
-				len += oal_util_snprintf(buf + len, buf_len - len, "\nIPsec\n");
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE MU			0x%x\n", oal_ntohl(state.hse_mu));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE MU Channel    0x%x\n", oal_ntohl(state.hse_mu_chn));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_OK						0x%x\n", oal_ntohl(state.response_ok));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_VERIFY_FAILED			 0x%x\n", oal_ntohl(state.verify_failed));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_INVALID_DATA		0x%x\n", oal_ntohl(state.ipsec_invalid_data));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_REPLAY_DETECTED     0x%x\n", oal_ntohl(state.ipsec_replay_detected));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_REPLAY_LATE		 0x%x\n", oal_ntohl(state.ipsec_replay_late));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_SEQNUM_OVERFLOW     0x%x\n", oal_ntohl(state.ipsec_seqnum_overflow));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_CE_DROP			 0x%x\n", oal_ntohl(state.ipsec_ce_drop));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_TTL_EXCEEDED		0x%x\n", oal_ntohl(state.ipsec_ttl_exceeded));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_VALID_DUMMY_PAYLOAD 0x%x\n", oal_ntohl(state.ipsec_valid_dummy_payload));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_HEADER_LEN_OVERFLOW 0x%x\n", oal_ntohl(state.ipsec_header_overflow));
-				len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_PADDING_CHECK_FAIL  0x%x\n", oal_ntohl(state.ipsec_padding_check_fail));
-				len += oal_util_snprintf(buf + len, buf_len - len, "Code of handled error    0x%x\n", oal_ntohl(state.handled_error_code));
-				len += oal_util_snprintf(buf + len, buf_len - len, "SAId of handled error    0x%x\n", oal_ntohl(state.handled_error_said));
-				len += oal_util_snprintf(buf + len, buf_len - len, "Code of unhandled error  0x%x\n", oal_ntohl(state.unhandled_error_code));
-				len += oal_util_snprintf(buf + len, buf_len - len, "SAId of unhandled error  0x%x\n", oal_ntohl(state.unhandled_error_said));
+				text_stat_len = pfe_pe_get_text_statistics(util->pe[ii], buf + len, buf_len - len, verb_level);
+				if (0U == text_stat_len)
+				{
+					len = 0U;
+					break;
+				}
+				else
+				{
+					len += text_stat_len;
+					/* IPsec statistics */
+					pfe_pe_memcpy_from_dmem_to_host_32(util->pe[ii], &state, oal_ntohl(mmap.util_pe.ipsec_state), sizeof(state));
+					len += oal_util_snprintf(buf + len, buf_len - len, "\nIPsec\n");
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE MU            0x%x\n", oal_ntohl(state.hse_mu));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE MU Channel    0x%x\n", oal_ntohl(state.hse_mu_chn));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_OK                         0x%x\n", oal_ntohl(state.response_ok));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_VERIFY_FAILED              0x%x\n", oal_ntohl(state.verify_failed));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_INVALID_DATA         0x%x\n", oal_ntohl(state.ipsec_invalid_data));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_REPLAY_DETECTED      0x%x\n", oal_ntohl(state.ipsec_replay_detected));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_REPLAY_LATE          0x%x\n", oal_ntohl(state.ipsec_replay_late));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_SEQNUM_OVERFLOW      0x%x\n", oal_ntohl(state.ipsec_seqnum_overflow));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_CE_DROP              0x%x\n", oal_ntohl(state.ipsec_ce_drop));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_TTL_EXCEEDED         0x%x\n", oal_ntohl(state.ipsec_ttl_exceeded));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_VALID_DUMMY_PAYLOAD  0x%x\n", oal_ntohl(state.ipsec_valid_dummy_payload));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_HEADER_LEN_OVERFLOW  0x%x\n", oal_ntohl(state.ipsec_header_overflow));
+					len += oal_util_snprintf(buf + len, buf_len - len, "HSE_SRV_RSP_IPSEC_PADDING_CHECK_FAIL   0x%x\n", oal_ntohl(state.ipsec_padding_check_fail));
+					len += oal_util_snprintf(buf + len, buf_len - len, "Code of handled error    0x%x\n", oal_ntohl(state.handled_error_code));
+					len += oal_util_snprintf(buf + len, buf_len - len, "SAId of handled error    0x%x\n", oal_ntohl(state.handled_error_said));
+					len += oal_util_snprintf(buf + len, buf_len - len, "Code of unhandled error  0x%x\n", oal_ntohl(state.unhandled_error_code));
+					len += oal_util_snprintf(buf + len, buf_len - len, "SAId of unhandled error  0x%x\n", oal_ntohl(state.unhandled_error_said));
+				}
 			}
 		}
 	}
diff --git a/sw/xfci/libfci/Makefile b/sw/xfci/libfci/Makefile
index 91298f2..3459a66 100644
--- a/sw/xfci/libfci/Makefile
+++ b/sw/xfci/libfci/Makefile
@@ -1,5 +1,5 @@
 # =========================================================================
-#  Copyright 2018-2021 NXP
+#  Copyright 2018-2022 NXP
 #
 #  SPDX-License-Identifier: GPL-2.0
 #
@@ -45,6 +45,7 @@ INCLUDES += -I$(INC_PREFIX)src \
 			-I$(INC_PREFIX)public \
 			-I$(INC_PREFIX)../../common/public \
 			-I$(INC_PREFIX)../../hal/public \
+			-I$(INC_PREFIX)../../oal/public \
 			-I$(INC_PREFIX)../../fci/public \
 			-I$(INC_PREFIX)../../pfe_platform/public
 
diff --git a/sw/xfci/libfci/public/fpp_ext.h b/sw/xfci/libfci/public/fpp_ext.h
index 5dd352f..e84b4da 100644
--- a/sw/xfci/libfci/public/fpp_ext.h
+++ b/sw/xfci/libfci/public/fpp_ext.h
@@ -45,10 +45,10 @@
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Modify properties of a physical interface.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a physical interface query session and get properties 
+ *                   Initiate (or reinitiate) a physical interface query session and get properties
  *                   of the first physical interface from the internal list of physical interfaces.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
- *                   Continue the query session and get properties of the next physical interface 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
+ *                   Continue the query session and get properties of the next physical interface
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
  * @note
@@ -60,52 +60,52 @@
  * Modify properties of a physical interface. It is recommended to use the read-modify-write
  * approach (see @ref mgmt_phyif). Some properties cannot be modified (see fpp_phy_if_cmd_t).
  * @code{.c}
- *  .............................................  
- *  fpp_phy_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_phy_if_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UPDATE,  // Action
  *    .name   = "...",              // Interface name (see chapter Physical Interface)
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_phy_if_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_PHY_IF, sizeof(fpp_phy_if_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_PHY_IF, sizeof(fpp_phy_if_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of a physical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_phy_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_phy_if_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_phy_if_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_PHY_IF,
  *                  sizeof(fpp_phy_if_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first physical interface from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first physical interface from
  *  //  the internal list of physical interfaces.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_PHY_IF,
  *                  sizeof(fpp_phy_if_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next physical interface from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next physical interface from
  *  //  the internal list of physical interfaces.
- *  .............................................  
- * @endcode   
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -140,11 +140,11 @@
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Modify properties of a logical interface.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a logical interface query session and get properties 
- *                   of the first logical interface from the internal collective list of all 
+ *                   Initiate (or reinitiate) a logical interface query session and get properties
+ *                   of the first logical interface from the internal collective list of all
  *                   logical interfaces (regardless of physical interface affiliation).
- *              - @c FPP_ACTION_QUERY_CONT <br> 
- *                   Continue the query session and get properties of the next logical interface 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
+ *                   Continue the query session and get properties of the next logical interface
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
  * @note
@@ -153,22 +153,22 @@
  *
  * FPP_ACTION_REGISTER
  * -------------------
- * Create a new logical interface. The newly created interface is by default disabled and 
+ * Create a new logical interface. The newly created interface is by default disabled and
  * without any configuration. For configuration, see the following FPP_ACTION_UPDATE.
  * @code{.c}
- *  .............................................  
- *  fpp_log_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_log_if_cmd_t cmd_to_fci =
  *  {
  *    .action      = FPP_ACTION_REGISTER,  // Action
  *    .name        = "...",                // Interface name (user-defined)
  *    .parent_name = "..."                 // Parent physical interface name
  *                                         // (see chapter Physical Interface)
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  * @warning Do not create multiple logical interfaces with the same name.
  *
@@ -176,17 +176,17 @@
  * ---------------------
  * Remove (destroy) an existing logical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_log_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_log_if_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .name   = "..."                   // Name of an existing logical interface.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_UPDATE
@@ -194,52 +194,52 @@
  * Modify properties of a logical interface. It is recommended to use the read-modify-write
  * approach (see @ref mgmt_logif). Some properties cannot be modified (see fpp_log_if_cmd_t).
  * @code{.c}
- *  .............................................  
- *  fpp_log_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_log_if_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UPDATE,  // Action
  *    .name   = "...",              // Name of an existing logical interface.
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_log_if_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of a logical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_log_if_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_log_if_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_log_if_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_LOG_IF,
  *                  sizeof(fpp_log_if_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first logical interface from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first logical interface from
  *  //  the internal collective list of all logical interfaces.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_LOG_IF,
  *                  sizeof(fpp_log_if_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next logical interface from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next logical interface from
  *  //  the internal collective list of all logical interfaces.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -334,10 +334,10 @@
  * @details     Supported `.action` values: ---
  * <br>
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_IF_LOCK_SESSION, 0, NULL); 
- *  .............................................  
+ *  rtn = fci_write(client, FPP_CMD_IF_LOCK_SESSION, 0, NULL);
+ *  .............................................
  * @endcode
  *
  * Command return values
@@ -358,10 +358,10 @@
  * @details     Supported `.action` values: ---
  * <br>
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_IF_UNLOCK_SESSION, 0, NULL); 
- *  .............................................  
+ *  rtn = fci_write(client, FPP_CMD_IF_UNLOCK_SESSION, 0, NULL);
+ *  .............................................
  * @endcode
  *
  * Command return values
@@ -378,41 +378,41 @@
 /**
  * @brief       Interface flags
  * @details     Related data types: @ref fpp_phy_if_cmd_t, @ref fpp_log_if_cmd_t
- * @details     Some of these flags are applicable only for physical interfaces [phyif], 
- *              some are applicable only for logical interfaces [logif] and some are applicable 
+ * @details     Some of these flags are applicable only for physical interfaces [phyif],
+ *              some are applicable only for logical interfaces [logif] and some are applicable
  *              for both [phyif,logif].
  */
 typedef enum CAL_PACKED
 {
-    FPP_IF_ENABLED = (1 << 0),          /**< [phyif,logif] <br> 
+    FPP_IF_ENABLED = (1 << 0),          /**< [phyif,logif] <br>
                                              If set, the interface is enabled. */
-    FPP_IF_PROMISC = (1 << 1),          /**< [phyif,logif] <br> 
+    FPP_IF_PROMISC = (1 << 1),          /**< [phyif,logif] <br>
                                              If set, the interface is configured as promiscuous.
                                              - promiscuous phyif: all ingress traffic is accepted, regardless of destination MAC.
                                              - promiscuous logif: all inspected traffic is accepted, regardless of active match rules. */
-    FPP_IF_MATCH_OR = (1 << 3),         /**< [logif] <br> 
+    FPP_IF_MATCH_OR = (1 << 3),         /**< [logif] <br>
                                              If multiple match rules are active and this flag is set,
                                              then the final result of a match process is a logical OR of the rules.
                                              If this flag is @b not set, then the final result is a logical AND of the rules. */
-    FPP_IF_DISCARD = (1 << 4),          /**< [logif] <br> 
+    FPP_IF_DISCARD = (1 << 4),          /**< [logif] <br>
                                              If set, discard matching frames. */
     FPP_IF_MIRROR = (1 << 5),           /* DEPRECATED. Do not use.
-                                             [phyif] <br> 
+                                             [phyif] <br>
                                              If set, mirroring is enabled. */
     FPP_IF_LOADBALANCE = (1 << 6),      /* DEPRECATED. Do not use.
-                                             [phyif] <br> 
+                                             [phyif] <br>
                                              If set, the interface is a part of a loadbalance bucket. */
-    FPP_IF_VLAN_CONF_CHECK = (1 << 7),  /**< [phyif] <br> 
+    FPP_IF_VLAN_CONF_CHECK = (1 << 7),  /**< [phyif] <br>
                                              If set, the interface enforces a strict VLAN conformance check. */
-    FPP_IF_PTP_CONF_CHECK = (1 << 8),   /**< [phyif] <br> 
+    FPP_IF_PTP_CONF_CHECK = (1 << 8),   /**< [phyif] <br>
                                              If set, the interface enforces a strict PTP conformance check. */
-    FPP_IF_PTP_PROMISC = (1 << 9),      /**< [phyif] <br> 
+    FPP_IF_PTP_PROMISC = (1 << 9),      /**< [phyif] <br>
                                              If set, then PTP traffic is accepted even if the FPP_IF_VLAN_CONF_CHECK is set. */
-    FPP_IF_LOOPBACK = (1 << 10),        /**< [logif] <br> 
+    FPP_IF_LOOPBACK = (1 << 10),        /**< [logif] <br>
                                              If set, a loopback mode is enabled. */
-    FPP_IF_ALLOW_Q_IN_Q = (1 << 11),    /**< [phyif] <br> 
+    FPP_IF_ALLOW_Q_IN_Q = (1 << 11),    /**< [phyif] <br>
                                              If set, the interface accepts QinQ-tagged traffic. */
-    FPP_IF_DISCARD_TTL = (1 << 12),     /**< [phyif] <br> 
+    FPP_IF_DISCARD_TTL = (1 << 12),     /**< [phyif] <br>
                                              If set, then packets with TTL<2 are automatically discarded.
                                              If @b not set, then packets with TTL<2 are passed to the default logical interface. */
     FPP_IF_MAX = (int)(1U << 31U)
@@ -468,7 +468,7 @@ typedef enum CAL_PACKED
     FPP_IF_MATCH_DMAC = (1 << 30),        /**< Match destination MAC address (see fpp_if_m_args_t) */
     FPP_IF_MATCH_HIF_COOKIE = (int)(1U << 31U),  /**< Match HIF header cookie. HIF header cookie is a part of internal overhead data.
                                                       It is attached to traffic data by a host's PFE driver. */
-    
+
     /* Ensure proper size */
     FPP_IF_MATCH_MAX = (int)(1U << 31U)
 } fpp_if_m_rules_t;
@@ -488,7 +488,7 @@ typedef struct CAL_PACKED_ALIGNED(4)
     uint16_t ethtype;  /*< EtherType. [NBO]. See FPP_IF_MATCH_ETHTYPE. */
     uint16_t sport;    /*< L4 source port. [NBO]. See FPP_IF_MATCH_SPORT. */
     uint16_t dport;    /*< L4 destination port [NBO]. See FPP_IF_MATCH_DPORT. */
-    
+
     /* Source and destination IP addresses */
     struct
     {
@@ -497,14 +497,14 @@ typedef struct CAL_PACKED_ALIGNED(4)
             uint32_t sip;     /*< IPv4 source address. [NBO]. See FPP_IF_MATCH_SIP. */
             uint32_t dip;     /*< IPv4 destination address. [NBO]. See FPP_IF_MATCH_DIP. */
         } v4;
-    
+
         struct
         {
             uint32_t sip[4];  /*< IPv6 source address. [NBO]. See FPP_IF_MATCH_SIP6. */
             uint32_t dip[4];  /*< IPv6 destination address. [NBO]. See FPP_IF_MATCH_DIP6. */
         } v6;
     } ipv;
-    
+
     uint8_t proto;        /*< IP Protocol Number (protocol ID). See FPP_IF_MATCH_PROTO. */
     uint8_t smac[6];      /*< Source MAC Address. See FPP_IF_MATCH_SMAC. */
     uint8_t dmac[6];      /*< Destination MAC Address. See FPP_IF_MATCH_DMAC. */
@@ -551,8 +551,8 @@ typedef struct CAL_PACKED_ALIGNED(4)
 /**
  * @brief       Physical interface blocking state.
  * @details     Related data types: @ref fpp_phy_if_cmd_t
- * @details     Used when a physical interface is configured in a Bridge-like mode.    
- *              See @ref l2_bridge and @ref l2l3_bridge. Affects the following Bridge-related 
+ * @details     Used when a physical interface is configured in a Bridge-like mode.
+ *              See @ref l2_bridge and @ref l2l3_bridge. Affects the following Bridge-related
  *              capabilities of a physical interface:
  *              - Learning of MAC addresses from the interface's ingress traffic.
  *              - Forwarding of the interface's ingress traffic.
@@ -563,7 +563,7 @@ typedef enum CAL_PACKED
     BS_BLOCKED = 1,      /**< Learning and forwarding disabled. */
     BS_LEARN_ONLY = 2,   /**< Learning enabled, forwarding disabled. */
     BS_FORWARD_ONLY = 3  /**< Learning disabled, forwarding enabled. <br>
-                              Traffic is forwarded only if its both source and destination MAC addresses 
+                              Traffic is forwarded only if its both source and destination MAC addresses
                               are known to the bridge. */
 } fpp_phy_if_block_state_t;
 
@@ -589,18 +589,18 @@ typedef struct CAL_PACKED_ALIGNED(4)
     fpp_phy_if_op_mode_t mode;  /*< Interface mode. */
     fpp_phy_if_block_state_t block_state;  /*< Interface blocking state. */
     fpp_phy_if_stats_t stats;   /*< Physical interface statistics. [ro] */
-    
+
     /* Names of associated mirroring rules for ingress traffic. See FPP_CMD_MIRROR.
        Empty string at given position == position is disabled. */
     char rx_mirrors[FPP_MIRRORS_CNT][MIRROR_NAME_SIZE];
-    
+
     /* Names of associated mirroring rules for egress traffic. See FPP_CMD_MIRROR.
        Empty string at given position == position is disabled. */
     char tx_mirrors[FPP_MIRRORS_CNT][MIRROR_NAME_SIZE];
-    
-    char ftable[16];    /*< Name of a Flexible Parser table which shall be used 
+
+    char ftable[16];    /*< Name of a Flexible Parser table which shall be used
                             as a Flexible Filter of this physical interface.
-                            Empty string == Flexible filter is disabled. 
+                            Empty string == Flexible filter is disabled.
                             See Flexible Parser for more info. */
 } fpp_phy_if_cmd_t;
 /* [fpp_phy_if_cmd_t] */
@@ -622,12 +622,12 @@ typedef struct CAL_PACKED_ALIGNED(4)
     uint32_t id;                /*< Interface ID. [NBO,ro] */
     char parent_name[IFNAMSIZ]; /*< Parent physical interface name. [ro] */
     uint32_t parent_id;         /*< Parent physical interface ID. [NBO,ro] */
-    
+
     uint32_t egress;            /*< Egress physical interfaces. [NBO]. A bitset.
-                                    Each physical interface is represented by a bitflag. 
+                                    Each physical interface is represented by a bitflag.
                                     Conversion between a physical interface ID and a corr-
                                     esponding bitflag is (1uL << "physical interface ID"). */
-    
+
     fpp_if_flags_t flags;       /*< Interface flags. [NBO]. A bitset. */
     fpp_if_m_rules_t match;     /*< Match rules. [NBO]. A bitset. */
     fpp_if_m_args_t CAL_PACKED_ALIGNED(4) arguments;  /*< Match rules arguments. */
@@ -648,9 +648,9 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_QUERY <br>
  *                   Initiate (or reinitiate) a MAC address query session and get
  *                   the first MAC address of the requested interface.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get the next MAC address
- *                   of the requested interface. Intended to be called in a loop 
+ *                   of the requested interface. Intended to be called in a loop
  *                   (to iterate through the list).
  *
  * @note
@@ -664,67 +664,67 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -------------------
  * Add a new MAC address to emac physical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_if_mac_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_if_mac_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_REGISTER,  // Action
  *    .name   = "...",                // Physical interface name
  *    .mac    = {...}                 // Physical interface MAC
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove an existing MAC address from emac physical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_if_mac_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_if_mac_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .name   = "...",                  // Physical interface name
  *    .mac    = {...}                   // Physical interface MAC
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get MAC addresses of a requested emac physical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_if_mac_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_if_mac_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *    .name   = "...",            // Physical interface name
  *  };
- *    
+ *
  *  fpp_if_mac_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_IF_MAC,
  *                  sizeof(fpp_if_mac_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds the first MAC address of the requested physical interface.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_IF_MAC,
  *                  sizeof(fpp_if_mac_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds the next MAC address of the requested physical interface.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -743,7 +743,7 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *        Some other client has the interface database locked for exclusive access.
  * - @c FPP_ERR_INTERNAL_FAILURE <br>
  *        Internal FCI failure.
- * 
+ *
  * @hideinitializer
  */
 #define FPP_CMD_IF_MAC							0xf120
@@ -779,49 +779,49 @@ typedef struct CAL_PACKED_ALIGNED(2)
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Modify properties of a mirroring rule.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a mirroring rule query session and get properties 
+ *                   Initiate (or reinitiate) a mirroring rule query session and get properties
  *                   of the first mirroring rule from the internal list of mirroring rules.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next mirroring rule
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
  * FPP_ACTION_REGISTER
  * -------------------
- * Create a new mirroring rule. When creating a new mirroring rule, it is also possible to 
+ * Create a new mirroring rule. When creating a new mirroring rule, it is also possible to
  * simultaneously set its properties (using the same rules which apply to @ref FPP_ACTION_UPDATE).
  * @code{.c}
- *  .............................................  
- *  fpp_mirror_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_mirror_cmd_t cmd_to_fci =
  *  {
  *    .action        = FPP_ACTION_REGISTER, // Action
  *    .name          = "...",               // Name of the mirroring rule.
  *    .egress_phy_if = "...",               // Name of the physical interface where to mirror.
- *      
+ *
  *    // optional
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing mirroring rule.
  * @code{.c}
- *  .............................................  
- *  fpp_mirror_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_mirror_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .name   = "...",                  // Name of the mirroring rule.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_UPDATE
@@ -829,52 +829,52 @@ typedef struct CAL_PACKED_ALIGNED(2)
  * Modify properties of a mirroring rule. It is recommended to use the read-modify-write
  * approach. Some properties cannot be modified (see fpp_mirror_cmd_t).
  * @code{.c}
- *  .............................................  
- *  fpp_mirror_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_mirror_cmd_t cmd_to_fci =
  *  {
  *    .action        = FPP_ACTION_REGISTER, // Action
  *    .name          = "...",               // Name of the mirroring rule.
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_mirror_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
  *                                         (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of a mirroring rule.
  * @code{.c}
- *  .............................................  
- *  fpp_mirror_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_mirror_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_mirror_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_MIRROR,
  *                  sizeof(fpp_mirror_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first mirroring rule from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first mirroring rule from
  *  //  the internal list of mirroring rules.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_MIRROR,
  *                  sizeof(fpp_mirror_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next mirroring rule from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next mirroring rule from
  *  //  the internal list of mirroring rules.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -891,7 +891,7 @@ typedef struct CAL_PACKED_ALIGNED(2)
  *        Unknown (nonexistent) physical interface in the `.egress_phy_if` property.
  * - @c FPP_ERR_INTERNAL_FAILURE <br>
  *        Internal FCI failure.
- * 
+ *
  * @hideinitializer
  */
 #define FPP_CMD_MIRROR						0xf130
@@ -907,7 +907,7 @@ typedef enum CAL_PACKED
 {
     MODIFY_ACT_NONE = 0U,                   /**< No action to be done. */
     MODIFY_ACT_ADD_VLAN_HDR = (1U << 1),    /**< Construct/Update outer VLAN Header. */
-    
+
     /* Ensure proper size */
     MODIFY_ACT_INVALID = (int)(1U << 31)
 } fpp_modify_actions_t;
@@ -940,12 +940,12 @@ typedef struct CAL_PACKED_ALIGNED(4)
     uint16_t action;               /*< Action */
     char name[MIRROR_NAME_SIZE];   /*< Name of the mirroring rule. [ro] */
     char egress_phy_if[IFNAMSIZ];  /*< Name of the physical interface where to mirror. */
-    
+
     char filter_table_name[16];	   /*< Name of a Flexible Parser table that can be used
                                        to filter which frames to mirror.
                                        Empty string == disabled (no filtering).
                                        See Flexible Parser for more info. */
-    
+
     fpp_modify_actions_t m_actions;  /*< Modifications to be done on mirrored frame. [NBO] */
     fpp_modify_args_t    m_args;     /*< Configuration values (arguments) for m_actions. */
 } fpp_mirror_cmd_t;
@@ -964,48 +964,48 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Modify properties of a bridge domain.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a bridge domain query session and get properties 
+ *                   Initiate (or reinitiate) a bridge domain query session and get properties
  *                   of the first bridge domain from the internal list of bridge domains.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next bridge domain
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
  * FPP_ACTION_REGISTER
  * -------------------
- * Create a new bridge domain. When creating a new bridge domain, it is also possible to 
+ * Create a new bridge domain. When creating a new bridge domain, it is also possible to
  * simultaneously set its properties (using the same rules which apply to @ref FPP_ACTION_UPDATE).
  * @code{.c}
- *  .............................................  
- *  fpp_l2_bd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_bd_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_REGISTER,  // Action
  *    .vlan   = ...,                  // VLAN ID of a new bridge domain. [NBO] (user-defined)
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_l2_bd_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
  *                                        (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing bridge domain.
  * @code{.c}
- *  .............................................  
- *  fpp_l2_bd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_bd_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .vlan   = ...,                    // VLAN ID of an existing bridge domain. [NBO]
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
  *                                        (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_UPDATE
@@ -1013,52 +1013,52 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * Modify properties of a logical interface. It is recommended to use the read-modify-write
  * approach. Some properties cannot be modified (see fpp_l2_bd_cmd_t).
  * @code{.c}
- *  .............................................  
- *  fpp_l2_bd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_bd_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UPDATE,  // Action
  *    .vlan   = ...,                // VLAN ID of an existing bridge domain. [NBO]
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_l2_bd_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
  *                                        (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of a bridge domain.
  * @code{.c}
- *  .............................................  
- *  fpp_l2_bd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_bd_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_l2_bd_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_L2_BD,
  *                  sizeof(fpp_l2_bd_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first bridge domain from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first bridge domain from
  *  //  the internal list of bridge domains.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_L2_BD,
  *                  sizeof(fpp_l2_bd_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next bridge domain from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next bridge domain from
  *  //  the internal list of bridge domains.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -1073,7 +1073,7 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *        Unexpected value of some property.
  * - @c FPP_ERR_INTERNAL_FAILURE <br>
  *        Internal FCI failure.
- * 
+ *
  * @hideinitializer
  */
 #define FPP_CMD_L2_BD						0xf200
@@ -1112,36 +1112,36 @@ typedef struct CAL_PACKED_ALIGNED(2)
 {
     uint16_t action;    /*< Action */
     uint16_t vlan;      /*< Bridge domain VLAN ID. [NBO,ro] */
-    
-    uint8_t ucast_hit;  /*< Bridge domain action when the destination MAC of an inspected 
-                            frame is an unicast MAC and it matches some entry in the 
+
+    uint8_t ucast_hit;  /*< Bridge domain action when the destination MAC of an inspected
+                            frame is an unicast MAC and it matches some entry in the
                             Bridge MAC table. */
-    
-    uint8_t ucast_miss; /*< Bridge domain action when the destination MAC of an inspected 
-                            frame is an unicast MAC and it does NOT match any entry in the 
+
+    uint8_t ucast_miss; /*< Bridge domain action when the destination MAC of an inspected
+                            frame is an unicast MAC and it does NOT match any entry in the
                             Bridge MAC table. */
-    
-    uint8_t mcast_hit;  /*< Similar to ucast_hit, but for frames which have a multicast 
+
+    uint8_t mcast_hit;  /*< Similar to ucast_hit, but for frames which have a multicast
                             destination MAC address. */
-    
-    uint8_t mcast_miss; /*< Similar to ucast_miss, but for frames which have a multicast 
+
+    uint8_t mcast_miss; /*< Similar to ucast_miss, but for frames which have a multicast
                             destination MAC address. */
-    
+
     uint32_t if_list;   /*< Bridge domain ports. [NBO]. A bitset.
                             Ports are represented by physical interface bitflags.
                             If a bitflag of some physical interface is set here, the interface
                             is then considered a port of the given bridge domain.
                             Conversion between a physical interface ID and a corresponding
                             bitflag is (1uL << "physical interface ID"). */
-    
-    uint32_t untag_if_list; /*< A bitset [NBO], denoting which bridge domain ports from 
-                                '.if_list' are considered untagged (their egress frames 
+
+    uint32_t untag_if_list; /*< A bitset [NBO], denoting which bridge domain ports from
+                                '.if_list' are considered untagged (their egress frames
                                 have the VLAN tag removed).
-                                Ports which are present in both the '.if_list' bitset and 
+                                Ports which are present in both the '.if_list' bitset and
                                 this bitset are considered untagged.
                                 Ports which are present only in the '.if_list' bitset are
                                 considered tagged. */
-    
+
     fpp_l2_bd_flags_t flags;  /*< Bridge domain flags [NBO,ro] */
 } fpp_l2_bd_cmd_t;
 /* [fpp_l2_bd_cmd_t] */
@@ -1159,15 +1159,15 @@ typedef struct CAL_PACKED_ALIGNED(2)
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Modify properties of a static entry.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) static entry query session and get properties 
- *                   of the first static entry from the internal collective list of all 
+ *                   Initiate (or reinitiate) static entry query session and get properties
+ *                   of the first static entry from the internal collective list of all
  *                   L2 static entries (regardless of bridge domain affiliation).
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next static entry
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
  * @note
- * When using this command, it is recommended to disable dynamic learning of MAC addresses on all 
+ * When using this command, it is recommended to disable dynamic learning of MAC addresses on all
  * physical interfaces which are configured to be a part of @ref l2_bridge or @ref l2l3_bridge.
  * See @ref FPP_CMD_PHY_IF and @ref fpp_phy_if_block_state_t.
  *
@@ -1175,37 +1175,37 @@ typedef struct CAL_PACKED_ALIGNED(2)
  * -------------------
  * Create a new L2 static entry.
  * @code{.c}
- *  .............................................  
- *  fpp_l2_static_ent_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_static_ent_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_REGISTER,  // Action
  *    .vlan   = ...,                  // VLAN ID of an associated bridge domain. [NBO]
  *    .mac    = ...,                  // Static entry MAC address.
  *    .forward_list = ...             // Egress physical interfaces. [NBO]
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
  *                                                (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing L2 static entry.
  * @code{.c}
- *  .............................................  
- *  fpp_l2_static_ent_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_static_ent_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .vlan   = ...,                    // VLAN ID of an associated bridge domain. [NBO]
  *    .mac    = ...                     // Static entry MAC address.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
  *                                                (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_UPDATE
@@ -1213,53 +1213,53 @@ typedef struct CAL_PACKED_ALIGNED(2)
  * Modify properties of L2 static entry. It is recommended to use the read-modify-write
  * approach. Some properties cannot be modified (see fpp_l2_static_ent_cmd_t).
  * @code{.c}
- *  .............................................  
- *  fpp_l2_static_ent_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_static_ent_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UPDATE,  // Action
  *    .vlan   = ...,                // VLAN ID of an associated bridge domain. [NBO]
  *    .mac    = ...,                // Static entry MAC address.
- *    
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_l2_static_ent_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
  *                                                (unsigned short*)(&cmd_to_fci));
- *  ............................................. 
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of L2 static entry.
  * @code{.c}
- *  .............................................  
- *  fpp_l2_static_ent_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_l2_static_ent_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_l2_static_ent_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_L2_STATIC_ENT,
  *                  sizeof(fpp_l2_static_ent_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the first static entry from
  *  //  the internal collective list of all static entries.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_L2_STATIC_ENT,
  *                  sizeof(fpp_l2_static_ent_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next static entry from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next static entry from
  *  //  the internal collective list of all static entries.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -1292,31 +1292,31 @@ typedef struct CAL_PACKED_ALIGNED(2)
 typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;        /*< Action */
-    
-    uint16_t vlan;          /*< VLAN ID of an associated bridge domain. [NBO,ro] 
-                                VLAN-aware static entries are applied only on frames 
+
+    uint16_t vlan;          /*< VLAN ID of an associated bridge domain. [NBO,ro]
+                                VLAN-aware static entries are applied only on frames
                                 which have a matching VLAN tag.
-                                For non-VLAN aware static entries, use VLAN ID of 
+                                For non-VLAN aware static entries, use VLAN ID of
                                 the Default BD (Default Bridge Domain). */
-    
+
     uint8_t mac[6];         /*< Static entry MAC address. [ro] */
-    
+
     uint32_t forward_list;  /*< Egress physical interfaces. [NBO]. A bitset.
                                 Frames with matching destination MAC address (and VLAN tag)
                                 are forwarded through all physical interfaces which are a part
-                                of this bitset. Physical interfaces are represented by 
-                                bitflags. Conversion between a physical interface ID and 
+                                of this bitset. Physical interfaces are represented by
+                                bitflags. Conversion between a physical interface ID and
                                 a corresponding bitflag is (1uL << "physical interface ID").*/
-    
+
     uint8_t local;          /*< Local MAC address. (0 == false, 1 == true)
-                                A part of L2L3 Bridge feature. If true, then the forward list 
-                                of such a static entry is ignored and frames with 
-                                a corresponding destination MAC address are passed to 
+                                A part of L2L3 Bridge feature. If true, then the forward list
+                                of such a static entry is ignored and frames with
+                                a corresponding destination MAC address are passed to
                                 the IP router algorithm. See chapter about L2L3 Bridge. */
-    
+
     uint8_t dst_discard;    /*< Frames with matching destination MAC address (and VLAN tag)
                                 shall be discarded. (0 == disabled, 1 == enabled) */
-    
+
     uint8_t src_discard;    /*< Frames with matching source MAC address (and VLAN tag)
                                 shall be discarded. (0 == disabled, 1 == enabled) */
 } fpp_l2_static_ent_cmd_t;
@@ -1329,10 +1329,10 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * @details     Supported `.action` values: ---
  * <br>
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_LEARNED, 0, NULL); 
- *  .............................................  
+ *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_LEARNED, 0, NULL);
+ *  .............................................
  * @endcode
  *
  * Command return values
@@ -1353,10 +1353,10 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * @details     Supported `.action` values: ---
  * <br>
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_STATIC, 0, NULL); 
- *  .............................................  
+ *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_STATIC, 0, NULL);
+ *  .............................................
  * @endcode
  *
  * Command return values
@@ -1377,10 +1377,10 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * @details     Supported `.action` values: ---
  * <br>
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_ALL, 0, NULL); 
- *  .............................................  
+ *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_ALL, 0, NULL);
+ *  .............................................
  * @endcode
  *
  * Command return values
@@ -1409,45 +1409,45 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_UNUSE_RULE <br>
  *                   Remove an FP rule from an FP table.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) an FP table query session and get properties 
+ *                   Initiate (or reinitiate) an FP table query session and get properties
  *                   of the first FP @b rule from the requested FP table.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next FP @b rule
- *                   from the requested FP table. Intended to be called in a loop 
+ *                   from the requested FP table. Intended to be called in a loop
  *                   (to iterate through the requested FP table).
  *
  * FPP_ACTION_REGISTER
  * -------------------
  * Create a new FP table.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_table_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_table_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_REGISTER,    // Action
  *    .table_info.t.table_name = "..."  // Name of a new FP table.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
  *                                                  (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing FP table.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_table_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_table_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .table_info.t.table_name = "..."  // Name of an existing FP table.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
  *                                                  (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  * @note FP table cannot be destroyed if it is in use by some PFE feature.
  *       First remove the table from use, then destroy it.
@@ -1457,23 +1457,23 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * Insert an FP rule at the specified position in an FP table.
  * - If there are already some rules in the table, they are shifted accordingly to make room
  *   for the newly inserted rule.
- * - If the desired position is greater than the count of all rules in the table, the newly 
+ * - If the desired position is greater than the count of all rules in the table, the newly
  *   inserted rule is placed as the last rule of the table.
- * 
+ *
  * @code{.c}
- *  .............................................  
- *  fpp_fp_table_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_table_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_USE_RULE,     // Action
  *    .table_info.t.table_name = "...",  // Name of an existing FP table.
  *    .table_info.t.rule_name  = "...",  // Name of an existing FP rule.
  *    .table_info.t.position   = ...     // Desired position of the rule in the table.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
  *                                                  (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  * @note Each FP rule can be assigned only to one FP table (cannot be simultaneously a member of multiple FP tables).
  *
@@ -1481,18 +1481,18 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * ---------------------
  * Remove an FP rule from an FP table.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_table_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_table_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UNUSE_RULE,   // Action
  *    .table_info.t.table_name = "...",  // Name of an existing FP table.
  *    .table_info.t.rule_name  = "...",  // Name of an FP rule which is a member of the table.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
  *                                                  (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
@@ -1500,35 +1500,35 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * Get properties of an FP @b rule from the requested FP table.
  * Query result (properties of the @b rule) is stored in the member `.table_info.r`.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_table_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_table_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY         // Action
  *    .table_info.t.table_name = "...",  // Name of an existing FP table.
  *  };
- *    
+ *
  *  fpp_fp_table_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_FP_TABLE,
  *                  sizeof(fpp_fp_table_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci.table_info.r' now holds properties of the first FP rule from
  *  //  the requested FP table.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_FP_TABLE,
  *                  sizeof(fpp_fp_table_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci.table_info.r' now holds properties of the next FP rule from 
+ *
+ *  // 'reply_from_fci.table_info.r' now holds properties of the next FP rule from
  *  //  the requested FP table.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  * @note There is currently no way to read a list of existing FP tables from PFE.
- * 
+ *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
  * - @c FPP_ERR_OK <br>
@@ -1544,7 +1544,7 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *        Unexpected value of some property.
  * - @c FPP_ERR_INTERNAL_FAILURE <br>
  *        Internal FCI failure.
- * 
+ *
  * @hideinitializer
  */
 #define FPP_CMD_FP_TABLE						0xf220
@@ -1555,10 +1555,10 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * @details     Related topics: @ref flex_parser
  * @details     Related data types: @ref fpp_fp_rule_cmd_t, @ref fpp_fp_rule_props_t
  * @details     Each FP rule consists of a condition specified by the following properties:
- *              `.data`, `.mask` and `.offset` + `.offset_from`. FP rule then works as follows: 
- *              32-bit data value from the inspected Ethernet frame (at given @c offset_from + 
- *              @c offset position, masked by the @c mask) is compared with the @c data value 
- *              (masked by the same @c mask). If the values are equal, then condition of the FP rule 
+ *              `.data`, `.mask` and `.offset` + `.offset_from`. FP rule then works as follows:
+ *              32-bit data value from the inspected Ethernet frame (at given @c offset_from +
+ *              @c offset position, masked by the @c mask) is compared with the @c data value
+ *              (masked by the same @c mask). If the values are equal, then condition of the FP rule
  *              is true. An invert flag may be set to invert the condition result.
  * @details     Supported `.action` values:
  *              - @c FPP_ACTION_REGISTER <br>
@@ -1566,10 +1566,10 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_DEREGISTER <br>
  *                   Remove (destroy) an existing FP rule.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) an FP rule query session and get properties 
- *                   of the first FP rule from the internal collective list of all 
+ *                   Initiate (or reinitiate) an FP rule query session and get properties
+ *                   of the first FP rule from the internal collective list of all
  *                   FP rules (regardless of FP table affiliation).
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next FP rule
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
@@ -1577,8 +1577,8 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -------------------
  * Create a new FP rule. For detailed info about FP rule properties, see fpp_fp_rule_cmd_t.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_rule_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_rule_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_REGISTER,  // Action
  *    .r.rule_name = "...",           // Rule name. A string of up to 15 characters + '\0'.
@@ -1586,37 +1586,37 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *    .r.mask      = ...,             // Bitmask. [NBO]
  *    .r.offset    = ...,             // Offset (in bytes). [NBO]
  *    .r.invert    = ...,             // Invert the match result.
- *    
+ *
  *    .r.next_rule_name = "...",      // Name of the FP rule to jump to if '.match_action' ==
  *                                    // FP_NEXT_RULE. Set all-zero if unused.
- *    
+ *
  *    .r.match_action = ...,          // Action to do if the inspected frame matches
  *                                    // the FP rule criteria.
- *    
+ *
  *    .r.offset_from = ...            // Header for offset calculation.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t),
  *                                                 (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing FP rule.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_rule_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_rule_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_DEREGISTER,  // Action
  *    .r.rule_name = "...",             // Name of an existing FP rule.
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t),
  *                                                 (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  * @note FP rule cannot be destroyed if it is a member of some FP table.
  *       First remove the rule from the table, then destroy the rule.
@@ -1625,32 +1625,32 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * ------------------------------------------
  * Get properties of an FP rule. Query result is stored in the member `.r`.
  * @code{.c}
- *  .............................................  
- *  fpp_fp_rule_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fp_rule_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_fp_rule_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_FP_RULE,
  *                  sizeof(fpp_fp_rule_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci.r' now holds properties of the first FP rule from
  *  //  the internal collective list of all FP rules.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_FP_RULE,
  *                  sizeof(fpp_fp_rule_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci.r' now holds properties of the next FP rule from 
+ *
+ *  // 'reply_from_fci.r' now holds properties of the next FP rule from
  *  //  the internal collective list of all FP rules.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -1700,7 +1700,7 @@ typedef enum CAL_PACKED
 {
     FP_ACCEPT,    /**< Flexible Parser accepts the frame. */
     FP_REJECT,    /**< Flexible Parser rejects the frame. */
-    FP_NEXT_RULE  /**< Flexible Parser continues with the matching process, but jumps to 
+    FP_NEXT_RULE  /**< Flexible Parser continues with the matching process, but jumps to
                        a specific FP rule in the FP table. */
 } fpp_fp_rule_match_action_t;
 
@@ -1710,8 +1710,8 @@ typedef enum CAL_PACKED
  * @details     Offset can be calculated either from the L2, L3 or L4 header beginning.
  *              The L2 header is also the beginning of an Ethernet frame.
  * @details     L2 header is always a valid header for offset calculation. Other headers may be missing
- *              in some Ethernet frames. If an FP rule expects L3/L4 header (for offset calculation) 
- *              but the given header is missing in the inspected Ethernet frame, then the result 
+ *              in some Ethernet frames. If an FP rule expects L3/L4 header (for offset calculation)
+ *              but the given header is missing in the inspected Ethernet frame, then the result
  *              of the matching process is "frame does not match FP rule criteria".
  */
 typedef enum CAL_PACKED
@@ -1732,26 +1732,26 @@ typedef enum CAL_PACKED
 typedef struct CAL_PACKED
 {
     uint8_t rule_name[16];  /*< Rule name. A string of up to 15 characters + '\0'. */
-    
+
     uint32_t data;          /*< Expected data. [NBO]. This value is expected to be found
                                 at the specified offset in the inspected Ethernet frame. */
-    
+
     uint32_t mask;          /*< Bitmask [NBO], selecting which bits of a 32bit value shall
                                 be used for data comparison. This bitmask is applied on both
                                 '.data' value and the inspected value for the frame. */
-    
+
     uint16_t offset;        /*< Offset (in bytes) of the inspected value in the frame. [NBO]
                                 This offset is calculated from the '.offset_from' header. */
-    
+
     uint8_t invert;         /*< Invert the match result before match action is selected. */
-    
+
     uint8_t next_rule_name[16];  /*< Name of the FP rule to jump to if '.match_action' ==
                                      FP_NEXT_RULE. Set all-zero if unused. This next rule must
                                      be in the same FP table (cannot jump across tables). */
-    
-    fpp_fp_rule_match_action_t match_action;  /*< Action to do if the inspected frame 
+
+    fpp_fp_rule_match_action_t match_action;  /*< Action to do if the inspected frame
                                                   matches the FP rule criteria. */
-    
+
     fpp_fp_offset_from_t offset_from;  /*< Header for offset calculation. */
 } fpp_fp_rule_props_t;
 /* [fpp_fp_rule_props_t] */
@@ -1922,9 +1922,9 @@ typedef struct CAL_PACKED
  *              - @c FPP_ACTION_DEREGISTER <br>
  *                   Remove (destroy) an existing SPD entry.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) an SPD entry query session and get properties 
+ *                   Initiate (or reinitiate) an SPD entry query session and get properties
  *                   of the first SPD entry from the SPD database of a target physical interface.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next SPD entry
  *                   from the SPD database of the target physical interface.
  *                   Intended to be called in a loop (to iterate through the database).
@@ -1938,86 +1938,86 @@ typedef struct CAL_PACKED
  * -------------------
  * Create a new SPD entry in the SPD database of a target physical interface.
  * @code{.c}
- *  .............................................  
- *  fpp_spd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_spd_cmd_t cmd_to_fci =
  *  {
  *    .action   = FPP_ACTION_REGISTER,  // Action
- *      
+ *
  *    .name     = "...",  // Physical interface name (see chapter Physical Interface).
  *    .flags    =  ...,   // SPD entry flags. A bitset.
  *    .position =  ...,   // Entry position. [NBO]
  *    .saddr    = {...},  // Source IP address. [NBO]
  *    .daddr    = {...},  // Destination IP address. [NBO]
- *      
+ *
  *    .sport    =  ...,   // Source port. [NBO]
  *                        // Optional (does not have to be set). See '.flags'.
- *      
+ *
  *    .dport    =  ...,   // Destination port. [NBO]
  *                        // Optional (does not have to be set). See '.flags'.
- *      
+ *
  *    .protocol =  ...,   // IANA IP Protocol Number (protocol ID).
- *      
+ *
  *    .sa_id    =  ...,   // SAD entry identifier for HSE. [NBO]
- *                        // Used only when '.spd_action' == SPD_ACT_PROCESS_ENCODE). 
- *      
+ *                        // Used only when '.spd_action' == SPD_ACT_PROCESS_ENCODE).
+ *
  *    .spi      =  ...    // SPI to match in the ingress traffic. [NBO]
  *                        // Used only when '.spd_action' == SPD_ACT_PROCESS_DECODE).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t), 
+ *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t),
  *                                     (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove (destroy) an existing SPD entry.
  * @code{.c}
- *  .............................................  
- *  fpp_spd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_spd_cmd_t cmd_to_fci =
  *  {
  *    .action   = FPP_ACTION_DEREGISTER,  // Action
  *    .name     = "...",  // Physical interface name (see chapter Physical Interface).
  *    .position =  ...,   // Entry position. [NBO]
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t), 
+ *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t),
  *                                     (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of an SPD entry.
  * @code{.c}
- *  .............................................  
- *  fpp_spd_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_spd_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *    .name   = "...",  // Physical interface name (see chapter Physical Interface).
  *  };
- *    
+ *
  *  fpp_spd_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_SPD,
  *                  sizeof(fpp_spd_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first SPD entry from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first SPD entry from
  *  //  the SPD database of the target physical interface..
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_SPD,
  *                  sizeof(fpp_spd_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next SPD entry from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next SPD entry from
  *  //  the SPD database of the target physical interface.
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * Command return values (for all applicable ACTIONs)
@@ -2075,36 +2075,36 @@ typedef struct CAL_PACKED_ALIGNED(4)
     uint16_t action;        /*< Action */
     char name[IFNAMSIZ];    /*< Physical interface name. */
     fpp_spd_flags_t flags;  /*< SPD entry flags. A bitset. */
-    
+
     uint16_t position;      /*< Entry position. [NBO]
                                 0 : insert as the first entry of the SPD table.
                                 N : insert as the Nth entry of the SPD table, starting from 0.
-                                Entries are inserted (not overwritten). Already existing 
+                                Entries are inserted (not overwritten). Already existing
                                 entries are shifted to make room for the newly inserted one.
                                 If (N > current count of SPD entries) then the new entry
                                 gets inserted as the last entry of the SPD table. */
-    
+
     uint32_t saddr[4];      /*< Source IP address. [NBO]
                                 IPv4 uses only element [0]. Address type is set in '.flags' */
-    
+
     uint32_t daddr[4];      /*< Destination IP address. [NBO]
                                 IPv4 uses only element [0]. Address type is set in '.flags' */
-    
+
     uint16_t sport;         /*< Source port. [NBO]
                                 Optional (does not have to be set). See '.flags' */
-    
+
     uint16_t dport;         /*< Destination port. [NBO]
                                 Optional (does not have to be set). See '.flags' */
-                                
+
     uint8_t protocol;       /*< IANA IP Protocol Number (protocol ID). */
-    
+
     uint32_t sa_id;         /*< SAD entry identifier for HSE. [NBO]
                                 Used only when '.spd_action' == SPD_ACT_PROCESS_ENCODE).
                                 Corresponding SAD entry must exist in HSE. */
-                                
+
     uint32_t spi;           /*< SPI to match in the ingress traffic. [NBO]
                                 Used only when '.spd_action' == SPD_ACT_PROCESS_DECODE). */
-    
+
     fpp_spd_action_t spd_action;  /*< Action to be done on the frame. */
 } fpp_spd_cmd_t;
 /* [fpp_spd_cmd_t] */
@@ -2124,46 +2124,46 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Modify properties of an Egress QoS queue.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_queue_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_queue_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_UPDATE,  // Action
  *    .if_name = "...",              // Physical interface name.
  *    .id      =  ...,               // Queue ID.
- *      
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_qos_queue_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_QOS_QUEUE, sizeof(fpp_qos_queue_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_QOS_QUEUE, sizeof(fpp_qos_queue_cmd_t),
  *                                            (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get properties of a target Egress QoS queue.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_queue_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_queue_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY  // Action
  *    .if_name = "...",            // Physical interface name.
  *    .id      =  ...              // Queue ID.
  *  };
- *    
+ *
  *  fpp_qos_queue_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_QUEUE,
  *                  sizeof(fpp_qos_queue_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the target Egress QoS queue.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
   * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -2171,6 +2171,9 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *        Success
  * - @c FPP_ERR_QOS_QUEUE_NOT_FOUND <br>
  *        Unknown (nonexistent) Egress QoS queue was requested.
+ * - @c FPP_ERR_QOS_QUEUE_SUM_OF_LENGTHS_EXCEEDED <br>
+ *        Sum of all Egress QoS queue lengths for a given physical interface would exceed limits of the interface.
+ *        First shorten some other queues of the interface, then lengthen the queue of interest.
  * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
  *        Unexpected value of some property.
  * - @c FPP_ERR_INTERNAL_FAILURE <br>
@@ -2206,37 +2209,37 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;         /*< Action */
     char if_name[IFNAMSIZ];  /*< Physical interface name. [ro] */
-    
+
     uint8_t id;         /*< Queue ID. [ro]
                             minimal ID == 0
                             maximal ID is implementation defined. See Egress QoS. */
-    
-    uint8_t mode;       /*< Queue mode: 
+
+    uint8_t mode;       /*< Queue mode:
                             0 == Disabled. Queue will drop all packets.
                             1 == Default. HW implementation-specific. Normally not used.
                             2 == Tail drop
                             3 == WRED */
-    
+
     uint32_t min;       /*< Minimum threshold. [NBO]. Value is `.mode`-specific:
                             - Disabled, Default: n/a
                             - Tail drop: n/a
-                            - WRED: Threshold in number of packets in the queue at which 
-                                    the WRED lowest drop probability zone starts. 
-                                    While the queue fill level is below this threshold, 
+                            - WRED: Threshold in number of packets in the queue at which
+                                    the WRED lowest drop probability zone starts.
+                                    While the queue fill level is below this threshold,
                                     the drop probability is 0%. */
-    
-    uint32_t max;       /*< Maximum threshold. [NBO]. Value is `.mode`-specific: 
+
+    uint32_t max;       /*< Maximum threshold. [NBO]. Value is `.mode`-specific:
                             - Disabled, Default: n/a
                             - Tail drop: The queue length in number of packets. Queue length
-                                         is the number of packets the queue can accommodate 
+                                         is the number of packets the queue can accommodate
                                          before drops will occur.
-                            - WRED: Threshold in number of packets in the queue at which 
+                            - WRED: Threshold in number of packets in the queue at which
                                     the WRED highest drop probability zone ends.
                                     While the queue fill level is above this threshold,
                                     the drop probability is 100%. */
-    
-    uint8_t zprob[32];  /*< WRED drop probabilities for all probability zones in [%]. 
-                            The lowest probability zone is `.zprob[0]`. Only valid for 
+
+    uint8_t zprob[32];  /*< WRED drop probabilities for all probability zones in [%].
+                            The lowest probability zone is `.zprob[0]`. Only valid for
                             `.mode = WRED`. Value 255 means 'invalid'. Number of zones
                             per queue is implementation-specific. See Egress QoS. */
 } fpp_qos_queue_cmd_t;
@@ -2257,46 +2260,46 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Modify properties of an Egress QoS scheduler.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_scheduler_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_scheduler_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_UPDATE,  // Action
  *    .if_name = "...",              // Physical interface name.
  *    .id      =  ...,               // Scheduler ID.
- *      
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_qos_scheduler_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_QOS_SCHEDULER, sizeof(fpp_qos_scheduler_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_QOS_SCHEDULER, sizeof(fpp_qos_scheduler_cmd_t),
  *                                                (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get properties of a target Egress QoS scheduler.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_scheduler_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_scheduler_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY  // Action
  *    .if_name = "...",            // Physical interface name.
  *    .id      =  ...              // Scheduler ID.
  *  };
- *    
+ *
  *  fpp_qos_scheduler_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_SCHEDULER,
  *                  sizeof(fpp_qos_scheduler_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the target Egress QoS scheduler.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -2333,33 +2336,33 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;        /*< Action */
     char if_name[IFNAMSIZ]; /*< Physial interface name. [ro] */
-    
+
     uint8_t id;             /*< Scheduler ID. [ro]
                                 minimal ID == 0
                                 maximal ID is implementation defined. See Egress QoS. */
-    
-    uint8_t mode;           /*< Scheduler mode: 
+
+    uint8_t mode;           /*< Scheduler mode:
                                 0 == Scheduler disabled
                                 1 == Data rate (payload length)
                                 2 == Packet rate (number of packets) */
-    
+
     uint8_t algo;           /*< Scheduler algorithm:
                                 0 == PQ (Priority Queue). Input with the highest priority
                                      is serviced first. Input 0 has the @b lowest priority.
                                 1 == DWRR (Deficit Weighted Round Robin).
                                 2 == RR (Round Robin).
                                 3 == WRR (Weighted Round Robin). */
-    
+
     uint32_t input_en;      /*< Input enable bitfield. [NBO]
                                 When a bit `n` is set it means that scheduler input `n`
-                                is enabled and connected to traffic source defined by 
+                                is enabled and connected to traffic source defined by
                                 `.source[n]`. Number of inputs is implementation-specific.
                                 See Egress QoS. */
-    
+
     uint32_t input_w[32];   /*< Input weight. [NBO]. Scheduler algorithm-specific:
                                 - PQ, RR - n/a
                                 - WRR, DWRR - Weight in units given by `.mode` */
-    
+
     uint8_t input_src[32];  /*< Traffic source for each scheduler input. Traffic sources
                                 are implementation-specific. See Egress QoS. */
 } fpp_qos_scheduler_cmd_t;
@@ -2380,46 +2383,46 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Modify properties of an Egress QoS shaper.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_shaper_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_shaper_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_UPDATE,  // Action
  *    .if_name = "...",              // Physical interface name.
  *    .id      =  ...,               // Shaper ID.
- *      
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_qos_shaper_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_QOS_SHAPER, sizeof(fpp_qos_shaper_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_QOS_SHAPER, sizeof(fpp_qos_shaper_cmd_t),
  *                                             (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get properties of a target Egress QoS shaper.
  * @code{.c}
- *  .............................................  
- *  fpp_qos_shaper_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_qos_shaper_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY  // Action
  *    .if_name = "...",            // Physical interface name.
  *    .id      =  ...,             // Shaper ID.
  *  };
- *    
+ *
  *  fpp_qos_shaper_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_SHAPER,
  *                  sizeof(fpp_qos_shaper_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the target Egress QoS shaper.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -2456,18 +2459,18 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;        /*< Action */
     char if_name[IFNAMSIZ]; /*< Physial interface name. [ro] */
-    
-    uint8_t id;             /*< Shaper ID. [ro] 
+
+    uint8_t id;             /*< Shaper ID. [ro]
                                 minimal ID == 0
                                 maximal ID is implementation defined. See Egress QoS. */
-    
+
     uint8_t position;       /*< Position of the shaper.
                                 Positions are implementation defined. See Egress QoS. */
-    
+
     uint32_t isl;           /*< Idle slope in units per second (see `.mode`). [NBO] */
     int32_t max_credit;     /*< Max credit. [NBO] */
     int32_t min_credit;     /*< Min credit. [NBO] */
-    
+
     uint8_t mode;           /*< Shaper mode:
                                 0 == Shaper disabled
                                 1 == Data rate.
@@ -2504,41 +2507,41 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Enable/disable Ingress QoS policer of an @b emac physical interface.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_cmd_t cmd_to_fci =
  *  {
- *    .action  = FPP_ACTION_UPDATE,  
+ *    .action  = FPP_ACTION_UPDATE,
  *    .if_name = "...",    // Physical interface name ('emac' interfaces only).
  *    .enable  =  ...      // 0 == disabled ; 1 == enabled
  *  };
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_write(client, FPP_CMD_QOS_POLICER, sizeof(fpp_qos_policer_cmd_t),
  *                                              (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get status (enabled/disabled) of an Ingress QoS policer.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY,
  *    .if_name = "...",    // Physical interface name ('emac' interfaces only).
  *  };
- *    
+ *
  *  fpp_qos_policer_cmd_t reply_from_fci = {0};
  *  unsigned short reply_length = 0u;
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_POLICER,
  *                  sizeof(fpp_qos_policer_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds the '.enable' field set accordingly.
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * Command return values (for all applicable ACTIONs)
@@ -2583,11 +2586,11 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_DEREGISTER <br>
  *                   Remove a flow from an Ingress QoS flow classification table.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a flow query session and get properties 
+ *                   Initiate (or reinitiate) a flow query session and get properties
  *                   of the first flow from an Ingress QoS flow clasification table.
  *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next
- *                   flow from the table. Intended to be called in a loop 
+ *                   flow from the table. Intended to be called in a loop
  *                   (to iterate through the table).
  *
  * @note
@@ -2599,70 +2602,70 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * Add a packet flow to an Ingress QoS flow classification table. Specify flow parameters and
  * the action to be done for packets which conform to the given flow.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_REGISTER,
  *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
  *    .id      =  ...,   // Position in the classification table. 0xFF == automatic placement.
- *      
+ *
  *    .flow    = {...}   // Flow specification structure.
  *  };
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_FLOW, sizeof(fpp_qos_policer_flow_cmd_t),
  *                                                   (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_DEREGISTER
  * ---------------------
  * Remove a flow from an Ingress QoS flow classification table.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_DEREGISTER,
  *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
  *    .id      =  ...,   // Position in the classification table.
  *  };
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_FLOW, sizeof(fpp_qos_policer_flow_cmd_t),
  *                                                   (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
- * 
+ *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of the Ingress QoS flow.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY,
  *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
  *    .id      =  ...,   // Entry position in the table, from 0 to "table size - 1".
  *  };
- *    
+ *
  *  fpp_qos_policer_flow_cmd_t reply_from_fci = {0};
  *  unsigned short reply_length = 0u;
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_FLOW,
  *                  sizeof(fpp_qos_policer_flow_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds the content of the first available (i.e. active) flow
  *  //  from the Ingress QoS flow classification table of the target physical interface.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_FLOW,
  *                  sizeof(fpp_qos_policer_flow_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the next available flow from the table.
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * Command return values (for all applicable ACTIONs)
@@ -2704,7 +2707,7 @@ typedef enum CAL_PACKED
 
     FPP_IQOS_FLOW_TYPE_MAX = FPP_IQOS_FLOW_TYPE_VLAN,
     /* Ensure proper size */
-    FPP_IQOS_FLOW_TYPE_MAX_ = (uint16_t)(1U << 15U)
+    FPP_IQOS_FLOW_TYPE_RESERVED = (uint16_t)(1U << 15U)
 } fpp_iqos_flow_type_t;
 
 /**
@@ -2723,7 +2726,7 @@ typedef enum CAL_PACKED
 
     FPP_IQOS_ARG_MAX = FPP_IQOS_ARG_DPORT,
     /* Ensure proper size */
-    FPP_IQOS_ARG_MAX_ = (uint16_t)(1U << 15U)
+    FPP_IQOS_ARG_RESERVED = (uint16_t)(1U << 15U)
 } fpp_iqos_flow_arg_type_t;
 
 /**
@@ -2763,7 +2766,7 @@ typedef enum CAL_PACKED
  *   - `PacketData` is the inspected value from an ingress packet.
  *   - `ArgData` is the argument value of an argumentful flow type.
  *   - `Mask` is the bitmask of an argumentful flow type. <br>
- *      For IP addresses, the network prefix (e.g. /24) is internally converted into 
+ *      For IP addresses, the network prefix (e.g. /24) is internally converted into
  *      a valid subnet mask (/24 == 0xFFFFFFF0).
  *
  * Example: <br>
@@ -2785,29 +2788,29 @@ typedef enum CAL_PACKED
 typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t vlan;       /*< FPP_IQOS_ARG_VLAN: VLAN ID (max 4095). [NBO] */
-    
-    uint16_t vlan_m;     /*< FPP_IQOS_ARG_VLAN: VLAN ID comparison bitmask (12b). [NBO] 
+
+    uint16_t vlan_m;     /*< FPP_IQOS_ARG_VLAN: VLAN ID comparison bitmask (12b). [NBO]
                              Use FPP_IQOS_VLAN_ID_MASK to compare whole value (all bits). */
-    
+
     uint8_t tos;         /*< FPP_IQOS_ARG_TOS: TOS field for IPv4, TCLASS for IPv6. */
-    
-    uint8_t tos_m;       /*< FPP_IQOS_ARG_TOS: TOS comparison bitmask. 
+
+    uint8_t tos_m;       /*< FPP_IQOS_ARG_TOS: TOS comparison bitmask.
                              Use FPP_IQOS_TOS_MASK to compare whole value (all bits). */
-    
+
     uint8_t l4proto;     /*< FPP_IQOS_ARG_L4PROTO: L4 protocol field for IPv4 and IPv6. */
-    
+
     uint8_t l4proto_m;   /*< FPP_IQOS_ARG_L4PROTO: L4 protocol comparison bitmask.
                              Use FPP_IQOS_L4PROTO_MASK to compare whole value (all bits). */
-    
+
     uint32_t sip;        /*< FPP_IQOS_ARG_SIP: Source IP address for IPv4/IPv6. [NBO] */
     uint32_t dip;        /*< FPP_IQOS_ARG_DIP: Destination IP address for IPv4/IPv6. [NBO] */
-    
-    uint8_t sip_m;       /*< FPP_IQOS_ARG_SIP: Source IP address - network prefix. 
+
+    uint8_t sip_m;       /*< FPP_IQOS_ARG_SIP: Source IP address - network prefix.
                              Use FPP_IQOS_SDIP_MASK to compare whole address (all bits). */
-    
+
     uint8_t dip_m;       /*< FPP_IQOS_ARG_DIP: Destination IP address - network prefix.
                              Use FPP_IQOS_SDIP_MASK to compare whole address (all bits). */
-    
+
     uint16_t sport_max;  /*< FPP_IQOS_ARG_SPORT: Max L4 source port. [NBO] */
     uint16_t sport_min;  /*< FPP_IQOS_ARG_SPORT: Min L4 source port. [NBO] */
     uint16_t dport_max;  /*< FPP_IQOS_ARG_DPORT: Max L4 destination port. [NBO] */
@@ -2834,7 +2837,7 @@ typedef enum CAL_PACKED
  * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER_FLOW
  * @details     Related data types: @ref fpp_qos_policer_flow_cmd_t
  * @note        Some values are in a network byte order [NBO].
- * 
+ *
  * @snippet     fpp_ext.h  fpp_iqos_flow_spec_t
  */
 /* [fpp_iqos_flow_spec_t] */
@@ -2842,13 +2845,13 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     fpp_iqos_flow_type_t type_mask;          /*< Argumentless flow types to match. [NBO]
                                                  A bitset mask. */
-    
+
     fpp_iqos_flow_arg_type_t arg_type_mask;  /*< Argumentful flow types to match. [NBO]
                                                  A bitset mask. */
-    
+
     fpp_iqos_flow_args_t CAL_PACKED_ALIGNED(4) args; /*< Arguments for argumentful flow types.
                                                          Related to 'arg_type_mask'. */
-    
+
     fpp_iqos_flow_action_t action;           /*< Action to be done for matching packets. */
 } fpp_iqos_flow_spec_t;
 /* [fpp_iqos_flow_spec_t] */
@@ -2865,14 +2868,14 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;
     char if_name[IFNAMSIZ]; /*< Physical interface name ('emac' interfaces only). */
-    
+
     uint8_t id;             /*< Position in the classification table.
                                 minimal ID == 0
                                 maximal ID is implementation defined. See Ingress QoS.
                                 For FPP_ACTION_REGISTER, value 0xFF means "don't care".
                                 If 0xFF is set as registration id, driver will automatically
                                 choose the first available free position. */
-    
+
     fpp_iqos_flow_spec_t CAL_PACKED_ALIGNED(4) flow;  /*< Flow specification. */
 } fpp_qos_policer_flow_cmd_t;
 /* [fpp_qos_policer_flow_cmd_t] */
@@ -2896,49 +2899,49 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Update Ingress QoS WRED queue of a target physical interface.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_wred_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_UPDATE,
  *    .if_name = "...",      // Physical interface name ('emac' interfaces only).
  *    .queue   =  ...,       // Target Ingress QoS WRED queue (DMEM, LMEM, RXF).
  *    .enable  =  ...,       // Enable/disable switch (0 == disabled, 1 == enabled).
- *      
+ *
  *    .thr[]   = {...},      // Min/max/full WRED thresholds.
  *                           // 0xFFFF == let HW keep its currently configured thld value.
- *      
+ *
  *    .zprob[] = {...}       // WRED drop probabilities for all zones in 1/16 increments.
  *                           // 0xFF == let HW keep its currently configured zone value.
  *  };
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_WRED, sizeof(fpp_qos_policer_wred_cmd_t),
  *                                                   (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get properties of a target Ingress QoS WRED queue.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_wred_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY,
  *    .if_name = "...",      // Physical interface name ('emac' interfaces only).
  *    .queue   =  ...,       // Target Ingress QoS WRED queue (DMEM, LMEM, RXF).
  *  };
- *    
+ *
  *  fpp_qos_policer_wred_cmd_t reply_from_fci = {0};
  *  unsigned short reply_length = 0u;
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_WRED,
  *                  sizeof(fpp_qos_policer_wred_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the target Ingress QoS WRED queue.
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * Command return values (for all applicable ACTIONs)
@@ -2995,15 +2998,15 @@ typedef enum CAL_PACKED
                                      If queue fill below `.thr[FPP_IQOS_WRED_MIN_THR]`, the following applies:
                                      - Drop Unmanaged traffic by probability zones.
                                      - Keep Managed and Reserved traffic. */
-    
+
     FPP_IQOS_WRED_MAX_THR,      /**< WRED queue max threshold. <br>
                                      If queue fill over `.thr[FPP_IQOS_WRED_MIN_THR]` but below `.thr[FPP_IQOS_WRED_MAX_THR]`, the following applies:
                                      - Drop all Unmanaged and Managed traffic.
                                      - Keep Reserved traffic. */
-    
+
     FPP_IQOS_WRED_FULL_THR,     /**< WRED queue full threshold. <br>
                                      If queue fill over `.thr[FPP_IQOS_WRED_FULL_THR]`, then drop all traffic. */
-    
+
     FPP_IQOS_WRED_THR_COUNT     /* must be last */
 } fpp_iqos_wred_thr_t;
 
@@ -3025,7 +3028,7 @@ typedef struct CAL_PACKED_ALIGNED(4)
     fpp_iqos_queue_t queue;  /*< Target Ingress QoS WRED queue. [ro] */
     uint8_t enable;          /*< Enable/disable switch of the target WRED queue HW module.
                                  0 == disabled, 1 == enabled. */
-    
+
     uint16_t thr[FPP_IQOS_WRED_THR_COUNT]; /*< WRED queue thresholds. [NBO]
                                                See 'fpp_iqos_wred_thr_t'.
                                                Unit is "number of packets".
@@ -3034,13 +3037,13 @@ typedef struct CAL_PACKED_ALIGNED(4)
                                                Ingress QoS chapter for implementation details.
                                                Value 0xFFFF == HW keeps its currently
                                                                configured value. */
-    
+
     uint8_t zprob[FPP_IQOS_WRED_ZONES_COUNT]; /*< WRED drop probabilities for all probability
                                                   zones. See 'fpp_iqos_wred_zone_t'.
                                                   One unit (1) represents probability of 1/16.
                                                   Min value == 0   ( 0/16 = 0%)
                                                   Max value == 15  (15/16 = 93,75%)
-                                                  Value 255 == HW keeps its currently 
+                                                  Value 255 == HW keeps its currently
                                                                configured value. */
 } fpp_qos_policer_wred_cmd_t;
 /* [fpp_qos_policer_wred_cmd_t] */
@@ -3064,45 +3067,45 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Configure Ingress QoS credit based shaper (IEEE 802.1Q) of a target physical interface.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_shp_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_UPDATE,
  *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
  *    .id      =  ...,   // ID of the target Ingress QoS shaper.
- *      
+ *
  *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
  *               // Some properties cannot be modified (see fpp_qos_policer_shp_cmd_t).
  *  };
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_SHP, sizeof(fpp_qos_policer_shp_cmd_t),
  *                                                  (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY
  * ----------------
  * Get properties of a target Ingress QoS shaper.
  * @code{.c}
- *  .............................................  
+ *  .............................................
  *  fpp_qos_policer_shp_cmd_t cmd_to_fci =
  *  {
  *    .action  = FPP_ACTION_QUERY,
  *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
  *    .id      =  ...    // ID of the target Ingress QoS shaper.
  *  };
- *    
+ *
  *  fpp_qos_policer_shp_cmd_t reply_from_fci = {0};
  *  unsigned short reply_length = 0u;
- *    
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_SHP,
  *                  sizeof(fpp_qos_policer_shp_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
+ *
  *  // 'reply_from_fci' now holds properties of the target Ingress QoS shaper.
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * Command return values (for all applicable ACTIONs)
@@ -3139,10 +3142,10 @@ typedef enum CAL_PACKED
 {
     FPP_IQOS_SHP_BPS = 0,          /**< `.isl` is in bits-per-second. <br>
                                         `.max_credit` and `.min_credit` are in number of bytes. */
-    
+
     FPP_IQOS_SHP_PPS,              /**< `.isl` is in packets-per-second. <br>
                                         `.max_credit` and `.min_credit` are in number of packets. */
-    
+
     FPP_IQOS_SHP_RATE_MODE_COUNT   /* must be last */
 } fpp_iqos_shp_rate_mode_t;
 
@@ -3160,20 +3163,20 @@ typedef struct CAL_PACKED_ALIGNED(4)
 {
     uint16_t action;
     char if_name[IFNAMSIZ];    /*< Physical interface name ('emac' interfaces only). [ro] */
-    
+
     uint8_t id;                /*< ID of the target Ingress QoS shaper. [ro]
                                    Min ID == 0
                                    Max ID is implementation defined. See Ingress QoS. */
-    
+
     uint8_t enable;            /*< Enable/disable switch of the target Ingress QoS shaper 
                                    HW module. 0 == disabled, 1 == enabled. */
-    
+
     fpp_iqos_shp_type_t type;  /*< Shaper type. Port level, bcast or mcast. */
-    
+
     fpp_iqos_shp_rate_mode_t mode;  /*< Shaper mode. Bits or packets. */
     uint32_t isl;                   /*< Idle slope. Units are '.mode' dependent. [NBO] */
     int32_t max_credit;             /*< Max credit. Units are '.mode' dependent. [NBO] */
-    int32_t min_credit;             /*< Min credit. Units are '.mode' dependent. [NBO] 
+    int32_t min_credit;             /*< Min credit. Units are '.mode' dependent. [NBO]
                                         Must be negative. */
 } fpp_qos_policer_shp_cmd_t;
 /* [fpp_qos_policer_shp_cmd_t] */
@@ -3187,9 +3190,9 @@ typedef struct CAL_PACKED_ALIGNED(4)
  *              - @c FPP_ACTION_UPDATE <br>
  *                   Enable/disable a FW feature.
  *              - @c FPP_ACTION_QUERY <br>
- *                   Initiate (or reinitiate) a FW feature query session and get properties 
+ *                   Initiate (or reinitiate) a FW feature query session and get properties
  *                   of the first FW feature from the internal list of FW features.
- *              - @c FPP_ACTION_QUERY_CONT <br> 
+ *              - @c FPP_ACTION_QUERY_CONT <br>
  *                   Continue the query session and get properties of the next FW feature
  *                   from the list. Intended to be called in a loop (to iterate through the list).
  *
@@ -3197,49 +3200,49 @@ typedef struct CAL_PACKED_ALIGNED(4)
  * -----------------
  * Enable/disable a FW feature.
  * @code{.c}
- *  .............................................  
- *  fpp_fw_features_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fw_features_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_UPDATE,  // Action
  *    .val    = ...                 // 0 == disabled ; 1 == enabled
  *  };
- *    
+ *
  *  int rtn = 0;
- *  rtn = fci_write(client, FPP_CMD_FW_FEATURE, sizeof(fpp_fw_features_cmd_t), 
+ *  rtn = fci_write(client, FPP_CMD_FW_FEATURE, sizeof(fpp_fw_features_cmd_t),
  *                                             (unsigned short*)(&cmd_to_fci));
- *  .............................................  
+ *  .............................................
  * @endcode
  *
  * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
  * ------------------------------------------
  * Get properties of a FW feature.
  * @code{.c}
- *  .............................................  
- *  fpp_fw_features_cmd_t cmd_to_fci = 
+ *  .............................................
+ *  fpp_fw_features_cmd_t cmd_to_fci =
  *  {
  *    .action = FPP_ACTION_QUERY  // Action
  *  };
- *    
+ *
  *  fpp_fw_features_cmd_t reply_from_fci = {0};
- *  unsigned short reply_length = 0u; 
- *    
+ *  unsigned short reply_length = 0u;
+ *
  *  int rtn = 0;
  *  rtn = fci_query(client, FPP_CMD_FW_FEATURE,
  *                  sizeof(fpp_fw_features_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the first FW feature from 
+ *
+ *  // 'reply_from_fci' now holds properties of the first FW feature from
  *  //  the internal list of FW features.
- *    
+ *
  *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
  *  rtn = fci_query(client, FPP_CMD_FW_FEATURE,
  *                  sizeof(fpp_fw_features_cmd_t), (unsigned short*)(&cmd_to_fci),
  *                  &reply_length, (unsigned short*)(&reply_from_fci));
- *    
- *  // 'reply_from_fci' now holds properties of the next FW feature from 
+ *
+ *  // 'reply_from_fci' now holds properties of the next FW feature from
  *  //  the internal list of FW features.
- *  .............................................  
- * @endcode 
+ *  .............................................
+ * @endcode
  *
  * Command return values (for all applicable ACTIONs)
  * --------------------------------------------------
@@ -3290,10 +3293,10 @@ typedef struct CAL_PACKED_ALIGNED(2)
     uint16_t action;                       /*< Action */
     char name[FPP_FEATURE_NAME_SIZE + 1];  /*< Feature name. [ro] */
     char desc[FPP_FEATURE_DESC_SIZE + 1];  /*< Feature description. [ro] */
-    
+
     uint8_t val;        /*< Feature current state.
                             0 == disabled ; 1 == enabled */
-    
+
     fpp_fw_feature_flags_t flags;  /*< Feature configuration variant. [ro] */
     uint8_t def_val;               /*< Factory default value of the '.val' property. [ro] */
     uint8_t reserved;              /*< RESERVED (do not use) */
diff --git a/sw/xfci/libfci/public/libfci.h b/sw/xfci/libfci/public/libfci.h
index 48fb637..204459e 100644
--- a/sw/xfci/libfci/public/libfci.h
+++ b/sw/xfci/libfci/public/libfci.h
@@ -789,11 +789,12 @@
  *
  *              @if S32G2
  *                The following applies for each @b S32G2/PFE QoS block:
- *                - @b Queues:
+ *                - @b Queues: @anchor ref__queues
  *                     - Number of queues: 8
- *                     - Maximum queue depth: 255
+ *                     - Size of a @link ref__queue_slot_pools queue slot pool @endlink for each @b emac : 255
+ *                     - Size of a queue slot pool for each @b hif : 32
  *                     - Probability zones per queue: 8
- *                       <small><br>
+ *                       <small><br><br>
  *                       Queues of @b hif interfaces:
  *                       Every hif interface has only @b 2 queues, indexed as follows:
  *                         - [0] : low priority queue (L)
@@ -801,7 +802,6 @@
  *
  *                       Use only these indexes if hif queues are configured via FCI commands.
  *                       </small>
- *
  *                - @b Schedulers:
  *                     - Number of schedulers: 2
  *                     - Number of scheduler inputs: 8
@@ -827,6 +827,27 @@
  *                     of each other and do share the 'conflicting transmission' signal.
  *              @endif
  *
+ *              Queue slot pools @anchor ref__queue_slot_pools
+ *              ----------------
+ *              Every QoS block has it own pool of queue slots. These slots can be assigned to particular queues.
+ *              Length of a queue is equal to number of assigned slots. It is possible to configure queue lengths via FCI API.
+ *              Setting a queue length (@link fpp_qos_queue_cmd_t @endlink.max) means assigning given number of slots to the given queue.
+ *              Sum of all queue lengths of the particular physical interface cannot be bigger than size of its queue slot pool.
+ *
+ *              See section @link ref__queues Queues @endlink for info about queue slot pool sizes for various physical interfaces.
+ *              <small><br><br>
+ *              Examples of queue slots distribution:
+ *              - Asymmetrical queue slots distribution for @b emac0.
+ *                Only 241 slots of the emac0 are used. Emac0 still has 14 free queue slots which could be used to
+ *                lenghten some emac0 queues, if needed.
+ *                  - queue 0 : 150 slots
+ *                  - queues 1 .. 7 : 13 slots per each queue
+ *              - Symmetrical queue slots distribution for @b hif0.
+ *                All 32 queue slots of the hif0 are used. There are no free queue slots left on hif0.
+ *                  - queue 0 : 16 slots
+ *                  - queue 1 : 16 slots
+ *              </small>
+ *
  *              Traffic queueing algorithm
  *              --------------------------
  *              The following pseudocode explains traffic queueing algorithm of PFE:
-- 
2.17.1

