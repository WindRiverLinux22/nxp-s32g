From 38e35629142013eb5bcd7ed667b823e07463a1ae Mon Sep 17 00:00:00 2001
From: Martin Hrdlicka <martin.hrdlicka@nxp.com>
Date: Fri, 3 Mar 2023 15:02:28 +0100
Subject: [PATCH 1/2] version PFE_S32G_A53_LNX_1.3.0 RC2

Highlights:
    1) HIF netdev
    2) Slave STR support
    3) Graceful shutdown of HIF slave
    4) Support for PFE FW 1.6.0
    5) Jumbo frames up to 9k
    6) Use RT_LMEM on G3 by default
    7) Support external TS clock on EMACs
    8) Various fixes

pfe_linux.git: f9c1fd1b253ea8c8a668d18f5a302acffcc42d47

Upstream-Status: Pending

Signed-off-by: Jan Petrous <jan.petrous@nxp.com>
Signed-off-by: Claudiu Manoil <claudiu.manoil@nxp.com>
Signed-off-by: Martin Hrdlicka <martin.hrdlicka@nxp.com>
Signed-off-by: Zhantao Tang <zhantao.tang@windriver.com>
---
 doc/nxp,s32g-pfe.yaml                       |  84 ++++++---
 sw/fci/src/fci_connections.c                |  67 ++++---
 sw/fci/src/fci_routes.c                     |   5 +-
 sw/libfci_cli/Makefile                      |   2 +-
 sw/linux-pfeng/pfeng-dt.c                   | 103 +++++------
 sw/linux-pfeng/pfeng-ethtool.c              |   8 +-
 sw/linux-pfeng/pfeng-hif.c                  |  37 +++-
 sw/linux-pfeng/pfeng-hwts.c                 |  46 ++---
 sw/linux-pfeng/pfeng-netif.c                | 106 +++++------
 sw/linux-pfeng/pfeng-phylink.c              |  36 ++--
 sw/linux-pfeng/pfeng-ptp.c                  |  31 ++--
 sw/linux-pfeng/pfeng-slave-drv.c            |  69 ++++++--
 sw/linux-pfeng/pfeng.h                      |  66 ++++---
 sw/oal/src/oal_mm_linux.c                   | 172 +++++++++---------
 sw/pfe_platform/hw/s32g/pfe_class_csr.c     |   6 +
 sw/pfe_platform/hw/s32g/pfe_class_csr.h     |   1 +
 sw/pfe_platform/hw/s32g/pfe_gpi_csr.c       |   1 +
 sw/pfe_platform/public/pfe_hif_ring_linux.h |   1 +
 sw/pfe_platform/public/pfe_phy_if.h         |   4 +-
 sw/pfe_platform/public/pfe_rtable.h         |   5 +-
 sw/pfe_platform/src/pfe_hif_chnl_linux.c    | 180 +++++++++++++++----
 sw/pfe_platform/src/pfe_hif_ring_linux.c    |  78 +++++++--
 sw/pfe_platform/src/pfe_hm.c                |   2 +-
 sw/pfe_platform/src/pfe_log_if.c            |  56 +-----
 sw/pfe_platform/src/pfe_log_if_slave.c      |  65 ++-----
 sw/pfe_platform/src/pfe_phy_if.c            |  47 +----
 sw/pfe_platform/src/pfe_phy_if_slave.c      | 136 ++-------------
 sw/pfe_platform/src/pfe_rtable.c            | 184 +++++++++++++++++---
 sw/pfe_platform/src/pfe_spd_acc.c           |  10 +-
 29 files changed, 900 insertions(+), 708 deletions(-)

diff --git a/doc/nxp,s32g-pfe.yaml b/doc/nxp,s32g-pfe.yaml
index 25a0634..f961056 100644
--- a/doc/nxp,s32g-pfe.yaml
+++ b/doc/nxp,s32g-pfe.yaml
@@ -1,5 +1,5 @@
 # SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
-# Copyright 2022 NXP
+# Copyright 2022-2023 NXP
 %YAML 1.2
 ---
 $id: "http://devicetree.org/schemas/net/nxp,s32g-pfe.yaml#"
@@ -24,8 +24,8 @@ properties:
   compatible:
     items:
       - enum:
-          - nxp,s32g-pfe
-          - nxp,s32g-pfe-slave
+        - nxp,s32g-pfe
+        - nxp,s32g-pfe-slave
     description:
       The single instance driver (aka standalone driver mode) and the Master
       driver require "nxp,s32g-pfe", the Slave driver requires "nxp,s32g-pfe-slave".
@@ -50,12 +50,12 @@ properties:
     maxItems: 3
     oneOf:
       - items:
-          - const: pfe_sys
-          - const: pfe_pe
-          - const: pfe_ts
+        - const: pfe_sys
+        - const: pfe_pe
+        - const: pfe_ts
       - items:
-          - const: pfe_sys
-          - const: pfe_pe
+        - const: pfe_sys
+        - const: pfe_pe
 
   interrupts:
     items:
@@ -88,6 +88,7 @@ properties:
     maxItems: 1
 
   memory-region:
+    maxItems: 4
     items:
       - description: The BMU2 buffer pool, must be in the range 0x00020000 - 0xbfffffff
       - description: RT region
@@ -95,6 +96,7 @@ properties:
       - description: Buffer descriptor rings
 
   memory-region-names:
+    maxItems: 4
     items:
       - const: pfe-bmu2-pool
       - const: pfe-rt-pool
@@ -115,25 +117,29 @@ properties:
       firmware search path containing the firmware image used when
       initializing PFE UTIL hardware. Optional.
 
-  nxp,pfeng-hif-channels:
+  nxp,pfeng-emac-ts-ext-modes:
     $ref: /schemas/types.yaml#/definitions/uint32-array
     description: |
-      The set of managed HIF channels. Any combination of standard
-      HIF channel can be used. HIF_NCPY is not supported.
-    minItems: 1
-    maxItems: 4
-    items:
-      minimum: 0
-      maximum: 3
+      The set of PFE_EMACs required to work in external timestamping
+      mode. The combination of external TS support is limited,
+      check S32G Reference Manual for detailed info.
+    maxItems: 3
+    contains:
+      enum:
+        - PFE_PHYIF_EMAC_0
+        - PFE_PHYIF_EMAC_1
+        - PFE_PHYIF_EMAC_2
 
   nxp,pfeng-ihc-channel:
     $ref: /schemas/types.yaml#/definitions/uint32
     description: |
       The HIF channel number used for IHC transport.
-      The outgoing channel, must be one from set
-      specified in nxp,pfeng-hif-channels.
-    minimum: 0
-    maximum: 3
+    maxItems: 1
+      enum:
+        - PFE_PHYIF_HIF_0
+        - PFE_PHYIF_HIF_1
+        - PFE_PHYIF_HIF_2
+        - PFE_PHYIF_HIF_3
 
 
   nxp,pfeng-master-channel:
@@ -143,8 +149,13 @@ properties:
       The destination channel used by Master for
       receiving IHC messages. Here can also be used
       the HIF_NCPY channel.
-    minimum: 0
-    maximum: 4
+    maxItems: 1
+      enum:
+        - PFE_PHYIF_HIF_0
+        - PFE_PHYIF_HIF_1
+        - PFE_PHYIF_HIF_2
+        - PFE_PHYIF_HIF_3
+        - PFE_PHYIF_HIF_NOCPY
 
   phys:
     maxItems: 3
@@ -197,13 +208,30 @@ properties:
           HIF channel can be used. HIF_NOCPY is not supported.
         minItems: 1
         maxItems: 4
-        items:
-          minimum: 0
-          maximum: 3
+          enum:
+            - PFE_PHYIF_HIF_0
+            - PFE_PHYIF_HIF_1
+            - PFE_PHYIF_HIF_2
+            - PFE_PHYIF_HIF_3
       nxp,pfeng-emac-id:
-        $ref: /schemas/types.yaml#/definitions/uint32-array
+        $ref: /schemas/types.yaml#/definitions/uint32
+        description: |
+          The linked PFE_EMAC port. Use nxp,pfeng-linked-phyif instead.
+        deprecated: true
+      nxp,pfeng-linked-phyif:
+        $ref: /schemas/types.yaml#/definitions/uint32
         description: |
-          The linked PFE_EMAC port.
+          The linked PFE physical port.
+        maxItems: 1
+          enum:
+            - PFE_PHYIF_EMAC_0
+            - PFE_PHYIF_EMAC_1
+            - PFE_PHYIF_EMAC_2
+            - PFE_PHYIF_HIF_NOCPY
+            - PFE_PHYIF_HIF_0
+            - PFE_PHYIF_HIF_1
+            - PFE_PHYIF_HIF_2
+            - PFE_PHYIF_HIF_3
       nxp,pfeng-netif-mode-aux:
         $ref: /schemas/types.yaml#/definitions/flag
         description: |
@@ -222,6 +250,8 @@ required:
 
 additionalProperties: false
 
+unevaluatedProperties: false
+
 allOf:
   - if:
       properties:
diff --git a/sw/fci/src/fci_connections.c b/sw/fci/src/fci_connections.c
index e9e9f44..ee5a97b 100644
--- a/sw/fci/src/fci_connections.c
+++ b/sw/fci/src/fci_connections.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -453,7 +453,7 @@ static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t
 			if (EOK != pfe_rtable_entry_set_5t(new_entry, tuple))
 			{
 				NXP_LOG_ERROR("Can't set 5 tuple\n");
-				pfe_rtable_entry_free(new_entry);
+				pfe_rtable_entry_free(NULL, new_entry);
 				new_entry = NULL;
 			}
 			else
@@ -476,7 +476,7 @@ static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t
 					if (EOK != pfe_rtable_entry_set_out_sip(new_entry, &tuple_rep->dst_ip))
 					{
 						NXP_LOG_ERROR("Couldn't set output SIP\n");
-						pfe_rtable_entry_free(new_entry);
+						pfe_rtable_entry_free(NULL, new_entry);
 						new_entry = NULL;
 					}
 				}
@@ -490,7 +490,7 @@ static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t
 						if (EOK != pfe_rtable_entry_set_out_dip(new_entry, &tuple_rep->src_ip))
 						{
 							NXP_LOG_ERROR("Couldn't set output DIP\n");
-							pfe_rtable_entry_free(new_entry);
+							pfe_rtable_entry_free(NULL, new_entry);
 							new_entry = NULL;
 						}
 					}
@@ -977,7 +977,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 								NXP_LOG_ERROR("Can't remove route entry\n");
 							}
 
-							pfe_rtable_entry_free(entry);
+							pfe_rtable_entry_free(fci_context->rtable, entry);
 							entry = NULL;
 
 							if (NULL != rep_entry)
@@ -987,7 +987,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 									NXP_LOG_ERROR("Can't remove route entry\n");
 								}
 
-								pfe_rtable_entry_free(rep_entry);
+								pfe_rtable_entry_free(fci_context->rtable, rep_entry);
 								rep_entry = NULL;
 							}
 						}
@@ -1000,7 +1000,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 								NXP_LOG_ERROR("Can't remove route entry\n");
 							}
 
-							pfe_rtable_entry_free(entry);
+							pfe_rtable_entry_free(fci_context->rtable, entry);
 							entry = NULL;
 
 							if (NULL != rep_entry)
@@ -1010,7 +1010,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 									NXP_LOG_ERROR("Can't remove route entry\n");
 								}
 
-								pfe_rtable_entry_free(rep_entry);
+								pfe_rtable_entry_free(fci_context->rtable, rep_entry);
 								rep_entry = NULL;
 							}
 						}
@@ -1040,7 +1040,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 									NXP_LOG_ERROR("Can't remove route entry\n");
 								}
 
-								pfe_rtable_entry_free(entry);
+								pfe_rtable_entry_free(fci_context->rtable, entry);
 								entry = NULL;
 							}
 
@@ -1049,7 +1049,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 								NXP_LOG_ERROR("Can't remove route entry\n");
 							}
 
-							pfe_rtable_entry_free(rep_entry);
+							pfe_rtable_entry_free(fci_context->rtable, rep_entry);
 							rep_entry = NULL;
 						}
 						else
@@ -1091,11 +1091,15 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 					if (NULL != entry)
 					{
 						/*	Get associated entry */
-						rep_entry = pfe_rtable_entry_get_child(entry);
+						rep_entry = pfe_rtable_entry_get_child(fci_context->rtable, entry);
 
 						ret = pfe_rtable_del_entry(fci_context->rtable, entry);
 						if (EOK != ret)
 						{
+							/*	Notify rtable module we are done working with this rtable entry */
+							pfe_rtable_entry_free(fci_context->rtable, entry);
+							entry = NULL;
+
 							NXP_LOG_ERROR("Can't remove route entry: %d\n", ret);
 							*fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
 							break;
@@ -1104,7 +1108,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 						{
 							/*	Release all entry-related resources */
 							NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry removed\n");
-							pfe_rtable_entry_free(entry);
+							pfe_rtable_entry_free(fci_context->rtable, entry);
 							entry = NULL;
 							*fci_ret = FPP_ERR_OK;
 						}
@@ -1122,6 +1126,10 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 						ret = pfe_rtable_del_entry(fci_context->rtable, rep_entry);
 						if (EOK != ret)
 						{
+							/*	Notify rtable module we are done working with this rtable entry */
+							pfe_rtable_entry_free(fci_context->rtable, rep_entry);
+							rep_entry = NULL;
+
 							NXP_LOG_ERROR("Can't remove reply route entry: %d\n", ret);
 							*fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
 							break;
@@ -1130,7 +1138,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 						{
 							/*	Release all entry-related resources */
 							NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry removed (reply direction)\n");
-							pfe_rtable_entry_free(rep_entry);
+							pfe_rtable_entry_free(fci_context->rtable, rep_entry);
 							rep_entry = NULL;
 							*fci_ret = FPP_ERR_OK;
 						}
@@ -1159,7 +1167,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 
 					NXP_LOG_INFO("UPDATED conntrack, only TTL decrement flag will be updated\n");
 
-					/*      Get entry by 5-tuple */
+					/*	Get entry by 5-tuple */
 					if (TRUE == ipv6)
 					{
 						fci_connections_ipv6_cmd_to_5t(ct6_cmd, &tuple);
@@ -1197,6 +1205,10 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 							}
 						}
 
+						/*	Notify rtable module we are done working with this rtable entry */
+						pfe_rtable_entry_free(fci_context->rtable, entry);
+						entry = NULL;
+
 						*fci_ret = FPP_ERR_OK;
 						ret = EOK;
 
@@ -1301,7 +1313,7 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 					}
 
 					/*	Check if reply direction does exist */
-					rep_entry =  pfe_rtable_entry_get_child(entry);
+					rep_entry = pfe_rtable_entry_get_child(fci_context->rtable, entry);
 					if (NULL == rep_entry)
 					{
 						/*	This means that entry in 'reply' direction has not been requested
@@ -1412,6 +1424,12 @@ static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, ui
 						}
 					}
 
+					/*	Notify rtable module we are done working with this rtable entry */
+					pfe_rtable_entry_free(fci_context->rtable, entry);
+					pfe_rtable_entry_free(fci_context->rtable, rep_entry);
+					entry = NULL;
+					rep_entry = NULL;
+
 					*fci_ret = FPP_ERR_OK;
 					ret = EOK;
 
@@ -1554,6 +1572,10 @@ errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16_t *fci_ret, fpp_
 				proto = pfe_rtable_entry_get_proto(entry);
 				timeout = fci_connections_get_default_timeout(proto);
 				pfe_rtable_entry_set_timeout(entry, timeout);
+
+				/*	Notify rtable module we are done working with this rtable entry */
+				pfe_rtable_entry_free(fci_context->rtable, entry);
+
 				entry = pfe_rtable_get_next(fci_context->rtable);
 			}
 
@@ -1674,11 +1696,9 @@ errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
 			{
 				NXP_LOG_ERROR("Fatal: Can't remove rtable entry = memory leak\n");
 			}
-			else
-			{
-				/*	Release the entry */
-				pfe_rtable_entry_free(entry);
-			}
+
+			/*	Release (deallocation) of the entry is done by the caller. */
+
 		}
 	}
 
@@ -1697,9 +1717,9 @@ void fci_connections_drop_all(void)
 	errno_t ret;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
-    if (unlikely(FALSE == fci_context->fci_initialized))
+	if (unlikely(FALSE == fci_context->fci_initialized))
 	{
-    	NXP_LOG_ERROR("Context not initialized\n");
+		NXP_LOG_ERROR("Context not initialized\n");
 	}
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
@@ -1715,6 +1735,9 @@ void fci_connections_drop_all(void)
 				NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
 			}
 
+			/*	Release the entry */
+			pfe_rtable_entry_free(fci_context->rtable, entry);
+
 			entry = pfe_rtable_get_next(fci_context->rtable);
 		}
 	}
diff --git a/sw/fci/src/fci_routes.c b/sw/fci/src/fci_routes.c
index 236c6bc..9aab5e5 100644
--- a/sw/fci/src/fci_routes.c
+++ b/sw/fci/src/fci_routes.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -70,6 +70,9 @@ static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
 				NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
 			}
 
+			/*	Release the entry */
+			pfe_rtable_entry_free(fci_context->rtable, entry);
+
 			entry = pfe_rtable_get_next(fci_context->rtable);
 		}
 	}
diff --git a/sw/libfci_cli/Makefile b/sw/libfci_cli/Makefile
index 5e145bd..1f2995e 100644
--- a/sw/libfci_cli/Makefile
+++ b/sw/libfci_cli/Makefile
@@ -61,7 +61,7 @@ ifeq ($(TARGET_OS),LINUX)
 	GLOBAL_CCFLAGS := $(shell echo $(GLOBAL_CCFLAGS))
 	
 	CLI_TARGET_OS = "LNX"
-	CLI_DRV_VERSION = "1.3.0 RC1"
+	CLI_DRV_VERSION = "1.3.0 RC2"
 	CLI_DRV_COMMIT_HASH = "M4_DRIVER_COMMIT_HASH"
 else
 #This branch by defaut means QNX.
diff --git a/sw/linux-pfeng/pfeng-dt.c b/sw/linux-pfeng/pfeng-dt.c
index 230ae3b..22a8f6b 100644
--- a/sw/linux-pfeng/pfeng-dt.c
+++ b/sw/linux-pfeng/pfeng-dt.c
@@ -213,32 +213,6 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 	}
 #endif /* PFE_CFG_PFE_MASTER */
 
-	/* IRQ per HIF */
-	for (i = 0; i < PFENG_PFE_HIF_CHANNELS; i++) {
-		ret = of_property_read_u32_index(np, "nxp,pfeng-hif-channels", i, &propval);
-		if (ret)
-			continue;
-		if (propval >= PFENG_PFE_HIF_CHANNELS) {
-			HM_MSG_DEV_ERR(dev, "HIF channel id=%u is invalid, aborting\n", propval);
-			return -EIO;
-		}
-		scnprintf(propname, sizeof(propname), "hif%d", propval);
-		irq = platform_get_irq_byname(priv->pdev, propname);
-		if (irq < 0) {
-			HM_MSG_DEV_ERR(dev, "Cannot find irq resource '%s', aborting\n", propname);
-			return -EIO;
-		}
-		pfe_cfg->irq_vector_hif_chnls[propval] = irq;
-		HM_MSG_DEV_INFO(dev, "irq '%s' : %u\n", propname, irq);
-
-		priv->hif_chnl[propval].refcount = 0;
-		priv->hif_chnl[propval].ihc = false;
-
-		priv->hif_chnl[propval].status = PFENG_HIF_STATUS_REQUESTED;
-		pfe_cfg->hif_chnls_mask |= 1 << propval;
-	}
-	HM_MSG_DEV_INFO(dev, "HIF channels mask: 0x%04x", pfe_cfg->hif_chnls_mask);
-
 #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
 	if (of_property_read_u32(np, "nxp,pfeng-ihc-channel", &propval)) {
 		HM_MSG_DEV_ERR(dev, "Invalid IHC hif-channel value");
@@ -304,37 +278,44 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 			HM_MSG_DEV_INFO(dev, "DT mac addr: %pM", netif_cfg->macaddr);
 #endif
 
-		if (of_find_property(child, "nxp,pfeng-netif-mode-aux", NULL))
-				netif_cfg->aux = true;
-
-		if (of_find_property(child, "nxp,pfeng-netif-mode-mgmt-only", NULL))
-				netif_cfg->only_mgmt = true;
-
-		HM_MSG_DEV_INFO(dev, "netif(%s) mode: %s", netif_cfg->name,
-			netif_cfg->only_mgmt ? "mgmt" : netif_cfg->aux ? "aux" : "std");
-
-		if (!netif_cfg->aux) {
-			/* EMAC id */
-			if (!of_find_property(child, "nxp,pfeng-emac-id", NULL)) {
-				HM_MSG_DEV_ERR(dev, "The required EMAC id is missing\n");
-				ret = -EINVAL;
-				goto err;
-			}
+		/* Phy id */
+		if (of_find_property(child, "nxp,pfeng-netif-mode-aux", NULL)) {
+			/* unused hole in array is used for AUX netdev */
+			netif_cfg->phyif_id = PFE_PHY_IF_ID_AUX;
+			HM_MSG_DEV_INFO(dev, "netif(%s) no linked phyif in AUX mode", netif_cfg->name);
+		} else {
 			ret = of_property_read_u32(child, "nxp,pfeng-emac-id", &id);
-			if (ret || id >= PFENG_PFE_EMACS) {
-				HM_MSG_DEV_ERR(dev, "The EMAC id is invalid: %d\n", id);
+			if (!ret && id <= PFENG_PFE_EMACS) {
+				/* support backward compatibility */
+				HM_MSG_DEV_WARN(dev, "netif(%s) nxp,pfeng-emac-id property is deprecated, please use nxp,pfeng-linked-phyif", netif_cfg->name);
+			} else if (!of_find_property(child, "nxp,pfeng-linked-phyif", NULL)) {
+				HM_MSG_DEV_ERR(dev, "The required EMAC id is missing\n");
 				ret = -EINVAL;
 				goto err;
+			} else {
+				ret = of_property_read_u32(child, "nxp,pfeng-linked-phyif", &id);
+				if (ret || id >= PFENG_NETIFS_CNT) {
+					HM_MSG_DEV_ERR(dev, "The linked phyif-id is invalid: %d\n", id);
+					ret = -EINVAL;
+					goto err;
+				}
 			}
 #ifdef PFE_CFG_PFE_SLAVE
 			if (of_find_property(child, "nxp,pfeng-emac-router", NULL))
 				netif_cfg->emac_router = true;
 #endif /* PFE_CFG_PFE_SLAVE */
 
-			netif_cfg->emac_id = id;
-			HM_MSG_DEV_INFO(dev, "netif(%s) EMAC: %u", netif_cfg->name, netif_cfg->emac_id);
+			netif_cfg->phyif_id = id;
+			HM_MSG_DEV_INFO(dev, "netif(%s) linked phyif: %u", netif_cfg->name, netif_cfg->phyif_id);
 		}
 
+		if (of_find_property(child, "nxp,pfeng-netif-mode-mgmt-only", NULL)) {
+			netif_cfg->only_mgmt = true;
+			HM_MSG_DEV_INFO(dev, "netif(%s) mode: mgmt", netif_cfg->name);
+		} else
+			HM_MSG_DEV_INFO(dev, "netif(%s) mode: %s", netif_cfg->name,
+				pfeng_netif_cfg_is_aux(netif_cfg) ? "aux" : "std");
+
 		/* netif HIF channel(s) */
 		hifmap = 0;
 		hifs = of_property_count_elems_of_size(child, "nxp,pfeng-hif-channels", sizeof(u32));
@@ -349,6 +330,26 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 				HM_MSG_DEV_ERR(dev, "%pOFn: couldn't read HIF id at index %d, ret=%d\n", np, i, ret);
 				goto err;
 			}
+			if (propval >= PFENG_PFE_HIF_CHANNELS) {
+				HM_MSG_DEV_ERR(dev, "netif(%s) HIF channel id=%u is invalid, aborting\n", netif_cfg->name, propval);
+				goto err;
+			}
+
+			if (!pfe_cfg->irq_vector_hif_chnls[propval]) {
+				/* Get IRQ number */
+				scnprintf(propname, sizeof(propname), "hif%d", propval);
+				irq = platform_get_irq_byname(priv->pdev, propname);
+				if (irq < 0) {
+					HM_MSG_DEV_ERR(dev, "Cannot find irq resource '%s', aborting\n", propname);
+					goto err;
+				}
+				pfe_cfg->irq_vector_hif_chnls[propval] = irq;
+				HM_MSG_DEV_DBG(dev, "irq '%s' : %u\n", propname, irq);
+
+				priv->hif_chnl[propval].status = PFENG_HIF_STATUS_REQUESTED;
+				pfe_cfg->hif_chnls_mask |= 1 << propval;
+			}
+
 			hifmap |= 1 << propval;
 			priv->hif_chnl[propval].refcount++;
 		}
@@ -360,8 +361,8 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 		netif_cfg->dn = of_node_get(child);
 
 #ifdef PFE_CFG_PFE_MASTER
-		if (!netif_cfg->aux) {
-			struct pfeng_emac *emac = &priv->emac[netif_cfg->emac_id];
+		if (pfeng_netif_cfg_has_emac(netif_cfg)) {
+			struct pfeng_emac *emac = &priv->emac[netif_cfg->phyif_id];
 			__maybe_unused struct device_node *phy_handle;
 			phy_interface_t intf_mode;
 
@@ -372,13 +373,13 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 
 			if (pfeng_manged_inband(child)) {
 				emac->link_an = MLO_AN_INBAND;
-				HM_MSG_DEV_INFO(dev, "SGMII AN enabled on EMAC%d\n", netif_cfg->emac_id);
+				HM_MSG_DEV_INFO(dev, "SGMII AN enabled on EMAC%d\n", netif_cfg->phyif_id);
 			}
 
 			emac->phyless = false;
 			phy_handle = of_parse_phandle(child, "phy-handle", 0);
 			if (emac->link_an == MLO_AN_INBAND && !phy_handle) {
-				HM_MSG_DEV_INFO(dev, "EMAC%d PHY less SGMII\n", netif_cfg->emac_id);
+				HM_MSG_DEV_INFO(dev, "EMAC%d PHY less SGMII\n", netif_cfg->phyif_id);
 				emac->phyless = true;
 			}
 
@@ -463,6 +464,8 @@ int pfeng_dt_create_config(struct pfeng_priv *priv)
 		list_add_tail(&netif_cfg->lnode, &priv->netif_cfg_list);
 	} /* foreach PFENG_DT_COMPATIBLE_LOGIF */
 
+	HM_MSG_DEV_INFO(dev, "HIF channels mask: 0x%04x", pfe_cfg->hif_chnls_mask);
+
 	/* Decrement HIF refcount to use simple check for zero */
 	for (i = 0; i < PFENG_PFE_HIF_CHANNELS; i++)
 		if (priv->hif_chnl[i].refcount)
diff --git a/sw/linux-pfeng/pfeng-ethtool.c b/sw/linux-pfeng/pfeng-ethtool.c
index d6d23e9..520f064 100644
--- a/sw/linux-pfeng/pfeng-ethtool.c
+++ b/sw/linux-pfeng/pfeng-ethtool.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2018-2022 NXP
+ * Copyright 2018-2023 NXP
  *
  * SPDX-License-Identifier: GPL-2.0
  *
@@ -81,7 +81,7 @@ static void pfeng_ethtool_get_pauseparam(struct net_device *netdev, struct ethto
 	bool_t rx_pause = false, tx_pause = false;
 	errno_t err;
 
-	err = pfe_phy_if_get_flow_control(netif->priv->emac[netif->cfg->emac_id].phyif_emac, &tx_pause, &rx_pause);
+	err = pfe_phy_if_get_flow_control(pfeng_netif_get_emac_phyif(netif), &tx_pause, &rx_pause);
 	if (err != EOK) {
 		tx_pause = false;
 		rx_pause = false;
@@ -99,8 +99,8 @@ static int pfeng_ethtool_set_pauseparam(struct net_device *netdev, struct ethtoo
 	if (epauseparm->autoneg)
 		return -EOPNOTSUPP;
 
-	pfe_phy_if_set_tx_flow_control(netif->priv->emac[netif->cfg->emac_id].phyif_emac, epauseparm->tx_pause);
-	pfe_phy_if_set_rx_flow_control(netif->priv->emac[netif->cfg->emac_id].phyif_emac, epauseparm->rx_pause);
+	pfe_phy_if_set_tx_flow_control(pfeng_netif_get_emac_phyif(netif), epauseparm->tx_pause);
+	pfe_phy_if_set_rx_flow_control(pfeng_netif_get_emac_phyif(netif), epauseparm->rx_pause);
 
 	return 0;
 }
diff --git a/sw/linux-pfeng/pfeng-hif.c b/sw/linux-pfeng/pfeng-hif.c
index f239ef4..82ed72b 100644
--- a/sw/linux-pfeng/pfeng-hif.c
+++ b/sw/linux-pfeng/pfeng-hif.c
@@ -16,6 +16,11 @@
 #include "pfeng.h"
 #define PFE_DEFAULT_TX_WORK (PFE_CFG_HIF_RING_LENGTH >> 1)
 
+#define pfeng_priv_for_each_chnl(priv, chnl_idx, chnl)			\
+	for (chnl_idx = 0, chnl = &priv->hif_chnl[chnl_idx];		\
+		chnl_idx < PFENG_PFE_HIF_CHANNELS;			\
+		chnl_idx++, chnl = &priv->hif_chnl[chnl_idx])
+
 static const u32 pfeng_hif_id_to_vlan_rx_flag[] = {
 	HIF_RX_HIF0_VLAN,
 	HIF_RX_HIF1_VLAN,
@@ -23,7 +28,7 @@ static const u32 pfeng_hif_id_to_vlan_rx_flag[] = {
 	HIF_RX_HIF3_VLAN
 };
 
-int pfeng_hif_chnl_stop(struct pfeng_hif_chnl *chnl)
+static int pfeng_hif_chnl_stop(struct pfeng_hif_chnl *chnl)
 {
 	/* Disable channel interrupt */
 	pfe_hif_chnl_irq_mask(chnl->priv);
@@ -38,6 +43,8 @@ int pfeng_hif_chnl_stop(struct pfeng_hif_chnl *chnl)
 	/* Disable TX */
 	pfe_hif_chnl_tx_disable(chnl->priv);
 
+	chnl->status = PFENG_HIF_STATUS_ENABLED;
+
 	HM_MSG_DEV_INFO(chnl->dev, "HIF%d stopped\n", chnl->idx);
 
 	return 0;
@@ -77,6 +84,30 @@ int pfeng_hif_chnl_start(struct pfeng_hif_chnl *chnl)
 	return 0;
 }
 
+int pfeng_hif_slave_suspend(struct pfeng_priv *priv)
+{
+	struct pfeng_hif_chnl *chnl;
+	int i;
+
+	pfeng_priv_for_each_chnl(priv, i, chnl)
+		if (chnl->status >= PFENG_HIF_STATUS_ENABLED)
+			pfeng_hif_chnl_stop(chnl);
+
+	return 0;
+}
+
+int pfeng_hif_slave_resume(struct pfeng_priv *priv)
+{
+	struct pfeng_hif_chnl *chnl;
+	int i;
+
+	pfeng_priv_for_each_chnl(priv, i, chnl)
+		if (chnl->status >= PFENG_HIF_STATUS_ENABLED)
+			pfeng_hif_chnl_start(chnl);
+
+	return 0;
+}
+
 /**
  * @brief		HIF channel ISR
  * @details		Will be called by HIF channel instance when an event has occurred
@@ -283,13 +314,13 @@ static int pfeng_hif_chnl_rx(struct pfeng_hif_chnl *chnl, int limit)
 		 */
 		if (likely(!netif->cfg->only_mgmt)) {
 			/* Accept all traffic */
-		} else if (likely(!chnl->netifs[PFENG_NETIFS_AUX_IDX])) {
+		} else if (likely(!chnl->netifs[PFE_PHY_IF_ID_AUX])) {
 			/* No AUX */
 		} else if (unlikely(hif_hdr->flags & (HIF_RX_PTP | HIF_RX_ETS))) {
 			/* Frame is "management" */
 		} else {
 			/* Frame is "non-management", route to AUX */
-			netif = chnl->netifs[PFENG_NETIFS_AUX_IDX];
+			netif = chnl->netifs[PFE_PHY_IF_ID_AUX];
 		}
 
 		netdev = netif->netdev;
diff --git a/sw/linux-pfeng/pfeng-hwts.c b/sw/linux-pfeng/pfeng-hwts.c
index 7324892..a0c619b 100644
--- a/sw/linux-pfeng/pfeng-hwts.c
+++ b/sw/linux-pfeng/pfeng-hwts.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021-2022 NXP
+ * Copyright 2021-2023 NXP
  *
  * SPDX-License-Identifier: GPL-2.0
  *
@@ -10,7 +10,6 @@
 
 #include "pfeng.h"
 
-#ifdef PFE_CFG_PFE_MASTER
 static inline int pfeng_hwts_check_dup(struct pfeng_netif *netif,struct pfeng_ts_skb * new_entry)
 {
 	struct list_head *tmp = NULL, *curr = NULL;
@@ -100,6 +99,9 @@ int pfeng_hwts_store_tx_ref(struct pfeng_netif *netif, struct sk_buff *skb)
 		.ref_num = netif->ts_ref_num++ & 0x0FFFU
 	};
 
+	if (!netif->ts_work_on)
+		return -EINVAL;
+
 	/* Send data to worker */
 	ret = kfifo_put(&netif->ts_skb_fifo, ts_skb_entry);
 	if(0 == ret)
@@ -118,6 +120,9 @@ void pfeng_hwts_get_tx_ts(struct pfeng_netif *netif, pfe_ct_ets_report_t *etsr)
 	struct pfeng_tx_ts tx_timestamp;
 	int ret = 1;
 
+	if (!netif->ts_work_on)
+		return;
+
 	tx_timestamp.ts.hwtstamp = ns_to_ktime(etsr->ts_sec * 1000000000ULL + etsr->ts_nsec);
 	tx_timestamp.ref_num = ntohs(etsr->ref_num) & 0x0FFFU;
 
@@ -128,36 +133,19 @@ void pfeng_hwts_get_tx_ts(struct pfeng_netif *netif, pfe_ct_ets_report_t *etsr)
 	if(0 == ret)
 		HM_MSG_NETDEV_ERR(netif->netdev, "No more memory. Time stamp dropped.\n");
 }
-#else /* PFE_CFG_PFE_MASTER */
-
-void pfeng_hwts_get_rx_ts(struct pfeng_netif *netif, struct sk_buff *skb)
-{
-	/* NOP */
-}
-
-int pfeng_hwts_store_tx_ref(struct pfeng_netif *netif, struct sk_buff *skb)
-{
-	return -ENOMEM;
-}
-
-void pfeng_hwts_get_tx_ts(struct pfeng_netif *netif, pfe_ct_ets_report_t *etsr)
-{
-	/* NOP */
-}
-static void pfeng_hwts_work(struct work_struct *work)
-{
-	/* NOP */
-}
-#endif /* else PFE_CFG_PFE_MASTER */
 
 int pfeng_hwts_ioctl_set(struct pfeng_netif *netif, struct ifreq *rq)
 {
 	struct hwtstamp_config cfg = { 0 };
 
+	if (!netif->ts_work_on)
+		return -EINVAL;
+
 	if (copy_from_user(&cfg, rq->ifr_data, sizeof(cfg)))
 		return -EFAULT;
 
-	if(!IS_ENABLED(PFE_CFG_PFE_MASTER) || !netif->priv->clk_ptp_reference)
+	if((IS_ENABLED(PFE_CFG_PFE_MASTER) && !netif->priv->clk_ptp_reference) ||
+		pfeng_netif_is_aux(netif))
 	{
 		netif->tshw_cfg.rx_filter = HWTSTAMP_FILTER_NONE;
 		netif->tshw_cfg.tx_type = HWTSTAMP_TX_OFF;
@@ -191,13 +179,16 @@ int pfeng_hwts_ioctl_set(struct pfeng_netif *netif, struct ifreq *rq)
 
 int pfeng_hwts_ioctl_get(struct pfeng_netif *netif, struct ifreq *rq)
 {
+	if (!netif->ts_work_on)
+		return -EINVAL;
+
 	return copy_to_user(rq->ifr_data, &netif->tshw_cfg, sizeof(netif->tshw_cfg)) ? -EFAULT : 0;
 }
 
 int pfeng_hwts_ethtool(struct pfeng_netif *netif, struct ethtool_ts_info *info)
 {
-	if (!IS_ENABLED(PFE_CFG_PFE_MASTER) ||
-	    !netif->priv->clk_ptp_reference || netif->cfg->aux) {
+	if ((IS_ENABLED(PFE_CFG_PFE_MASTER) && !netif->priv->clk_ptp_reference) ||
+		pfeng_netif_is_aux(netif)) {
 		info->so_timestamping |= SOF_TIMESTAMPING_TX_SOFTWARE |
 					 SOF_TIMESTAMPING_RX_SOFTWARE |
 					 SOF_TIMESTAMPING_SOFTWARE;
@@ -219,14 +210,11 @@ int pfeng_hwts_ethtool(struct pfeng_netif *netif, struct ethtool_ts_info *info)
 
 int pfeng_hwts_init(struct pfeng_netif *netif)
 {
-#ifdef PFE_CFG_PFE_MASTER
-
 	if (kfifo_alloc(&netif->ts_skb_fifo, 32, GFP_KERNEL))
 		return -ENOMEM;
 
 	if (kfifo_alloc(&netif->ts_tx_fifo, 32, GFP_KERNEL))
 		return -ENOMEM;
-#endif /* PFE_CFG_PFE_MASTER */
 
 	/* Initialize for master and slave to have easier cleanup */
 	INIT_LIST_HEAD(&netif->ts_skb_list);
diff --git a/sw/linux-pfeng/pfeng-netif.c b/sw/linux-pfeng/pfeng-netif.c
index 9539bc8..f09631b 100644
--- a/sw/linux-pfeng/pfeng-netif.c
+++ b/sw/linux-pfeng/pfeng-netif.c
@@ -33,22 +33,6 @@ typedef struct
 	pfe_drv_id_t owner;		/* Identification of the driver that owns this entry */
 } pfeng_netif_mac_db_list_entry_t;
 
-static pfe_log_if_t *pfeng_netif_get_emac_logif(struct pfeng_netif *netif)
-{
-	if (pfeng_netif_is_aux(netif))
-		return NULL;
-
-	return __pfeng_netif_get_emac(netif)->logif_emac;
-}
-
-static pfe_phy_if_t *pfeng_netif_get_emac_phyif(struct pfeng_netif *netif)
-{
-	if (pfeng_netif_is_aux(netif))
-		return NULL;
-
-	return __pfeng_netif_get_emac(netif)->phyif_emac;
-}
-
 static u8 *__mac_to_str(const u8 *addr, u8 *buf, int len)
 {
 	scnprintf(buf, len, "%pM", addr);
@@ -112,10 +96,8 @@ static int pfeng_netif_logif_open(struct net_device *netdev)
 #endif /* PFE_CFG_PFE_MASTER */
 
 #ifdef PFE_CFG_PFE_SLAVE
-	if (!netif->slave_netif_inited) {
-		HM_MSG_NETDEV_ERR(netif->netdev, "SLAVE init transaction failed.\n");
+	if (!netif->slave_netif_inited)
 		return -EINVAL;
-	}
 #endif /* PFE_CFG_PFE_SLAVE */
 
 	/* Configure real RX and TX queues */
@@ -135,7 +117,7 @@ static int pfeng_netif_logif_open(struct net_device *netdev)
 			return -EINVAL;
 		}
 
-		if (netif->cfg->aux) {
+		if (pfeng_netif_is_aux(netif)) {
 			/* PFENG_LOGIF_MODE_TX_CLASS mode requires logIf config */
 			if (!pfe_log_if_is_enabled(chnl->logif_hif)) {
 				ret = pfe_log_if_enable(chnl->logif_hif);
@@ -279,13 +261,13 @@ static netdev_tx_t pfeng_netif_logif_xmit(struct sk_buff *skb, struct net_device
 #endif /* PFE_CFG_HIF_PRIO_CTRL */
 
 	/* Use correct TX mode */
-	if (unlikely(!netif->cfg->aux)) {
+	if (unlikely(!pfeng_netif_is_aux(netif))) {
 		/* Set INJECT flag and bypass classifier */
 		tx_hdr->flags |= HIF_TX_INJECT;
-		tx_hdr->e_phy_ifs = oal_htonl(1U << netif->cfg->emac_id);
+		tx_hdr->e_phy_ifs = oal_htonl(1U << netif->cfg->phyif_id);
 	} else {
 		/* Tag the frame with ID of target physical interface */
-		tx_hdr->cookie = oal_htonl(netif->cfg->emac_id);
+		tx_hdr->cookie = oal_htonl(netif->cfg->phyif_id);
 	}
 
 	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
@@ -441,7 +423,7 @@ static int pfeng_netif_logif_ioctl(struct net_device *netdev, struct ifreq *rq,
 		if (netdev->phydev)
 			return phy_mii_ioctl(netdev->phydev, rq, cmd);
 		/* If no phydev, use direct MDIO call */
-		val = pfeng_mdio_read(netif->priv->emac[netif->cfg->emac_id].mii_bus, phyaddr, phyreg);
+		val = pfeng_mdio_read(pfeng_netif_get_emac(netif)->mii_bus, phyaddr, phyreg);
 		if (val > -1) {
 			mii->val_out = val;
 			return 0;
@@ -451,7 +433,7 @@ static int pfeng_netif_logif_ioctl(struct net_device *netdev, struct ifreq *rq,
 		if (netdev->phydev)
 			return phy_mii_ioctl(netdev->phydev, rq, cmd);
 		/* If no phydev, use direct MDIO call */
-		return pfeng_mdio_write(netif->priv->emac[netif->cfg->emac_id].mii_bus, phyaddr, phyreg, mii->val_in);
+		return pfeng_mdio_write(pfeng_netif_get_emac(netif)->mii_bus, phyaddr, phyreg, mii->val_in);
 	case SIOCGHWTSTAMP:
 		if (phy_has_hwtstamp(netdev->phydev))
 			return phy_mii_ioctl(netdev->phydev, rq, cmd);
@@ -660,7 +642,7 @@ static netdev_features_t pfeng_netif_fix_features(struct net_device *netdev, net
 	struct pfeng_netif *netif = netdev_priv(netdev);
 
 	/* Don't enable hw checksumming for AUX interface */
-	if (netif->cfg->aux) {
+	if (pfeng_netif_is_aux(netif)) {
 		features &= ~(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_RXCSUM);
 		HM_MSG_NETDEV_INFO(netdev, "checksum offload not possible for AUX interface\n");
 	}
@@ -693,19 +675,13 @@ static void pfeng_netif_detach_hifs(struct pfeng_netif *netif)
 		if (!(netif->cfg->hifmap & (1 << i)))
 			continue;
 
-		if (netif->cfg->aux) {
-			chnl->netifs[PFENG_NETIFS_AUX_IDX] = NULL;
-			HM_MSG_NETDEV_INFO(netdev, "AUX unsubscribe from HIF%u\n", chnl->idx);
-			continue;
-		}
-
 		/* Unsubscribe from HIF channel */
-		if (chnl->netifs[netif->cfg->emac_id] != netif) {
+		if (chnl->netifs[netif->cfg->phyif_id] != netif) {
 			HM_MSG_NETDEV_ERR(netdev, "Unknown netif registered to HIF%u\n", i);
 			ret = -EINVAL;
 			return;
 		}
-		chnl->netifs[netif->cfg->emac_id] = NULL;
+		chnl->netifs[netif->cfg->phyif_id] = NULL;
 		HM_MSG_NETDEV_INFO(netdev, "Unsubscribe from HIF%u\n", chnl->idx);
 	}
 }
@@ -726,19 +702,13 @@ static int pfeng_netif_attach_hifs(struct pfeng_netif *netif)
 			goto err;
 		}
 
-		if (netif->cfg->aux) {
-			chnl->netifs[PFENG_NETIFS_AUX_IDX] = netif;
-			HM_MSG_NETDEV_INFO(netdev, "AUX subscribe to HIF%u\n", chnl->idx);
-			continue;
-		}
-
 		/* Subscribe to HIF channel */
-		if (chnl->netifs[netif->cfg->emac_id]) {
+		if (chnl->netifs[netif->cfg->phyif_id]) {
 			HM_MSG_NETDEV_ERR(netdev, "Unable to register to HIF%u\n", i);
 			ret = -EINVAL;
 			goto err;
 		}
-		chnl->netifs[netif->cfg->emac_id] = netif;
+		chnl->netifs[netif->cfg->phyif_id] = netif;
 		HM_MSG_NETDEV_INFO(netdev, "Subscribe to HIF%u\n", chnl->idx);
 	}
 	ret = 0;
@@ -778,12 +748,12 @@ static void pfeng_netif_logif_remove(struct pfeng_netif *netif)
 			HM_MSG_NETDEV_WARN(netif->netdev, "Can't unregister EMAC Logif\n");
 		else
 			pfe_log_if_destroy(logif_emac);
-		netif->priv->emac[netif->cfg->emac_id].logif_emac = NULL;
+		netif->priv->emac[netif->cfg->phyif_id].logif_emac = NULL;
 	}
 
 	HM_MSG_NETDEV_INFO(netif->netdev, "unregisted\n");
 
-	if (!netif->cfg->aux) {
+	if (!pfeng_netif_is_aux(netif)) {
 #ifdef PFE_CFG_PFE_MASTER
 		pfeng_ptp_unregister(netif);
 #endif /* PFE_CFG_PFE_MASTER */
@@ -821,7 +791,7 @@ static int pfeng_netif_control_platform_ifs(struct pfeng_netif *netif)
 	/* Prefetch linked EMAC interfaces */
 	if (emac) {
 		if (!emac->phyif_emac) {
-			emac->phyif_emac = pfe_platform_get_phy_if_by_id(priv->pfe_platform, netif->cfg->emac_id);
+			emac->phyif_emac = pfe_platform_get_phy_if_by_id(priv->pfe_platform, netif->cfg->phyif_id);
 			if (!emac->phyif_emac) {
 				HM_MSG_NETDEV_ERR(netdev, "Could not get linked EMAC physical interface\n");
 				goto err;
@@ -921,12 +891,12 @@ static int pfeng_netif_control_platform_ifs(struct pfeng_netif *netif)
 			HM_MSG_NETDEV_DBG(netdev, "HIF Logif reused: %s @%px\n", hifname, chnl->logif_hif);
 
 		if (emac) {
-			if (netif->cfg->aux) {
+			if (pfeng_netif_is_aux(netif)) {
 				/* Make sure that HIF ingress traffic will be forwarded to respective EMAC */
 #ifdef PFE_CFG_PFE_MASTER
-				ret = pfe_log_if_set_egress_ifs(chnl->logif_hif, 1 << pfeng_emac_ids[netif->cfg->emac_id]);
+				ret = pfe_log_if_set_egress_ifs(chnl->logif_hif, 1 << pfeng_emac_ids[netif->cfg->phyif_id]);
 #else
-				ret = pfe_log_if_add_egress_if(chnl->logif_hif, pfe_platform_get_phy_if_by_id(priv->pfe_platform, pfeng_emac_ids[netif->cfg->emac_id]));
+				ret = pfe_log_if_add_egress_if(chnl->logif_hif, pfe_platform_get_phy_if_by_id(priv->pfe_platform, pfeng_emac_ids[netif->cfg->phyif_id]));
 #endif
 				if (EOK != ret) {
 					HM_MSG_NETDEV_ERR(netdev, "Can't set HIF egress interface\n");
@@ -938,7 +908,7 @@ static int pfeng_netif_control_platform_ifs(struct pfeng_netif *netif)
 
 #ifdef PFE_CFG_PFE_SLAVE
 	/* Add rule for local MAC */
-	if (!netif->cfg->aux && emac) {
+	if (!pfeng_netif_is_aux(netif) && emac) {
 		/* Configure the logical interface to accept frames matching local MAC address */
 		ret = pfe_log_if_add_match_rule(emac->logif_emac, IF_MATCH_DMAC, (void *)netif->cfg->macaddr, 6U);
 		if (EOK != ret) {
@@ -984,7 +954,7 @@ static int pfeng_netif_logif_init_second_stage(struct pfeng_netif *netif)
 
 	pfeng_netif_set_mac_address(netdev, (void *)&saddr);
 
-	if (!netif->cfg->aux) {
+	if (!pfeng_netif_is_aux(netif)) {
 		/* Init hw timestamp */
 		ret = pfeng_hwts_init(netif);
 		if (ret) {
@@ -1039,20 +1009,23 @@ static int pfeng_netif_event(struct notifier_block *nb,
 			struct pfeng_netif *netif = netdev_priv(ndev);
 			struct pfeng_emac *emac = pfeng_netif_get_emac(netif);
 
+			if (!emac)
+				goto out;
+
 			if (!emac->rx_clk_pending)
 				goto out;
 
 			ret = clk_prepare_enable(emac->rx_clk);
 			if (ret) {
 				HM_MSG_DEV_ERR(netif->dev, "Failed to enable RX clock on EMAC%d for interface %s (err %d)\n",
-					netif->cfg->emac_id, phy_modes(emac->intf_mode), ret);
+					netif->cfg->phyif_id, phy_modes(emac->intf_mode), ret);
 				goto out;
 			}
 
 			emac->rx_clk_pending = false;
 
 			HM_MSG_DEV_INFO(netif->dev, "RX clock on EMAC%d for interface %s installed\n",
-				 netif->cfg->emac_id, phy_modes(emac->intf_mode));
+				 netif->cfg->phyif_id, phy_modes(emac->intf_mode));
 		}
 
 		break;
@@ -1151,12 +1124,12 @@ static struct pfeng_netif *pfeng_netif_logif_create(struct pfeng_priv *priv, str
 
 #ifdef PFE_CFG_PFE_MASTER
 	/* Add phylink */
-	if (!netif_cfg->aux && priv->emac[netif_cfg->emac_id].intf_mode != PHY_INTERFACE_MODE_INTERNAL)
+	if (pfeng_netif_cfg_has_emac(netif->cfg) && priv->emac[netif_cfg->phyif_id].intf_mode != PHY_INTERFACE_MODE_INTERNAL)
 		pfeng_phylink_create(netif);
 #endif
 
 	/* Accelerated feature */
-	if (!netif_cfg->aux) {
+	if (!pfeng_netif_is_aux(netif)) {
 		/* Chksumming can be enabled only if no AUX involved */
 		netdev->hw_features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_RXCSUM;
 	}
@@ -1296,19 +1269,28 @@ static int pfeng_netif_logif_suspend(struct pfeng_netif *netif)
 		if (!chnl->ihc)
 #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
 		{
+#ifdef PFE_CFG_PFE_MASTER
+			/* On Standalone/Master we disable HIF logif instances */
 			chnl->phyif_hif = NULL;
 			if (chnl->logif_hif) {
 				pfe_log_if_disable(chnl->logif_hif);
 				chnl->logif_hif = NULL;
 			}
+#else
+			/* On Slave we only stop HIF instances */
+			if (chnl->logif_hif)
+				pfe_log_if_disable(chnl->logif_hif);
+#endif /* PFE_CFG_PFE_MASTER */
 		}
 	}
 
+#ifdef PFE_CFG_PFE_MASTER
 	/* Reset linked EMAC IFs */
 	if (emac) {
 		emac->phyif_emac = NULL;
 		emac->logif_emac = NULL;
 	}
+#endif /* PFE_CFG_PFE_MASTER */
 
 	return 0;
 }
@@ -1348,13 +1330,13 @@ static int pfeng_netif_logif_resume(struct pfeng_netif *netif)
 		if (emac->tx_clk) {
 			ret = clk_set_rate(emac->tx_clk, clk_rate);
 			if (ret)
-				HM_MSG_DEV_ERR(dev, "Failed to set TX clock on EMAC%d: %d\n", netif->cfg->emac_id, ret);
+				HM_MSG_DEV_ERR(dev, "Failed to set TX clock on EMAC%d: %d\n", netif->cfg->phyif_id, ret);
 			else {
 				ret = clk_prepare_enable(emac->tx_clk);
 				if (ret)
-					HM_MSG_DEV_ERR(dev, "TX clocks restart on EMAC%d failed: %d\n", netif->cfg->emac_id, ret);
+					HM_MSG_DEV_ERR(dev, "TX clocks restart on EMAC%d failed: %d\n", netif->cfg->phyif_id, ret);
 				else
-					HM_MSG_DEV_INFO(dev, "TX clocks on EMAC%d restarted\n", netif->cfg->emac_id);
+					HM_MSG_DEV_INFO(dev, "TX clocks on EMAC%d restarted\n", netif->cfg->phyif_id);
 			}
 			if (ret) {
 				devm_clk_put(dev, emac->tx_clk);
@@ -1365,13 +1347,13 @@ static int pfeng_netif_logif_resume(struct pfeng_netif *netif)
 		if (emac->rx_clk) {
 			ret = clk_set_rate(emac->rx_clk, clk_rate);
 			if (ret)
-				HM_MSG_DEV_ERR(dev, "Failed to set RX clock on EMAC%d: %d\n", netif->cfg->emac_id, ret);
+				HM_MSG_DEV_ERR(dev, "Failed to set RX clock on EMAC%d: %d\n", netif->cfg->phyif_id, ret);
 			else {
 				ret = clk_prepare_enable(emac->rx_clk);
 				if (ret)
-					HM_MSG_DEV_ERR(dev, "RX clocks restart on EMAC%d failed: %d\n", netif->cfg->emac_id, ret);
+					HM_MSG_DEV_ERR(dev, "RX clocks restart on EMAC%d failed: %d\n", netif->cfg->phyif_id, ret);
 				else
-					HM_MSG_DEV_INFO(dev, "RX clocks on EMAC%d restarted\n", netif->cfg->emac_id);
+					HM_MSG_DEV_INFO(dev, "RX clocks on EMAC%d restarted\n", netif->cfg->phyif_id);
 			}
 			if (ret) {
 				devm_clk_put(dev, emac->rx_clk);
@@ -1379,9 +1361,9 @@ static int pfeng_netif_logif_resume(struct pfeng_netif *netif)
 			}
 		}
 	}
-#endif /* PFE_CFG_PFE_MASTER */
 
 	ret = pfeng_netif_logif_init_second_stage(netif);
+#endif /* PFE_CFG_PFE_MASTER */
 
 	/* start HIF channel(s) */
 	pfeng_netif_for_each_chnl(netif, i, chnl) {
@@ -1394,7 +1376,7 @@ static int pfeng_netif_logif_resume(struct pfeng_netif *netif)
 		if (chnl->status != PFENG_HIF_STATUS_RUNNING)
 			HM_MSG_NETDEV_WARN(netif->netdev, "HIF%u in invalid state: not running\n", i);
 
-		if (netif->cfg->aux) {
+		if (pfeng_netif_is_aux(netif)) {
 			/* PFENG_LOGIF_MODE_TX_CLASS mode requires logIf config */
 			if (!pfe_log_if_is_enabled(chnl->logif_hif)) {
 				ret = pfe_log_if_enable(chnl->logif_hif);
diff --git a/sw/linux-pfeng/pfeng-phylink.c b/sw/linux-pfeng/pfeng-phylink.c
index 024c52e..60731fd 100644
--- a/sw/linux-pfeng/pfeng-phylink.c
+++ b/sw/linux-pfeng/pfeng-phylink.c
@@ -27,8 +27,8 @@
 
 static void pfeng_cfg_to_plat(struct pfeng_netif *netif, const struct phylink_link_state *state)
 {
-	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
-	pfe_emac_t *pfe_emac = netif->priv->pfe_platform->emac[netif->cfg->emac_id];
+	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
+	pfe_emac_t *pfe_emac = netif->priv->pfe_platform->emac[netif->cfg->phyif_id];
 	u32 emac_speed, emac_duplex;
 	bool speed_valid = true, duplex_valid = true;
 
@@ -79,7 +79,7 @@ static void pfeng_cfg_to_plat(struct pfeng_netif *netif, const struct phylink_li
 /* This could be done automatically in phylink in 5.10+ */
 void pfeng_xpcs_poll(struct work_struct * work) {
 	struct pfeng_netif *netif = container_of(work, struct pfeng_netif, xpcs_poll_work.work);
-	struct pfeng_emac *emac  = &netif->priv->emac[netif->cfg->emac_id];
+	struct pfeng_emac *emac  = &netif->priv->emac[netif->cfg->phyif_id];
 	struct phylink_link_state sgmii_state = { 0 };
 
 	emac->xpcs_ops->xpcs_get_state(emac->xpcs, &sgmii_state);
@@ -102,8 +102,8 @@ static void pfeng_phylink_validate(struct phylink_config *config, unsigned long
 	struct pfeng_priv *priv = netif->priv;
 	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = { 0, };
 	__ETHTOOL_DECLARE_LINK_MODE_MASK(mac_supported) = { 0, };
-	int max_speed = priv->emac[netif->cfg->emac_id].max_speed;
-	int an_serdes_speed = priv->emac[netif->cfg->emac_id].serdes_an_speed;
+	int max_speed = priv->emac[netif->cfg->phyif_id].max_speed;
+	int an_serdes_speed = priv->emac[netif->cfg->phyif_id].serdes_an_speed;
 
 	/* We only support SGMII and R/G/MII modes */
 	if (state->interface != PHY_INTERFACE_MODE_NA &&
@@ -137,7 +137,7 @@ static void pfeng_phylink_validate(struct phylink_config *config, unsigned long
 		/* G3: All PFE_EMACs support 2.5G over SGMII */
 		(netif->priv->on_g3 ||
 		/* G2: Only PFE_EMAC_0 supports 2.5G over SGMII */
-			!netif->cfg->emac_id) &&
+			!netif->cfg->phyif_id) &&
 		(state->interface == PHY_INTERFACE_MODE_SGMII ||
 		state->interface == PHY_INTERFACE_MODE_NA)) {
 		phylink_set(mac_supported, 2500baseT_Full);
@@ -146,7 +146,7 @@ static void pfeng_phylink_validate(struct phylink_config *config, unsigned long
 
 	/* SGMII AN can't distinguish between 1G and 2.5G */
 	if (state->interface == PHY_INTERFACE_MODE_SGMII &&
-	    priv->emac[netif->cfg->emac_id].link_an == MLO_AN_INBAND) {
+	    priv->emac[netif->cfg->phyif_id].link_an == MLO_AN_INBAND) {
 		if (an_serdes_speed == SPEED_2500) {
 			phylink_set(mask, 10baseT_Half);
 			phylink_set(mask, 10baseT_Full);
@@ -160,7 +160,7 @@ static void pfeng_phylink_validate(struct phylink_config *config, unsigned long
 			phylink_set(mask, 2500baseT_Full);
 			phylink_set(mask, 2500baseX_Full);
 		}
-	} else if (priv->emac[netif->cfg->emac_id].link_an == MLO_AN_FIXED) {
+	} else if (priv->emac[netif->cfg->phyif_id].link_an == MLO_AN_FIXED) {
 		phylink_clear(mac_supported, Autoneg);
 	}
 
@@ -183,7 +183,7 @@ static void pfeng_phylink_validate(struct phylink_config *config, unsigned long
 static int _pfeng_mac_link_state(struct phylink_config *config, struct phylink_link_state *state)
 {
 	struct pfeng_netif *netif = netdev_priv(to_net_dev(config->dev));
-	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
+	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
 
 	state->interface = emac->intf_mode;
 
@@ -226,7 +226,7 @@ static void pfeng_mac_an_restart(struct phylink_config *config)
  */
 static int s32g_set_rgmii_speed(struct pfeng_netif *netif, unsigned int speed)
 {
-	struct clk *tx_clk = netif->priv->emac[netif->cfg->emac_id].tx_clk;
+	struct clk *tx_clk = netif->priv->emac[netif->cfg->phyif_id].tx_clk;
 	unsigned long rate = 0;
 	int ret = 0;
 
@@ -259,7 +259,7 @@ static int s32g_set_rgmii_speed(struct pfeng_netif *netif, unsigned int speed)
 static void pfeng_mac_config(struct phylink_config *config, unsigned int mode, const struct phylink_link_state *state)
 {
 	struct pfeng_netif *netif = netdev_priv(to_net_dev(config->dev));
-	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
+	struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
 	__maybe_unused struct phylink_link_state sgmii_state = { 0 };
 
 	if (mode == MLO_AN_FIXED || mode == MLO_AN_PHY) {
@@ -345,7 +345,7 @@ static const struct phylink_mac_ops pfeng_phylink_ops = {
 int pfeng_phylink_create(struct pfeng_netif *netif)
 {
 	struct pfeng_priv *priv = netif->priv;
-	struct pfeng_emac *emac = &priv->emac[netif->cfg->emac_id];
+	struct pfeng_emac *emac = &priv->emac[netif->cfg->phyif_id];
 	struct phylink *phylink;
 
 	netif->phylink_cfg.dev = &netif->netdev->dev;
@@ -365,14 +365,14 @@ int pfeng_phylink_create(struct pfeng_netif *netif)
 				emac->xpcs = s32cc_phy2xpcs(emac->serdes_phy);
 				emac->xpcs_ops = s32cc_xpcs_get_ops();
 			} else {
-				HM_MSG_DEV_ERR(netif->dev, "SerDes PHY configuration failed on EMAC%d\n", netif->cfg->emac_id);
+				HM_MSG_DEV_ERR(netif->dev, "SerDes PHY configuration failed on EMAC%d\n", netif->cfg->phyif_id);
 			}
 		} else {
-			HM_MSG_DEV_ERR(netif->dev, "SerDes PHY init failed on EMAC%d\n", netif->cfg->emac_id);
+			HM_MSG_DEV_ERR(netif->dev, "SerDes PHY init failed on EMAC%d\n", netif->cfg->phyif_id);
 		}
 
 		if (!emac->xpcs || !emac->xpcs_ops) {
-			HM_MSG_DEV_ERR(netif->dev, "Can't get SGMII PCS on EMAC%d\n", netif->cfg->emac_id);
+			HM_MSG_DEV_ERR(netif->dev, "Can't get SGMII PCS on EMAC%d\n", netif->cfg->phyif_id);
 			emac->xpcs_ops = NULL;
 			emac->xpcs = NULL;
 		}
@@ -389,7 +389,7 @@ int pfeng_phylink_create(struct pfeng_netif *netif)
  */
 int pfeng_phylink_start(struct pfeng_netif *netif)
 {
-	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
+	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
 
 	phylink_start(netif->phylink);
 
@@ -443,7 +443,7 @@ void pfeng_phylink_mac_change(struct pfeng_netif *netif, bool up)
  */
 void pfeng_phylink_stop(struct pfeng_netif *netif)
 {
-	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
+	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
 
 	phylink_stop(netif->phylink);
 
@@ -458,7 +458,7 @@ void pfeng_phylink_stop(struct pfeng_netif *netif)
  */
 void pfeng_phylink_destroy(struct pfeng_netif *netif)
 {
-	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->emac_id];
+	__maybe_unused struct pfeng_emac *emac = &netif->priv->emac[netif->cfg->phyif_id];
 	phylink_destroy(netif->phylink);
 	netif->phylink = NULL;
 
diff --git a/sw/linux-pfeng/pfeng-ptp.c b/sw/linux-pfeng/pfeng-ptp.c
index 5990a91..5fdf8eb 100644
--- a/sw/linux-pfeng/pfeng-ptp.c
+++ b/sw/linux-pfeng/pfeng-ptp.c
@@ -17,7 +17,7 @@ int pfeng_ptp_adjfreq(struct ptp_clock_info *ptp, s32 delta)
 {
 	struct pfeng_netif *netif = container_of(ptp, struct pfeng_netif, ptp_ops);
 	struct pfeng_priv *priv = netif->priv;
-        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->emac_id];
+        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->phyif_id];
 	bool_t sgn = TRUE;
 	errno_t ret = 0;
 
@@ -31,7 +31,7 @@ int pfeng_ptp_adjfreq(struct ptp_clock_info *ptp, s32 delta)
 	ret = pfe_emac_set_ts_freq_adjustment(emac, delta, sgn);
 
 	if (ret == EPERM) {
-		HM_MSG_NETDEV_WARN(netif->netdev, "Frequency adjustment failed on EMAC%u\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_WARN(netif->netdev, "Frequency adjustment failed on EMAC%u\n", netif->cfg->phyif_id);
 		ret = -EOPNOTSUPP;
 	} else if (ret != 0){
 		HM_MSG_NETDEV_ERR(netif->netdev, "Frequency adjustment failed (err %d)\n", ret);
@@ -45,7 +45,7 @@ int pfeng_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)
 {
 	struct pfeng_netif *netif = container_of(ptp, struct pfeng_netif, ptp_ops);
 	struct pfeng_priv *priv = netif->priv;
-        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->emac_id];
+        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->phyif_id];
 	errno_t ret = 0;
 	bool_t sgn = TRUE;
 	uint32_t sec = 0, nsec = 0;
@@ -63,7 +63,7 @@ int pfeng_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)
 	ret = pfe_emac_adjust_ts_time(emac, sec, nsec, sgn);
 
 	if (ret == EPERM) {
-		HM_MSG_NETDEV_WARN(netif->netdev, "Time adjustment failed on EMAC%u\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_WARN(netif->netdev, "Time adjustment failed on EMAC%u\n", netif->cfg->phyif_id);
 		ret = -EOPNOTSUPP;
 	} else if (ret != 0) {
 		HM_MSG_NETDEV_ERR(netif->netdev, "Time adjustment failed (err %d)\n", ret);
@@ -77,7 +77,7 @@ int pfeng_ptp_gettime64(struct ptp_clock_info *ptp, struct timespec64 *ts)
 {
 	struct pfeng_netif *netif = container_of(ptp, struct pfeng_netif, ptp_ops);
 	struct pfeng_priv *priv = netif->priv;
-        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->emac_id];
+        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->phyif_id];
 	uint32_t sec = 0, nsec = 0;
 	uint16_t sec_hi = 0;
 	errno_t ret;
@@ -100,7 +100,7 @@ int pfeng_ptp_settime64(struct ptp_clock_info *ptp, const struct timespec64 *ts)
 {
 	struct pfeng_netif *netif = container_of(ptp, struct pfeng_netif, ptp_ops);
 	struct pfeng_priv *priv = netif->priv;
-	pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->emac_id];
+	pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->phyif_id];
 	errno_t ret;
 	uint32_t sec = (uint64_t)ts->tv_sec & 0x00000000FFFFFFFFU;
 	uint16_t sec_hi = (uint16_t)(ts->tv_sec >> 32);
@@ -110,7 +110,7 @@ int pfeng_ptp_settime64(struct ptp_clock_info *ptp, const struct timespec64 *ts)
 	ret = pfe_emac_set_ts_time(emac, sec, ts->tv_nsec, sec_hi);
 
 	if (ret == EPERM) {
-		HM_MSG_NETDEV_WARN(netif->netdev, "Set time failed on EMAC%u\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_WARN(netif->netdev, "Set time failed on EMAC%u\n", netif->cfg->phyif_id);
 		ret = -EOPNOTSUPP;
 	} else if (ret != 0) {
 		HM_MSG_NETDEV_ERR(netif->netdev, "Set time failed (err %d)\n", ret);
@@ -161,10 +161,15 @@ static void pfeng_ptp_prepare_clock_adjustement(struct pfeng_netif *netif, unsig
 void pfeng_ptp_register(struct pfeng_netif *netif)
 {
 	struct pfeng_priv *priv = netif->priv;
-        pfe_emac_t *emac = priv->pfe_platform->emac[netif->cfg->emac_id];
+        pfe_emac_t *emac;
 	errno_t ret;
 	bool ext_ts;
 
+	if (!pfeng_netif_cfg_has_emac(netif->cfg))
+		return;
+
+        emac = priv->pfe_platform->emac[netif->cfg->phyif_id];
+
 	/* Set PTP clock to null in case of error */
 	netif->ptp_clock = NULL;
 
@@ -176,13 +181,13 @@ void pfeng_ptp_register(struct pfeng_netif *netif)
 	pfeng_ptp_prepare_clock_adjustement(netif, priv->clk_ptp_reference);
 
 	/* Get EMAC's timestamping mode external / internal */
-	ext_ts = priv->pfe_platform->emac_ext_ts_mask & (1 << netif->cfg->emac_id);
+	ext_ts = priv->pfe_platform->emac_ext_ts_mask & (1 << netif->cfg->phyif_id);
 	/* Start PTP clock and enable time stamping in platform */
 	ret = pfe_emac_enable_ts(emac, priv->clk_ptp_reference,
 				 ext_ts ? 0 : (priv->clk_ptp_reference / 2LLU));
 
 	if(ret) {
-		HM_MSG_DEV_ERR(netif->dev, "Failed to register PTP clock on EMAC%d\n", netif->cfg->emac_id);
+		HM_MSG_DEV_ERR(netif->dev, "Failed to register PTP clock on EMAC%d\n", netif->cfg->phyif_id);
 		return;
 	}
 
@@ -191,9 +196,9 @@ void pfeng_ptp_register(struct pfeng_netif *netif)
 	netif->ptp_clock = ptp_clock_register(&netif->ptp_ops, netif->dev);
 
 	if (IS_ERR(netif->ptp_clock))
-		HM_MSG_NETDEV_ERR(netif->netdev, "Failed to register PTP clock on EMAC%d\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_ERR(netif->netdev, "Failed to register PTP clock on EMAC%d\n", netif->cfg->phyif_id);
 	else if (netif->ptp_clock)
-		HM_MSG_NETDEV_INFO(netif->netdev, "Registered PTP HW clock successfully on EMAC%d\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_INFO(netif->netdev, "Registered PTP HW clock successfully on EMAC%d\n", netif->cfg->phyif_id);
 }
 
 void pfeng_ptp_unregister(struct pfeng_netif *netif)
@@ -201,6 +206,6 @@ void pfeng_ptp_unregister(struct pfeng_netif *netif)
 	if (netif->ptp_clock) {
 		ptp_clock_unregister(netif->ptp_clock);
 		netif->ptp_clock = NULL;
-		HM_MSG_NETDEV_INFO(netif->netdev, "Unregistered PTP HW clock successfully on EMAC%d\n", netif->cfg->emac_id);
+		HM_MSG_NETDEV_INFO(netif->netdev, "Unregistered PTP HW clock successfully on EMAC%d\n", netif->cfg->phyif_id);
 	}
 }
diff --git a/sw/linux-pfeng/pfeng-slave-drv.c b/sw/linux-pfeng/pfeng-slave-drv.c
index e65713e..3f51526 100644
--- a/sw/linux-pfeng/pfeng-slave-drv.c
+++ b/sw/linux-pfeng/pfeng-slave-drv.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021-2022 NXP
+ * Copyright 2021-2023 NXP
  *
  * SPDX-License-Identifier: GPL-2.0
  *
@@ -165,23 +165,6 @@ static int pfeng_drv_remove(struct platform_device *pdev)
 
 	pfeng_dt_release_config(priv);
 
-	/* Free clocks */
-	if (priv->clk_ptp) {
-		clk_disable_unprepare(priv->clk_ptp);
-		clk_put(priv->clk_ptp);
-		priv->clk_ptp = NULL;
-	}
-	if (priv->clk_pe) {
-		clk_disable_unprepare(priv->clk_pe);
-		clk_put(priv->clk_pe);
-		priv->clk_pe = NULL;
-	}
-	if (priv->clk_sys) {
-		clk_disable_unprepare(priv->clk_sys);
-		clk_put(priv->clk_sys);
-		priv->clk_sys = NULL;
-	}
-
 	dev_set_drvdata(dev, NULL);
 
 	/* Shutdown memory management */
@@ -388,13 +371,48 @@ err_drv:
 /* Slave PM is not supported */
 static int pfeng_drv_pm_suspend(struct device *dev)
 {
-	HM_MSG_DEV_ERR(dev, "Suspending driver is unsupported\n");
+	struct pfeng_priv *priv = dev_get_drvdata(dev);
+
+	HM_MSG_DEV_INFO(dev, "Suspending driver\n");
+
+	priv->in_suspend = true;
+
+	pfeng_debugfs_remove(priv);
+
+	/* MDIO buses */
+	pfeng_mdio_suspend(priv);
+
+	/* NETIFs */
+	pfeng_netif_suspend(priv);
+
+	/* HIFs stop */
+	pfeng_hif_slave_suspend(priv);
+
+	HM_MSG_DEV_INFO(dev, "PFE Platform suspended\n");
 
 	return -ENOTSUP;
 }
 
 static int pfeng_drv_pm_resume(struct device *dev)
 {
+	struct pfeng_priv *priv = dev_get_drvdata(dev);
+
+	HM_MSG_DEV_INFO(dev, "Resuming driver\n");
+
+	/* Create debugfs */
+	pfeng_debugfs_create(priv);
+
+	/* HIFs start */
+	pfeng_hif_slave_resume(priv);
+
+	/* MDIO buses */
+	pfeng_mdio_resume(priv);
+
+	/* Create net interfaces */
+	pfeng_netif_resume(priv);
+
+	priv->in_suspend = false;
+
 	return 0;
 }
 
@@ -402,6 +420,18 @@ SIMPLE_DEV_PM_OPS(pfeng_drv_pm_ops,
 			pfeng_drv_pm_suspend,
 			pfeng_drv_pm_resume);
 
+
+/**
+ * pfeng_drv_shutdown
+ *
+ * @pdev: platform device pointer
+ * Description: this function calls at shut-down time to quiesce the device
+ */
+static void pfeng_drv_shutdown(struct platform_device *pdev)
+{
+	pfeng_drv_remove(pdev);
+}
+
 /* platform data */
 
 static struct platform_driver pfeng_platform_driver = {
@@ -412,6 +442,7 @@ static struct platform_driver pfeng_platform_driver = {
 		.pm = &pfeng_drv_pm_ops,
 		.of_match_table = of_match_ptr(pfeng_id_table),
 	},
+	.shutdown = pfeng_drv_shutdown,
 };
 
 module_platform_driver(pfeng_platform_driver);
diff --git a/sw/linux-pfeng/pfeng.h b/sw/linux-pfeng/pfeng.h
index d7b0761..03fedfc 100644
--- a/sw/linux-pfeng/pfeng.h
+++ b/sw/linux-pfeng/pfeng.h
@@ -44,7 +44,7 @@
 #else
 #error Incorrect configuration!
 #endif
-#define PFENG_DRIVER_VERSION		"1.3.0 RC1"
+#define PFENG_DRIVER_VERSION		"1.3.0 RC2"
 
 #define PFENG_FW_CLASS_NAME		"s32g_pfe_class.fw"
 #define PFENG_FW_UTIL_NAME		"s32g_pfe_util.fw"
@@ -71,6 +71,7 @@ static const pfe_ct_phy_if_id_t pfeng_hif_ids[] = {
 	PFE_PHY_IF_ID_HIF3,
 	/* HIF NOCPY is unsupported, the id can be used
 	 * only for addressing master IDEX HIF channel
+	 * or linked HIF netdev
 	 */
 	PFE_PHY_IF_ID_HIF_NOCPY
 };
@@ -78,15 +79,6 @@ static const pfe_ct_phy_if_id_t pfeng_hif_ids[] = {
 #define PFENG_PFE_HIF_CHANNELS		(ARRAY_SIZE(pfeng_hif_ids) - 1)
 #define PFENG_PFE_EMACS			(ARRAY_SIZE(pfeng_emac_ids))
 
-/* LOGIF mode variants */
-enum {
-	PFENG_LOGIF_MODE_TX_INJECT,
-	PFENG_LOGIF_MODE_TX_CLASS,
-	PFENG_LOGIF_MODE_RESERVED_1,
-	PFENG_LOGIF_MODE_AUX
-};
-
-
 /* HIF channel mode variants */
 enum {
 	PFENG_HIF_MODE_EXCLUSIVE,
@@ -130,10 +122,9 @@ struct pfeng_netif_cfg {
 	const char			*name;
 	struct device_node		*dn;
 	u8				macaddr[ETH_ALEN];
-	u8				emac_id;
+	u8				phyif_id;
 	u8				hifs;
 	u32				hifmap;
-	bool				aux;
 	bool				pause_rx;
 	bool				pause_tx;
 #ifdef PFE_CFG_PFE_SLAVE
@@ -190,9 +181,10 @@ struct pfe_hif_drv_tag
 };
 #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
 
-/* Count for max 3 EMAC netifs and 1 AUX netif */
-#define PFENG_NETIFS_CNT	PFENG_PFE_EMACS + 1
-#define PFENG_NETIFS_AUX_IDX	PFENG_PFE_EMACS
+/* netif array maps every phy_if to netif */
+#define PFENG_NETIFS_CNT	(PFE_PHY_IF_ID_MAX + 1)
+/* PHY_IF id hole of HIF block is used for AUX */
+#define PFE_PHY_IF_ID_AUX	PFE_PHY_IF_ID_HIF
 
 struct pfeng_rx_chnl_pool;
 struct pfeng_tx_chnl_pool;
@@ -232,12 +224,12 @@ struct pfeng_hif_chnl {
 static inline struct pfeng_netif *pfeng_phy_if_id_to_netif(struct pfeng_hif_chnl *chnl,
 							   pfe_ct_phy_if_id_t phy_if_id)
 {
-	if (likely((phy_if_id >= PFE_PHY_IF_ID_EMAC0 && phy_if_id <= PFE_PHY_IF_ID_EMAC2) &&
-		chnl->netifs[phy_if_id - PFE_PHY_IF_ID_EMAC0])) {
-		return chnl->netifs[phy_if_id - PFE_PHY_IF_ID_EMAC0];
+	if (likely((phy_if_id <= PFE_PHY_IF_ID_MAX) &&
+		chnl->netifs[phy_if_id])) {
+		return chnl->netifs[phy_if_id];
 	}
 
-	return chnl->netifs[PFENG_NETIFS_AUX_IDX];
+	return chnl->netifs[PFE_PHY_IF_ID_AUX];
 }
 
 /* leave out one BD to ensure minimum gap */
@@ -327,24 +319,50 @@ struct pfeng_priv {
 	u32				msg_verbosity;
 };
 
+static inline bool pfeng_netif_cfg_is_aux(struct pfeng_netif_cfg *cfg)
+{
+	return cfg->phyif_id == PFE_PHY_IF_ID_AUX;
+}
+
 static inline bool pfeng_netif_is_aux(struct pfeng_netif *netif)
 {
-	return netif->cfg->aux;
+	return pfeng_netif_cfg_is_aux(netif->cfg);
 }
 
 static inline struct pfeng_emac *__pfeng_netif_get_emac(struct pfeng_netif *netif)
 {
-	return &netif->priv->emac[netif->cfg->emac_id];
+	return &netif->priv->emac[netif->cfg->phyif_id];
+}
+
+static inline bool pfeng_netif_cfg_has_emac(struct pfeng_netif_cfg *cfg)
+{
+	return cfg->phyif_id <= PFE_PHY_IF_ID_EMAC2;
 }
 
 static inline struct pfeng_emac *pfeng_netif_get_emac(struct pfeng_netif *netif)
 {
-	if (pfeng_netif_is_aux(netif))
+	if (!pfeng_netif_cfg_has_emac(netif->cfg))
 		return NULL;
 
 	return __pfeng_netif_get_emac(netif);
 }
 
+static inline pfe_log_if_t *pfeng_netif_get_emac_logif(struct pfeng_netif *netif)
+{
+	if (!pfeng_netif_cfg_has_emac(netif->cfg))
+		return NULL;
+
+	return __pfeng_netif_get_emac(netif)->logif_emac;
+}
+
+static inline pfe_phy_if_t *pfeng_netif_get_emac_phyif(struct pfeng_netif *netif)
+{
+	if (!pfeng_netif_cfg_has_emac(netif->cfg))
+		return NULL;
+
+	return __pfeng_netif_get_emac(netif)->phyif_emac;
+}
+
 /* fw */
 int pfeng_fw_load(struct pfeng_priv *priv, const char *fw_class_name, const char *fw_util_name);
 void pfeng_fw_free(struct pfeng_priv *priv);
@@ -375,6 +393,10 @@ int pfeng_hif_chnl_set_coalesce(struct pfeng_hif_chnl *chnl, struct clk *clk_sys
 void pfeng_ihc_tx_work_handler(struct work_struct *work);
 void pfeng_ihc_rx_work_handler(struct work_struct *work);
 #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
+#ifdef PFE_CFG_PFE_SLAVE
+int pfeng_hif_slave_suspend(struct pfeng_priv *priv);
+int pfeng_hif_slave_resume(struct pfeng_priv *priv);
+#endif /* PFE_CFG_PFE_SLAVE */
 
 /* bman */
 int pfeng_bman_pool_create(struct pfeng_hif_chnl *chnl);
diff --git a/sw/oal/src/oal_mm_linux.c b/sw/oal/src/oal_mm_linux.c
index 0a45362..81e6f8a 100644
--- a/sw/oal/src/oal_mm_linux.c
+++ b/sw/oal/src/oal_mm_linux.c
@@ -1,5 +1,5 @@
 /* =========================================================================
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -501,18 +501,18 @@ uint32_t oal_mm_cache_get_line_size(void)
 	return OAL_CACHE_ALLIGN; //oal_cache_context.cache_line_size;
 }
 
-#ifdef PFE_CFG_PFE_MASTER
-static int pfeng_reserved_no_map_region_init(struct device *dev, struct reserved_mem **rmem_out, int rmem_id, int *rmem_idx)
+static int pfeng_reserved_bdr_pool_region_init(struct device *dev, struct gen_pool **pool_alloc, int rmem_idx)
 {
 	struct device_node *mem_node;
 	struct reserved_mem *rmem;
-	void __iomem *base_va;
-	char compatible[32];
+	struct gen_pool *p;
+	void *base;
 	int idx;
+	int ret;
 
-	idx = of_property_match_string(dev->of_node, "memory-region-names", pfeng_res_no_map_name[rmem_id]);
+	idx = of_property_match_string(dev->of_node, "memory-region-names", "pfe-bdr-pool");
 	if (idx < 0)
-		idx = *rmem_idx;
+		idx = rmem_idx;
 
 	mem_node = of_parse_phandle(dev->of_node, "memory-region", idx);
 	if (!mem_node) {
@@ -520,59 +520,66 @@ static int pfeng_reserved_no_map_region_init(struct device *dev, struct reserved
 		goto out;
 	}
 
-	scnprintf(compatible, sizeof(compatible), "nxp,s32g-%s", pfeng_res_no_map_name[rmem_id]);
-	if (!of_device_is_compatible(mem_node, compatible)) {
+	if (!of_device_is_compatible(mem_node, "nxp,s32g-pfe-bdr-pool")) {
 		/* don't fail probing if node not found */
-		dev_warn(dev, "memory-region: %s node missing\n", compatible);
+		dev_warn(dev, "nxp,s32g-pfe-bdr-pool node missing\n");
 		goto out;
 	}
 
 	rmem = of_reserved_mem_lookup(mem_node);
 	if (!rmem) {
 		dev_err(dev, "of_reserved_mem_lookup() returned NULL\n");
-		/* advance rmem iterator */
-		*rmem_idx = idx + 1;
 		goto out;
 	}
 
 	of_node_put(mem_node);
 
-	base_va = devm_ioremap_wc(dev, rmem->base, rmem->size);
-	if (!base_va) {
-		dev_err(dev, "%s mapping failed\n", pfeng_res_no_map_name[rmem_id]);
+	base = devm_memremap(dev, rmem->base, rmem->size, MEMREMAP_WB);
+	if (!base) {
+		dev_err(dev, "PFE BDR pool map failed\n");
 		return -EINVAL;
 	}
 
-	memset_io(base_va, 0, rmem->size);
+	p = devm_gen_pool_create(dev, L1_CACHE_SHIFT, -1, "pfe-bdr-pool");
+	if (!p) {
+		dev_err(dev, "gen pool create failed\n");
+		memunmap(base);
+		return -EINVAL;
+	}
 
-	rmem->priv = base_va;
-	*rmem_out = rmem;
-	/* advance rmem iterator */
-	*rmem_idx = idx + 1;
+	ret = gen_pool_add(p, (unsigned long)base, rmem->size, -1);
+	if (ret) {
+		dev_err(dev, "gen pool add failed\n");
+		memunmap(base);
+		gen_pool_destroy(p);
+		return ret;
+	}
+
+	*pool_alloc = p;
 
 	dev_info(dev, "assigned reserved memory node %s\n", rmem->name);
 
 	return 0;
 
 out:
-	dev_warn(dev, "fall back to default pool allocation\n");
+	dev_warn(dev, "allocate BDRs in non-cacheable memory\n");
 	of_node_put(mem_node);
 
 	return 0;
 }
 
-static int pfeng_reserved_bdr_pool_region_init(struct device *dev, struct gen_pool **pool_alloc, int rmem_idx)
+#ifdef PFE_CFG_PFE_MASTER
+static int pfeng_reserved_no_map_region_init(struct device *dev, struct reserved_mem **rmem_out, int rmem_id, int *rmem_idx)
 {
 	struct device_node *mem_node;
 	struct reserved_mem *rmem;
-	struct gen_pool *p;
-	void *base;
+	void __iomem *base_va;
+	char compatible[32];
 	int idx;
-	int ret;
 
-	idx = of_property_match_string(dev->of_node, "memory-region-names", "pfe-bdr-pool");
+	idx = of_property_match_string(dev->of_node, "memory-region-names", pfeng_res_no_map_name[rmem_id]);
 	if (idx < 0)
-		idx = rmem_idx;
+		idx = *rmem_idx;
 
 	mem_node = of_parse_phandle(dev->of_node, "memory-region", idx);
 	if (!mem_node) {
@@ -580,49 +587,42 @@ static int pfeng_reserved_bdr_pool_region_init(struct device *dev, struct gen_po
 		goto out;
 	}
 
-	if (!of_device_is_compatible(mem_node, "nxp,s32g-pfe-bdr-pool")) {
+	scnprintf(compatible, sizeof(compatible), "nxp,s32g-%s", pfeng_res_no_map_name[rmem_id]);
+	if (!of_device_is_compatible(mem_node, compatible)) {
 		/* don't fail probing if node not found */
-		dev_warn(dev, "nxp,s32g-pfe-bdr-pool node missing\n");
+		dev_warn(dev, "memory-region: %s node missing\n", compatible);
 		goto out;
 	}
 
 	rmem = of_reserved_mem_lookup(mem_node);
 	if (!rmem) {
 		dev_err(dev, "of_reserved_mem_lookup() returned NULL\n");
+		/* advance rmem iterator */
+		*rmem_idx = idx + 1;
 		goto out;
 	}
 
 	of_node_put(mem_node);
 
-	base = devm_memremap(dev, rmem->base, rmem->size, MEMREMAP_WB);
-	if (!base) {
-		dev_err(dev, "PFE BDR pool map failed\n");
-		return -EINVAL;
-	}
-
-	p = devm_gen_pool_create(dev, L1_CACHE_SHIFT, -1, "pfe-bdr-pool");
-	if (!p) {
-		dev_err(dev, "gen pool create failed\n");
-		memunmap(base);
+	base_va = devm_ioremap_wc(dev, rmem->base, rmem->size);
+	if (!base_va) {
+		dev_err(dev, "%s mapping failed\n", pfeng_res_no_map_name[rmem_id]);
 		return -EINVAL;
 	}
 
-	ret = gen_pool_add(p, (unsigned long)base, rmem->size, -1);
-	if (ret) {
-		dev_err(dev, "gen pool add failed\n");
-		memunmap(base);
-		gen_pool_destroy(p);
-		return ret;
-	}
+	memset_io(base_va, 0, rmem->size);
 
-	*pool_alloc = p;
+	rmem->priv = base_va;
+	*rmem_out = rmem;
+	/* advance rmem iterator */
+	*rmem_idx = idx + 1;
 
 	dev_info(dev, "assigned reserved memory node %s\n", rmem->name);
 
 	return 0;
 
 out:
-	dev_warn(dev, "allocate BDRs in non-cacheable memory\n");
+	dev_warn(dev, "fall back to default pool allocation\n");
 	of_node_put(mem_node);
 
 	return 0;
@@ -647,14 +647,41 @@ static int pfeng_reserved_dma_shared_pool_region_init(struct device *dev, int *r
 	return 0;
 }
 
-static errno_t __oal_mm_init_master(struct device *dev)
+int __oal_mm_wakeup_reinit(void)
+{
+	struct pfe_reserved_mem *res_mem = NULL;
+
+	if (list_empty(&pfe_reserved_mem_list))
+		return 0;
+
+	list_for_each_entry(res_mem, &pfe_reserved_mem_list, node) {
+		/* PFE_CFG_RT_MEM and PFE_CFG_SYS_MEM regions could be mapped to SRAM
+		 * Reinit is required when returning from SUSPEND mode
+		 */
+		if (!strcmp(res_mem->name, PFE_CFG_SYS_MEM) || !strcmp(res_mem->name, PFE_CFG_RT_MEM)) {
+			NXP_LOG_DEBUG("Reserved memory re-inited: %s\n", res_mem->name);
+			memset_io(res_mem->map_start_va, 0, res_mem->map_size);
+		}
+	}
+
+	return 0;
+}
+
+#else
+#define __oal_mm_wakeup_reinit() 0
+#endif /* PFE_CFG_PFE_MASTER */
+
+static errno_t __oal_mm_init_regions(struct device *dev)
 {
 	struct pfe_reserved_mem *pfe_res_mem;
 	struct gen_pool *pool_alloc = NULL;
+#ifdef PFE_CFG_PFE_MASTER
 	struct reserved_mem *rmem[PFE_REG_COUNT] = {NULL, NULL};
 	int rmem_idx = 0, i;
+#endif /* PFE_CFG_PFE_MASTER */
 	int ret;
 
+#ifdef PFE_CFG_PFE_MASTER
 	/* BMU2 and RT regions are required by MASTER only */
 	for (i = 0; i < PFE_REG_COUNT; i++) {
 		ret = pfeng_reserved_no_map_region_init(dev, &rmem[i], i, &rmem_idx);
@@ -665,13 +692,15 @@ static errno_t __oal_mm_init_master(struct device *dev)
 		}
 	}
 
+
 	ret = pfeng_reserved_dma_shared_pool_region_init(dev, &rmem_idx);
 	if (ret) {
 		dev_err(dev, "shared-dma-pool reservation failed. Error %d\n", ret);
 		return ret;
 	}
+#endif /* PFE_CFG_PFE_MASTER */
 
-	ret = pfeng_reserved_bdr_pool_region_init(dev, &pool_alloc, rmem_idx);
+	ret = pfeng_reserved_bdr_pool_region_init(dev, &pool_alloc, 0); // only one reserved reg on slave!
 	if (ret) {
 		dev_err(dev, "BDR pool reservation failed. Error %d\n", ret);
 		goto err_bdr_pool_region_init;
@@ -690,6 +719,7 @@ static errno_t __oal_mm_init_master(struct device *dev)
 		list_add(&pfe_res_mem->node, &pfe_reserved_mem_list);
 	}
 
+#ifdef PFE_CFG_PFE_MASTER
 	for (i = 0; i < PFE_REG_COUNT; i++) {
 		if (!rmem[i])
 			continue;
@@ -707,6 +737,7 @@ static errno_t __oal_mm_init_master(struct device *dev)
 		INIT_LIST_HEAD(&pfe_res_mem->node);
 		list_add(&pfe_res_mem->node, &pfe_reserved_mem_list);
 	}
+#endif /* PFE_CFG_PFE_MASTER */
 
 	return 0;
 
@@ -717,40 +748,6 @@ err_alloc:
 	return ret;
 }
 
-static void __oal_mm_shutdown_master(struct device *dev)
-{
-	of_reserved_mem_device_release(dev);
-
-	/* reserved_mem list nodes will be released by devm_ */
-	INIT_LIST_HEAD(&pfe_reserved_mem_list);
-}
-
-int __oal_mm_wakeup_reinit(void)
-{
-	struct pfe_reserved_mem *res_mem = NULL;
-
-	if (list_empty(&pfe_reserved_mem_list))
-		return 0;
-
-	list_for_each_entry(res_mem, &pfe_reserved_mem_list, node) {
-		/* PFE_CFG_RT_MEM and PFE_CFG_SYS_MEM regions could be mapped to SRAM
-		 * Reinit is required when returning from SUSPEND mode
-		 */
-		if (!strcmp(res_mem->name, PFE_CFG_SYS_MEM) || !strcmp(res_mem->name, PFE_CFG_RT_MEM)) {
-			NXP_LOG_DEBUG("Reserved memory re-inited: %s\n", res_mem->name);
-			memset_io(res_mem->map_start_va, 0, res_mem->map_size);
-		}
-	}
-
-	return 0;
-}
-
-#else
-#define __oal_mm_init_master(dev) 0
-#define __oal_mm_shutdown_master(dev) NULL
-#define __oal_mm_wakeup_reinit() 0
-#endif /* PFE_CFG_PFE_MASTER */
-
 errno_t oal_mm_wakeup_reinit(void)
 {
 	return __oal_mm_wakeup_reinit();
@@ -761,7 +758,7 @@ errno_t oal_mm_init(const void *devh)
 	struct device *dev = (struct device *)devh;
 	int ret;
 
-	ret = __oal_mm_init_master(dev);
+	ret = __oal_mm_init_regions(dev);
 	if (ret)
 		return ret;
 
@@ -774,7 +771,10 @@ errno_t oal_mm_init(const void *devh)
 
 void oal_mm_shutdown(void)
 {
-	__oal_mm_shutdown_master(__dev);
+	of_reserved_mem_device_release(__dev);
+
+	/* reserved_mem list nodes will be released by devm_ */
+	INIT_LIST_HEAD(&pfe_reserved_mem_list);
 
 	if (!hash_empty(pfe_addr_htable)) {
 		dev_warn(__dev, "Unfreed memory detected\n");
diff --git a/sw/pfe_platform/hw/s32g/pfe_class_csr.c b/sw/pfe_platform/hw/s32g/pfe_class_csr.c
index b9abcab..7d0efe2 100644
--- a/sw/pfe_platform/hw/s32g/pfe_class_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_class_csr.c
@@ -367,6 +367,12 @@ uint32_t pfe_class_cfg_get_text_stat(addr_t base_va, struct seq_file *seq, uint8
 			reg = hal_read32(base_va + CLASS_PE7_DEBUG);
 			seq_printf(seq, "PE7 PC\t0x%x\n", reg & 0xffffU);
 
+			if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
+			{
+				seq_printf(seq, "Packets freed by HW: %u\n",
+					hal_read32(base_va + CLASS_PE_CUM_DROP_COUNT_ADDR));
+			}
+
 			/*	Get info per PHY */
 			seq_printf(seq, "[PHY1]\n");
 
diff --git a/sw/pfe_platform/hw/s32g/pfe_class_csr.h b/sw/pfe_platform/hw/s32g/pfe_class_csr.h
index 859a701..da576b4 100644
--- a/sw/pfe_platform/hw/s32g/pfe_class_csr.h
+++ b/sw/pfe_platform/hw/s32g/pfe_class_csr.h
@@ -280,6 +280,7 @@
 #define CLASS_DDR_BUF_SIZE				(CBUS_CLASS_CSR_BASE_ADDR + 0x508U)
 #define CLASS_AXI_CTRL_ADDR				(CBUS_CLASS_CSR_BASE_ADDR + 0x50cU)
 #define CLASS_PE_CONFIG					(CBUS_CLASS_CSR_BASE_ADDR + 0x510U)
+#define CLASS_PE_CUM_DROP_COUNT_ADDR	(CBUS_CLASS_CSR_BASE_ADDR + 0x514U)
 
 /* CLASS defines */
 #define CLASS_PBUF_SIZE				0x200UL
diff --git a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
index cb1d14d..9e12d94 100644
--- a/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
+++ b/sw/pfe_platform/hw/s32g/pfe_gpi_csr.c
@@ -135,6 +135,7 @@ void pfe_gpi_cfg_init(addr_t base_va, const pfe_gpi_cfg_t *cfg)
 		regval |= 0x3U;
 		hal_write32(regval, base_va + GPI_CSR_AXI_WRITE_DONE_ADDR);
 	}
+	hal_write32(0xFFFFFFFFU, base_va + CSR_IGQOS_LRU_TIMER_VALUE);
 }
 
 /**
diff --git a/sw/pfe_platform/public/pfe_hif_ring_linux.h b/sw/pfe_platform/public/pfe_hif_ring_linux.h
index 439cf92..98265e9 100644
--- a/sw/pfe_platform/public/pfe_hif_ring_linux.h
+++ b/sw/pfe_platform/public/pfe_hif_ring_linux.h
@@ -25,6 +25,7 @@ errno_t pfe_hif_ring_drain_buf(pfe_hif_ring_t *ring, void **buf_pa) __attribute_
 bool_t pfe_hif_ring_is_below_wm(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
 void pfe_hif_ring_invalidate(const pfe_hif_ring_t *ring) __attribute__((cold));
 uint32_t pfe_hif_ring_get_fill_level(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
+bool_t pfe_hif_ring_is_on_head(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
 
 uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *name, struct seq_file *seq, uint8_t verb_level);
 
diff --git a/sw/pfe_platform/public/pfe_phy_if.h b/sw/pfe_platform/public/pfe_phy_if.h
index 1e1344d..020f3c7 100644
--- a/sw/pfe_platform/public/pfe_phy_if.h
+++ b/sw/pfe_platform/public/pfe_phy_if.h
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -55,7 +55,7 @@ errno_t pfe_phy_if_bind_hif(pfe_phy_if_t *iface, pfe_hif_chnl_t *hif);
 pfe_hif_chnl_t *pfe_phy_if_get_hif(const pfe_phy_if_t *iface);
 errno_t pfe_phy_if_bind_util(pfe_phy_if_t *iface);
 pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *iface) __attribute__((pure));
-char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface) __attribute__((pure));
+const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface) __attribute__((pure));
 void pfe_phy_if_destroy(pfe_phy_if_t *iface);
 pfe_class_t *pfe_phy_if_get_class(const pfe_phy_if_t *iface) __attribute__((pure));
 errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t block_state);
diff --git a/sw/pfe_platform/public/pfe_rtable.h b/sw/pfe_platform/public/pfe_rtable.h
index b904a20..a2f8569 100644
--- a/sw/pfe_platform/public/pfe_rtable.h
+++ b/sw/pfe_platform/public/pfe_rtable.h
@@ -117,7 +117,7 @@ uint32_t pfe_rtable_get_size(const pfe_rtable_t *rtable);
 void pfe_rtable_entry_set_ttl_decrement(pfe_rtable_entry_t *entry);
 void pfe_rtable_entry_remove_ttl_decrement(pfe_rtable_entry_t *entry);
 pfe_rtable_entry_t *pfe_rtable_entry_create(void);
-void pfe_rtable_entry_free(pfe_rtable_entry_t *entry);
+void pfe_rtable_entry_free(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
 errno_t pfe_rtable_entry_set_5t(pfe_rtable_entry_t *entry, const pfe_5_tuple_t *tuple);
 errno_t pfe_rtable_entry_set_sip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *ip_addr);
 void pfe_rtable_entry_get_sip(pfe_rtable_entry_t *entry, pfe_ip_addr_t *ip_addr);
@@ -147,7 +147,8 @@ void pfe_rtable_entry_set_callback(pfe_rtable_entry_t *entry, pfe_rtable_callbac
 void pfe_rtable_entry_set_refptr(pfe_rtable_entry_t *entry, void *refptr);
 void *pfe_rtable_entry_get_refptr(pfe_rtable_entry_t *entry);
 void pfe_rtable_entry_set_child(pfe_rtable_entry_t *entry, pfe_rtable_entry_t *child);
-pfe_rtable_entry_t *pfe_rtable_entry_get_child(const pfe_rtable_entry_t *entry);
+pfe_rtable_entry_t *pfe_rtable_entry_get_child_nolock(const pfe_rtable_entry_t *entry);
+pfe_rtable_entry_t *pfe_rtable_entry_get_child(pfe_rtable_t *rtable, const pfe_rtable_entry_t *entry);
 uint8_t pfe_rtable_entry_get_stats_index(const pfe_rtable_entry_t *entry);
 
 void pfe_rtable_entry_set_id5t(pfe_rtable_entry_t *entry, uint32_t id5t);
diff --git a/sw/pfe_platform/src/pfe_hif_chnl_linux.c b/sw/pfe_platform/src/pfe_hif_chnl_linux.c
index cdc6847..3313d11 100644
--- a/sw/pfe_platform/src/pfe_hif_chnl_linux.c
+++ b/sw/pfe_platform/src/pfe_hif_chnl_linux.c
@@ -95,6 +95,8 @@
 
 #define DUMMY_TX_BUF_LEN		64U
 #define DUMMY_RX_BUF_LEN		2048U
+#define DUMMY_FRAME_INVALID		0
+#define DUMMY_FRAME_IHC_SELF	1
 
 #define BUFFERS_CACHED TRUE
 
@@ -132,7 +134,8 @@ struct __attribute__((aligned(HAL_CACHE_LINE_SIZE))) __pfe_hif_chnl_tag
 static errno_t pfe_hif_chnl_set_rx_ring(pfe_hif_chnl_t *chnl, pfe_hif_ring_t *ring) __attribute__((cold));
 static errno_t pfe_hif_chnl_set_tx_ring(pfe_hif_chnl_t *chnl, pfe_hif_ring_t *ring) __attribute__((cold));
 static errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl) __attribute__((cold));
-static errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_t *chnl) __attribute__((cold));
+static errno_t pfe_hif_chnl_reset_fifos(pfe_hif_chnl_t *chnl) __attribute__((cold));
+static errno_t pfe_hif_chnl_send_frame(pfe_hif_chnl_t *chnl, uint32_t mode) __attribute__((cold));
 
 #if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
 static void pfe_hif_chnl_refill_rx_buffers(const pfe_hif_chnl_t *chnl) __attribute__((hot));
@@ -1505,29 +1508,21 @@ __attribute__((hot)) bool_t pfe_hif_chnl_is_tx_dma_active(const pfe_hif_chnl_t *
 }
 
 /**
- * @brief		Flush RX BDP buffer
- * @details		When channel is stopped the fetched BDs are remaining in internal
- * 				buffer and don't get flushed once channel is re-enabled. This
- * 				causes memory corruption when channel driver is stopped and then
- * 				started with other BD rings because HIF is missing possibility
- * 				to reset particular channels separately without affecting the
- * 				other channels.
+ * @brief		Send TX frame
  * @param[in]	chnl The channel instance
+ * @param[in]	mode The frame content mode: DUMMY_FRAME_INVALID or DUMMY_FRAME_IHC_SELF
  * @return		EOK if success, error code otherwise
  */
-static __attribute__((cold)) errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_t *chnl)
+static __attribute__((cold)) errno_t pfe_hif_chnl_send_frame(pfe_hif_chnl_t *chnl, uint32_t mode)
 {
-	void *tx_buf_va = NULL, *rx_buf_va = NULL;
-	void *tx_buf_pa, *rx_buf_pa, *buf_pa;
+	void *tx_buf_va = NULL, *tx_buf_pa;
 	pfe_ct_hif_tx_hdr_t *tx_hdr;
-	uint32_t len, ii;
-	bool_t lifm;
 	errno_t ret = EOK;
 
 	tx_buf_va = oal_mm_malloc_contig_aligned_nocache(sizeof(pfe_ct_hif_tx_hdr_t)+DUMMY_TX_BUF_LEN, 8U);
 	if (NULL == tx_buf_va)
 	{
-		NXP_LOG_ERROR("Can't get dummy TX buffer\n");
+		NXP_LOG_ERROR("Can't get dummy TX dummy buffer\n");
 		ret = ENOMEM;
 		goto the_end;
 	}
@@ -1535,11 +1530,67 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_
 	tx_buf_pa = oal_mm_virt_to_phys_contig(tx_buf_va);
 	if (NULL == tx_buf_pa)
 	{
-		NXP_LOG_ERROR("VA to PA conversion failed");
+		NXP_LOG_ERROR("TX dummy buffer VA to PA conversion failed");
 		ret = ENOMEM;
 		goto the_end;
 	}
 
+	tx_hdr = (pfe_ct_hif_tx_hdr_t *)tx_buf_va;
+
+	switch (mode)
+	{
+		case DUMMY_FRAME_INVALID:
+			/* send invalid frame */
+			tx_hdr->e_phy_ifs = 0;
+			tx_hdr->flags = 0;
+			break;
+
+		case DUMMY_FRAME_IHC_SELF:
+			/* send IHC frame to self channel */
+			tx_hdr->e_phy_ifs = oal_htonl(1U << (PFE_PHY_IF_ID_HIF0 + chnl->id));
+			tx_hdr->flags = (pfe_ct_hif_tx_flags_t)(HIF_TX_INJECT|HIF_TX_IHC);
+			tx_hdr->chid = chnl->id;
+			break;
+
+		default:
+			break;
+	}
+
+	ret = pfe_hif_chnl_tx(chnl, tx_buf_pa, tx_buf_va, sizeof(pfe_ct_hif_tx_hdr_t)+DUMMY_TX_BUF_LEN, TRUE);
+	if (EOK != ret)
+	{
+		NXP_LOG_ERROR("Dummy frame TX failed\n");
+	}
+
+the_end:
+	if (NULL != tx_buf_va)
+	{
+		oal_mm_free_contig(tx_buf_va);
+		tx_buf_va = NULL;
+	}
+
+	return ret;
+}
+
+/**
+ * @brief		Reset HIF channel FIFOs
+ * @details		When HIF channel is stopped, the prefetched BDs remain active
+ * 				in internal buffers. To gracefuly stop the channel all residues
+ * 				have to be flushed and the rings (both RX and TX, including
+ * 				write-back rings) should be moved to the head of rings, as
+ * 				it is required by Slave driver on start-up. Not doing
+ * 				channel reset ends up in nonfunctional driver, because
+ * 				SW and HW rings are out of sync.
+ * @param[in]	chnl The channel instance
+ * @return		EOK if success, error code otherwise
+ */
+static __attribute__((cold)) errno_t pfe_hif_chnl_reset_fifos(pfe_hif_chnl_t *chnl)
+{
+	void *rx_buf_va = NULL, *rx_buf_pa, *buf_pa;
+	uint32_t len, ii;
+	bool_t lifm;
+	errno_t ret = EOK;
+
 	rx_buf_va = oal_mm_malloc_contig_aligned_nocache(DUMMY_RX_BUF_LEN, 8U);
 	if (NULL == rx_buf_va)
 	{
@@ -1556,13 +1607,6 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_
 		goto the_end;
 	}
 
-	tx_hdr = (pfe_ct_hif_tx_hdr_t *)tx_buf_va;
-
-	tx_hdr->e_phy_ifs = oal_htonl(1U << (PFE_PHY_IF_ID_HIF0 + chnl->id));
-
-	tx_hdr->flags = (pfe_ct_hif_tx_flags_t)(HIF_TX_INJECT|HIF_TX_IHC);
-	tx_hdr->chid = chnl->id;
-
 	/*	Activate the channel */
 	pfe_hif_chnl_rx_enable(chnl);
 	pfe_hif_chnl_tx_enable(chnl);
@@ -1581,12 +1625,58 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_
 			{
 				NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
 			}
+			pfe_hif_chnl_rx_dma_start(chnl);
 		}
 
 		/*	Send dummy packet to self HIF channel */
-		if (EOK != pfe_hif_chnl_tx(chnl, tx_buf_pa, tx_buf_va, sizeof(pfe_ct_hif_tx_hdr_t)+DUMMY_TX_BUF_LEN, TRUE))
+		ret = pfe_hif_chnl_send_frame(chnl, DUMMY_FRAME_IHC_SELF);
+		if (EOK != ret)
+			goto the_end;
+
+		/*	Wait */
+		oal_time_usleep(500U);
+
+		/*	Do TX confirmations */
+		while (EOK == pfe_hif_chnl_get_tx_conf(chnl))
+		{
+			;
+		}
+
+		/*	Do plain RX */
+		while (EOK == pfe_hif_ring_dequeue_buf(chnl->rx_ring, &buf_pa, &len, &lifm))
+		{
+			;
+		}
+
+		/*	Decrement timeout counter */
+		if (ii > 0U)
+		{
+			ii--;
+		}
+		else
 		{
-			NXP_LOG_ERROR("Dummy frame TX failed\n");
+			NXP_LOG_ERROR("RX BD ring flush timed-out\n");
+			ret = ETIMEDOUT;
+			goto the_end;
+		}
+	}
+
+	/* RX ring reset to the head */
+	ii = pfe_hif_ring_get_len(chnl->rx_ring) - 1;
+	while (FALSE == pfe_hif_ring_is_on_head(chnl->rx_ring))
+	{
+		/*	Provide single RX buffer */
+		if (EOK != pfe_hif_chnl_supply_rx_buf(chnl, rx_buf_pa, DUMMY_RX_BUF_LEN))
+		{
+			NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
+		}
+		pfe_hif_chnl_rx_dma_start(chnl);
+
+		/*	Send dummy packet to self HIF channel */
+		ret = pfe_hif_chnl_send_frame(chnl, DUMMY_FRAME_IHC_SELF);
+		if (EOK != ret) {
+			NXP_LOG_ERROR("Can't send frame\n");
+			goto the_end;
 		}
 
 		/*	Wait */
@@ -1611,25 +1701,46 @@ static __attribute__((cold)) errno_t pfe_hif_chnl_flush_rx_bd_fifo(pfe_hif_chnl_
 		}
 		else
 		{
-			NXP_LOG_ERROR("RX BD ring flush timed-out\n");
+			NXP_LOG_ERROR("RX jump to head timed-out\n");
 			ret = ETIMEDOUT;
 			goto the_end;
 		}
+
+	}
+
+	/* TX ring reset to the head */
+	ii = pfe_hif_ring_get_len(chnl->tx_ring) - 1;
+	while (FALSE == pfe_hif_ring_is_on_head(chnl->tx_ring))
+	{
+		/*	Send invalid packet (to be dropped on Class) */
+		ret = pfe_hif_chnl_send_frame(chnl, DUMMY_FRAME_INVALID);
+		if (EOK != ret) {
+			NXP_LOG_ERROR("Can't send frame\n");
+			goto the_end;
+		}
+
+		/*	Wait */
+		oal_time_usleep(500U);
+
+		/*	Do TX confirmations */
+		while (EOK == pfe_hif_chnl_get_tx_conf(chnl))
+		{
+			;
+		}
 	}
 
 the_end:
+
+	/*	Stop the channel */
+	pfe_hif_chnl_rx_disable(chnl);
+	pfe_hif_chnl_tx_disable(chnl);
+
 	/*	Drain all in case when flush process has somehow failed */
 	while (EOK == pfe_hif_ring_drain_buf(chnl->rx_ring, &buf_pa))
 	{
 		;
 	}
 
-	if (NULL != tx_buf_va)
-	{
-		oal_mm_free_contig(tx_buf_va);
-		tx_buf_va = NULL;
-	}
-
 	if (NULL != rx_buf_va)
 	{
 		oal_mm_free_contig(rx_buf_va);
@@ -1708,15 +1819,12 @@ __attribute__((cold)) void pfe_hif_chnl_destroy(pfe_hif_chnl_t *chnl)
 
 #endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */
 
-			/*	Invalidate the RX ring */
-			pfe_hif_ring_invalidate(chnl->rx_ring);
-
 			/*
 				Here the ring should be empty. Execute HIF channel BDP shutdown
 				procedure to ensure that channel will not keep any content in
-				internal buffers.
+				internal buffers and HW rings are on head.
 			*/
-			if (EOK != pfe_hif_chnl_flush_rx_bd_fifo(chnl))
+			if (EOK != pfe_hif_chnl_reset_fifos(chnl))
 			{
 				NXP_LOG_ERROR("FATAL: Could not flush RX BD FIFO\n");
 			}
diff --git a/sw/pfe_platform/src/pfe_hif_ring_linux.c b/sw/pfe_platform/src/pfe_hif_ring_linux.c
index 1ef33da..37fa987 100644
--- a/sw/pfe_platform/src/pfe_hif_ring_linux.c
+++ b/sw/pfe_platform/src/pfe_hif_ring_linux.c
@@ -189,23 +189,23 @@ __attribute__((cold)) static void pfe_hif_ring_invalidate_std(const pfe_hif_ring
 
 __attribute__((hot)) static inline void inc_write_index_std(pfe_hif_ring_t *ring)
 {
-	ring->write_idx++;
-	ring->wr_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->write_idx & RING_LEN_MASK];
-	ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->write_idx & RING_LEN_MASK];
+	ring->write_idx = (ring->write_idx + 1) & RING_LEN_MASK;
+	ring->wr_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->write_idx];
+	ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->write_idx];
 }
 
 __attribute__((hot)) static inline void dec_write_index_std(pfe_hif_ring_t *ring)
 {
-	ring->write_idx--;
-	ring->wr_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->write_idx & RING_LEN_MASK];
-	ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->write_idx & RING_LEN_MASK];
+	ring->write_idx = (ring->write_idx - 1) & RING_LEN_MASK;
+	ring->wr_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->write_idx];
+	ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->write_idx];
 }
 
 __attribute__((hot)) static inline void inc_read_index_std(pfe_hif_ring_t *ring)
 {
-	ring->read_idx++;
-	ring->rd_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->read_idx & RING_LEN_MASK];
-	ring->rd_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->read_idx & RING_LEN_MASK];
+	ring->read_idx = (ring->read_idx + 1) & RING_LEN_MASK;
+	ring->rd_bd = &((pfe_hif_bd_t *)ring->base_va)[ring->read_idx];
+	ring->rd_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->read_idx];
 }
 
 /**
@@ -279,6 +279,25 @@ __attribute__((pure, cold)) uint32_t pfe_hif_ring_get_wb_tbl_len(const pfe_hif_r
 	return RING_LEN;
 }
 
+/**
+ * @brief		Check if the ring is on the head
+ * @param[in]	ring The ring instance
+ * @return		TRUE if the ring is on the head
+ * @note		Must not be preempted by: pfe_hif_ring_destroy()
+ */
+__attribute__((pure, hot)) bool_t pfe_hif_ring_is_on_head(const pfe_hif_ring_t *ring)
+{
+#if defined(PFE_CFG_NULL_ARG_CHECK)
+	if (unlikely(NULL == ring))
+	{
+		NXP_LOG_ERROR("NULL argument received\n");
+		return FALSE;
+	}
+#endif /* PFE_CFG_NULL_ARG_CHECK */
+
+	return ring->rd_wb_bd == ring->wb_tbl_base_va;
+}
+
 /**
  * @brief		Get length of the ring
  * @param[in]	ring The ring instance
@@ -685,6 +704,7 @@ __attribute__((cold)) uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *n
 	uint32_t ii;
 	uint32_t len = 0U;
 	char_t *idx_str;
+	bool_t pr_out;
 
 #if defined(PFE_CFG_NULL_ARG_CHECK)
 	if (unlikely((NULL == ring) || (NULL == name)))
@@ -702,28 +722,43 @@ __attribute__((cold)) uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *n
 		/* BD ring */
 		for (ii=0U; ii<RING_LEN; ii++)
 		{
-
 			pfe_hif_bd_t *bd = &(((pfe_hif_bd_t *)ring->base_va)[ii]);
+
+			pr_out = FALSE;
+
 			if (0 == ii)
 			{
 				seq_printf(seq, "  BD va/pa v0x%px/p0x%px\n", ring->base_va, ring->base_pa);
-				seq_printf(seq, "            pa           idx: bufl:ctrl: status :  data  :  next  :seqn\n");
+				seq_printf(seq, "            pa           idx: bufl:ctrl:  data  :  next  :seqn\n");
+				pr_out = TRUE;
 			}
 
 			if ((ring->write_idx & RING_LEN_MASK) == ii)
 			{
 				idx_str = "<-- WR";
+				pr_out = TRUE;
 			}
 			else if ((ring->read_idx & RING_LEN_MASK) == ii)
 			{
 				idx_str = "<-- RD";
+				pr_out = TRUE;
 			}
 			else
 			{
 				idx_str = "";
 			}
 
-			seq_printf(seq, "    p0x%px%5d: %04x:%04x:%08x:%08x:%04x%s\n",(void *)&((pfe_hif_bd_t *)ring->base_pa)[ii], ii, HIF_RING_BD_W1_BD_BUFFLEN_GET(bd->rsvd_buflen_w1), HIF_RING_BD_W0_BD_CTRL_GET(bd->ctrl_seqnum_w0), bd->data, bd->next, HIF_RING_BD_W0_BD_SEQNUM_GET(bd->ctrl_seqnum_w0), idx_str);
+			if ((ii == 1) || (ii >= (RING_LEN - 2)) ||
+				((ii > 1) && (((ring->read_idx & RING_LEN_MASK) - 1) == ii)) ||
+				((ii < (RING_LEN - 2)) && (((ring->read_idx & RING_LEN_MASK) + 1) == ii)))
+			{
+				pr_out = TRUE;
+			}
+
+			if (TRUE == pr_out)
+			{
+				seq_printf(seq, "    p0x%px%5d: %04x:%04x:%08x:%08x:%04x%s\n",(void *)&((pfe_hif_bd_t *)ring->base_pa)[ii], ii, HIF_RING_BD_W1_BD_BUFFLEN_GET(bd->rsvd_buflen_w1), HIF_RING_BD_W0_BD_CTRL_GET(bd->ctrl_seqnum_w0), bd->data, bd->next, HIF_RING_BD_W0_BD_SEQNUM_GET(bd->ctrl_seqnum_w0), idx_str);
+			}
 		}
 
 		/* WB ring */
@@ -731,22 +766,37 @@ __attribute__((cold)) uint32_t pfe_hif_ring_dump(pfe_hif_ring_t *ring, char_t *n
 			for (ii=0U; ii<RING_LEN; ii++)
 			{
 				pfe_hif_wb_bd_t *wb = &(((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ii]);
+
+				pr_out = FALSE;
+
 				if (0 == ii)
 				{
 					seq_printf(seq, "  WB va/pa v0x%px/p0x%px\n", ring->wb_tbl_base_va, ring->wb_tbl_base_pa);
-					seq_printf(seq, "            pa           idx:  ctl: rsvd :bufl:seqn\n");
+					seq_printf(seq, "            pa           idx:   ctl  : bufl :  seq\n");
+					pr_out = TRUE;
 				}
 
 				if ((ring->read_idx & RING_LEN_MASK) == ii)
 				{
 					idx_str = "<-- RD";
+					pr_out = TRUE;
 				}
 				else
 				{
 					idx_str = "";
 				}
 
-				seq_printf(seq, "    p0x%px%5d: %04x:%06x:%04x:%s\n", (void *)&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_pa)[ii], ii, HIF_RING_BD_W0_BD_CTRL(wb->rsvd_ctrl_w0), HIF_RING_WB_BD_W1_WB_BD_BUFFLEN(wb->seqnum_buflen_w1), HIF_RING_WB_BD_W1_WB_BD_SEQNUM(wb->seqnum_buflen_w1), idx_str);
+				if ((ii == 1) || (ii >= (RING_LEN - 2)) ||
+					((ii > 1) && (((ring->read_idx & RING_LEN_MASK) - 1) == ii)) ||
+					((ii < (RING_LEN - 2)) && (((ring->read_idx & RING_LEN_MASK) + 1) == ii)))
+				{
+					pr_out = TRUE;
+				}
+
+				if (TRUE == pr_out)
+				{
+					seq_printf(seq, "    p0x%px%5d: %04x:%06x:%04x:%s\n", (void *)&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_pa)[ii], ii, HIF_RING_BD_W0_BD_CTRL(wb->rsvd_ctrl_w0), HIF_RING_WB_BD_W1_WB_BD_BUFFLEN(wb->seqnum_buflen_w1), HIF_RING_WB_BD_W1_WB_BD_SEQNUM(wb->seqnum_buflen_w1), idx_str);
+				}
 			}
 		}
 	}
diff --git a/sw/pfe_platform/src/pfe_hm.c b/sw/pfe_platform/src/pfe_hm.c
index d94e072..2928f03 100644
--- a/sw/pfe_platform/src/pfe_hm.c
+++ b/sw/pfe_platform/src/pfe_hm.c
@@ -73,7 +73,7 @@ static const hm_string_t hm_evt_strings[] = {
 	{HM_EVT_EMAC_FSM_TX_TIMEOUT, "Tx FSM timeout error"},
 	{HM_EVT_EMAC_FSM_RX_TIMEOUT, "Rx FSM timeout error"},
 	{HM_EVT_EMAC_FSM_APP_TIMEOUT, "APP FSM timeout error"},
-	{HM_EVT_EMAC_FSM_APP_TIMEOUT, "PTP FSM timeout error"},
+	{HM_EVT_EMAC_FSM_PTP_TIMEOUT, "PTP FSM timeout error"},
 
 	{HM_EVT_BUS_MASTER1, "Master1 bus read error"},
 	{HM_EVT_BUS_MASTER2, "Master2 bus write error"},
diff --git a/sw/pfe_platform/src/pfe_log_if.c b/sw/pfe_platform/src/pfe_log_if.c
index 2fd7b47..7039ab5 100644
--- a/sw/pfe_platform/src/pfe_log_if.c
+++ b/sw/pfe_platform/src/pfe_log_if.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -32,41 +32,13 @@ struct pfe_log_if_tag
 	oal_mutex_t lock;
 };
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_START_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 /**
  * @brief	Pool of logical interface IDs. Module-local singleton.
  */
 static blalloc_t *pfe_log_if_id_pool = NULL;
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-
-#define ETH_43_PFE_START_SEC_CONST_32
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
-/* usage scope: pfe_log_if_get_name */
-static const char_t * const pfe_log_if_get_name_unknown = "(unknown)";
-
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CONST_32
-#include "Eth_43_PFE_MemMap.h"
-
-#define ETH_43_PFE_START_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 static errno_t pfe_log_if_read_from_class(const pfe_log_if_t *iface, pfe_ct_log_if_t *class_if, uint32_t pe_idx);
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 static errno_t pfe_log_if_write_to_class_nostats(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if);
 static errno_t pfe_log_if_write_to_class(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if);
 static errno_t pfe_log_if_match_rule1(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32_t arg_len);
@@ -342,8 +314,6 @@ static errno_t pfe_log_if_match_rule2(pfe_log_if_t *iface, pfe_ct_if_m_rules_t r
 	return ret;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Read interface structure from classifier memory
  * @param[in]	iface The interface instance
@@ -375,8 +345,6 @@ static errno_t pfe_log_if_read_from_class(const pfe_log_if_t *iface, pfe_ct_log_
 	return ret;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 /**
  * @brief		Write interface structure to classifier memory skipping interface statistics
  * @param[in]	iface The interface instance
@@ -2286,23 +2254,22 @@ __attribute__((pure)) bool_t pfe_log_if_is_discard(pfe_log_if_t *iface)
 /**
  * @brief		Get interface name
  * @param[in]	iface The interface instance
- * @return		Pointer to name string or NULL if failed/not found
+ * @return		Pointer to name string or "(unknown)" when called with NULL
  */
 __attribute__((pure)) const char_t *pfe_log_if_get_name(const pfe_log_if_t *iface)
 {
 	const char_t *str;
 
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == iface))
+	if (NULL != iface)
 	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		str = NULL;
+		str = iface->name;
 	}
 	else
-#endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-		str = ((NULL != iface) ? iface->name : pfe_log_if_get_name_unknown);
+		NXP_LOG_WARNING("NULL argument received for pfe_log_if_get_name\n");
+		str = "(unknown)";
 	}
+
 	return str;
 }
 
@@ -2371,8 +2338,6 @@ errno_t pfe_log_if_get_stats(const pfe_log_if_t *iface, pfe_ct_class_algo_stats_
 	return ret;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Return logical interface runtime statistics in text form
  * @details		Function writes formatted text into given buffer.
@@ -2429,12 +2394,5 @@ uint32_t pfe_log_if_get_text_statistics(const pfe_log_if_t *iface, char_t *buf,
 	return len;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 #endif /* ! PFE_CFG_PFE_SLAVE */
 
diff --git a/sw/pfe_platform/src/pfe_log_if_slave.c b/sw/pfe_platform/src/pfe_log_if_slave.c
index 4e61d87..c72e825 100644
--- a/sw/pfe_platform/src/pfe_log_if_slave.c
+++ b/sw/pfe_platform/src/pfe_log_if_slave.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -39,22 +39,6 @@ struct pfe_log_if_tag
 	oal_mutex_t lock;
 };
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_START_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
-/* usage scope: pfe_log_if_get_name */
-static const char_t *pfe_log_if_get_name_unknown = "(unknown)";
-
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-
-#define ETH_43_PFE_START_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 static errno_t pfe_log_if_db_lock(void)
 {
 	errno_t ret;
@@ -223,24 +207,20 @@ void pfe_log_if_destroy(pfe_log_if_t *iface)
 		}
 		else
 		{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 			if (EOK != oal_mutex_lock(&iface->lock))
 			{
 				NXP_LOG_ERROR("mutex lock failed\n");
 			}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 			/*	Destroy local MAC database */
 			ret = pfe_mac_db_destroy(iface->mac_db);
 			if (EOK != ret)
 			{
 				NXP_LOG_ERROR("unable to destroy MAC database: %d\n", ret);
 			}
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 			if (EOK != oal_mutex_unlock(&iface->lock))
 			{
 				NXP_LOG_ERROR("mutex unlock failed\n");
 			}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 		}
 
 		if (NULL != iface->name)
@@ -593,12 +573,10 @@ errno_t pfe_log_if_add_mac_addr(pfe_log_if_t *iface, const pfe_mac_addr_t addr,
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_lock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex lock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	(void)pfe_log_if_db_lock();
 
@@ -624,12 +602,10 @@ errno_t pfe_log_if_add_mac_addr(pfe_log_if_t *iface, const pfe_mac_addr_t addr,
 	}
 
 	(void)pfe_log_if_db_unlock();
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex unlock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	return ret;
 }
 
@@ -657,12 +633,10 @@ errno_t pfe_log_if_del_mac_addr(pfe_log_if_t *iface, const pfe_mac_addr_t addr,
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_lock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex lock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	(void)pfe_log_if_db_lock();
 
@@ -691,12 +665,10 @@ errno_t pfe_log_if_del_mac_addr(pfe_log_if_t *iface, const pfe_mac_addr_t addr,
 	}
 
 	(void)pfe_log_if_db_unlock();
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex unlock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	return ret;
 }
 
@@ -737,12 +709,10 @@ errno_t pfe_log_if_get_mac_addr(pfe_log_if_t *iface, pfe_mac_addr_t addr)
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_lock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex lock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	ret = pfe_mac_db_get_first_addr(iface->mac_db, MAC_DB_CRIT_ALL, PFE_TYPE_ANY, PFE_CFG_LOCAL_IF, addr);
 	if(EOK != ret)
@@ -750,12 +720,10 @@ errno_t pfe_log_if_get_mac_addr(pfe_log_if_t *iface, pfe_mac_addr_t addr)
 		NXP_LOG_ERROR("unable to get MAC address: %d\n", ret);
 	}
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex unlock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	return ret;
 }
@@ -784,12 +752,10 @@ errno_t pfe_log_if_flush_mac_addrs(pfe_log_if_t *iface, pfe_mac_db_crit_t crit,
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_lock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex lock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	/*	Pass parameters */
 	req.log_if_id = iface->id;
@@ -815,12 +781,10 @@ errno_t pfe_log_if_flush_mac_addrs(pfe_log_if_t *iface, pfe_mac_db_crit_t crit,
 	}
 
 	(void)pfe_log_if_db_unlock();
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex unlock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	return ret;
 }
 
@@ -1508,19 +1472,23 @@ errno_t pfe_log_if_allmulti_disable(const pfe_log_if_t *iface)
 /**
  * @brief		Get interface name
  * @param[in]	iface The interface instance
- * @return		Pointer to name string or NULL if failed/not found
+ * @return		Pointer to name string or "(unknown)" when called with NULL
  */
 __attribute__((pure)) const char_t *pfe_log_if_get_name(const pfe_log_if_t *iface)
 {
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == iface))
+	const char_t *str;
+
+	if (NULL != iface)
 	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		return NULL;
+		str = iface->name;
+	}
+	else
+	{
+		NXP_LOG_WARNING("NULL argument received for pfe_log_if_get_name\n");
+		str = "(unknown)";
 	}
-#endif /* PFE_CFG_NULL_ARG_CHECK */
 
-    return ((NULL != iface)? iface->name : pfe_log_if_get_name_unknown);
+	return str;
 }
 
 /**
@@ -1563,8 +1531,6 @@ errno_t pfe_log_if_get_stats(const pfe_log_if_t *iface, pfe_ct_class_algo_stats_
 	return ret;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Return logical interface runtime statistics in text form
  * @details		Function writes formatted text into given buffer.
@@ -1595,12 +1561,5 @@ uint32_t pfe_log_if_get_text_statistics(const pfe_log_if_t *iface, char_t *buf,
 	return len;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 #endif /* PFE_CFG_PFE_SLAVE */
 
diff --git a/sw/pfe_platform/src/pfe_phy_if.c b/sw/pfe_platform/src/pfe_phy_if.c
index b3f9d0f..17ef5a5 100644
--- a/sw/pfe_platform/src/pfe_phy_if.c
+++ b/sw/pfe_platform/src/pfe_phy_if.c
@@ -55,22 +55,9 @@ typedef struct
 	LLIST_t iterator;
 } pfe_phy_if_list_entry_t;
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 /* usage scope: pfe_phy_if_flush_mac_addrs */
 static const pfe_emac_crit_t crit_remap_table[4] = {EMAC_CRIT_BY_TYPE, EMAC_CRIT_BY_OWNER, EMAC_CRIT_BY_OWNER_AND_TYPE, EMAC_CRIT_ALL};
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
-#include "Eth_43_PFE_MemMap.h"
-
-#define ETH_43_PFE_START_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 static errno_t pfe_phy_if_write_to_class_nostats(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if);
 static errno_t pfe_phy_if_write_to_class(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if);
 static bool_t pfe_phy_if_has_log_if_nolock(const pfe_phy_if_t *iface, const pfe_log_if_t *log_if);
@@ -83,12 +70,8 @@ static pfe_ct_if_flags_t pfe_phy_if_get_flag_nolock(const pfe_phy_if_t *iface, p
 static errno_t pfe_phy_if_enable_hw_block(const pfe_phy_if_t *iface);
 static void pfe_phy_if_update_op_mode_nolock(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode);
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 static uint32_t pfe_phy_if_stat_to_str(const pfe_ct_phy_if_stats_t *stat, char *buf, uint32_t buf_len, uint8_t verb_level);
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 /**
  * @brief		Write interface structure to classifier memory skipping interface statistics
  * @param[in]	iface The interface instance
@@ -143,8 +126,6 @@ static errno_t pfe_phy_if_write_to_class(const pfe_phy_if_t *iface, const pfe_ct
 	return ret;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Converts statistics of a physical interface or classification algorithm into a text form
  * @param[in]	stat		Statistics to convert
@@ -176,8 +157,6 @@ static uint32_t pfe_phy_if_stat_to_str(const pfe_ct_phy_if_stats_t *stat, char *
 	return len;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 /**
  * @brief		Create new physical interface instance
  * @param[in]	class The classifier instance
@@ -3360,28 +3339,25 @@ __attribute__((pure)) pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *i
 /**
  * @brief		Get name
  * @param[in]	iface The interface instance
- * @return		Pointer to interface name string or NULL if not found/failed
+ * @return		Pointer to interface name string or "(unknown)" when called with NULL
  */
-__attribute__((pure)) char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
+__attribute__((pure)) const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
 {
-	char_t *str;
+	const char_t *str;
 
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == iface))
+	if (NULL != iface)
 	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		str = NULL;
+		str = iface->name;
 	}
 	else
-#endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-		str = iface->name;
+		NXP_LOG_WARNING("NULL argument received for pfe_phy_if_get_name\n");
+		str = "(unknown)";
 	}
+
 	return str;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Return physical interface runtime statistics in text form
  * @details		Function writes formatted text into given buffer.
@@ -3431,8 +3407,6 @@ uint32_t pfe_phy_if_get_text_statistics(const pfe_phy_if_t *iface, char_t *buf,
 	return len;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 /**
  * @brief		Get statistic values in numeric form
  * @details		This function providing single statistic value
@@ -3488,10 +3462,5 @@ uint32_t pfe_phy_if_get_stat_value(pfe_phy_if_t *iface, uint32_t stat_id)
 	return ret;
 }
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 #endif /* ! PFE_CFG_PFE_SLAVE */
 
diff --git a/sw/pfe_platform/src/pfe_phy_if_slave.c b/sw/pfe_platform/src/pfe_phy_if_slave.c
index 37411fa..5fbba2f 100644
--- a/sw/pfe_platform/src/pfe_phy_if_slave.c
+++ b/sw/pfe_platform/src/pfe_phy_if_slave.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2018-2022 NXP
+ *  Copyright 2018-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -38,22 +38,6 @@ struct pfe_phy_if_tag
 	bool_t is_enabled;
 };
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_START_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
-/* usage scope: pfe_phy_if_get_name */
-static char_t *pfe_phy_if_get_name_unknown = "(unknown)";
-
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
-#include "Eth_43_PFE_MemMap.h"
-
-#define ETH_43_PFE_START_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 static bool_t pfe_phy_if_has_log_if_nolock(const pfe_phy_if_t *iface, const pfe_log_if_t *log_if);
 
 static errno_t pfe_phy_if_db_lock(void)
@@ -172,12 +156,10 @@ void pfe_phy_if_destroy(pfe_phy_if_t *iface)
 
 	if (NULL != iface)
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		/*	Ask the master driver to remove all associated MAC addresses */
 		arg.phy_if_id = iface->id;
@@ -196,12 +178,10 @@ void pfe_phy_if_destroy(pfe_phy_if_t *iface)
 			NXP_LOG_ERROR("Unable to destroy MAC database: %d\n", ret);
 		}
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		if (NULL != iface->name)
 		{
@@ -339,21 +319,17 @@ bool_t pfe_phy_if_has_log_if(pfe_phy_if_t *iface, const pfe_log_if_t *log_if)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		match = pfe_phy_if_has_log_if_nolock(iface, log_if);
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return match;
@@ -413,12 +389,10 @@ pfe_ct_if_op_mode_t pfe_phy_if_get_op_mode(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -437,12 +411,10 @@ pfe_ct_if_op_mode_t pfe_phy_if_get_op_mode(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return mode;
@@ -470,12 +442,10 @@ errno_t pfe_phy_if_set_op_mode(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -490,12 +460,10 @@ errno_t pfe_phy_if_set_op_mode(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -523,12 +491,10 @@ errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t blo
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -543,12 +509,10 @@ errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t blo
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -577,12 +541,10 @@ errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *bl
 	else
 #endif /* GLOBAL_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -601,12 +563,10 @@ errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *bl
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -727,12 +687,10 @@ bool_t pfe_phy_if_is_enabled(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -750,12 +708,10 @@ bool_t pfe_phy_if_is_enabled(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return status;
@@ -783,12 +739,10 @@ errno_t pfe_phy_if_enable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -802,12 +756,10 @@ errno_t pfe_phy_if_enable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -864,21 +816,17 @@ errno_t pfe_phy_if_disable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		ret = pfe_phy_if_disable_nolock(iface);
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -998,12 +946,10 @@ bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1021,12 +967,10 @@ bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return status;
@@ -1054,12 +998,10 @@ errno_t pfe_phy_if_promisc_enable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1073,12 +1015,10 @@ errno_t pfe_phy_if_promisc_enable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1106,12 +1046,10 @@ errno_t pfe_phy_if_promisc_disable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1125,12 +1063,10 @@ errno_t pfe_phy_if_promisc_disable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1158,12 +1094,10 @@ errno_t pfe_phy_if_loopback_enable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1177,12 +1111,10 @@ errno_t pfe_phy_if_loopback_enable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1210,12 +1142,10 @@ errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1229,12 +1159,10 @@ errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1262,12 +1190,10 @@ errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1281,12 +1207,10 @@ errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1314,12 +1238,10 @@ errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1333,12 +1255,10 @@ errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1538,12 +1458,10 @@ errno_t pfe_phy_if_add_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr,
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1568,12 +1486,10 @@ errno_t pfe_phy_if_add_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr,
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1606,12 +1522,10 @@ errno_t pfe_phy_if_del_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr,
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1641,12 +1555,10 @@ errno_t pfe_phy_if_del_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr,
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1700,12 +1612,10 @@ errno_t pfe_phy_if_get_mac_addr_first(pfe_phy_if_t *iface, pfe_mac_addr_t addr,
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		ret = pfe_mac_db_get_first_addr(iface->mac_db, crit, type, owner, addr);
 		if(EOK != ret)
@@ -1713,12 +1623,10 @@ errno_t pfe_phy_if_get_mac_addr_first(pfe_phy_if_t *iface, pfe_mac_addr_t addr,
 			NXP_LOG_ERROR("%s: Unable to get MAC address: %d\n", iface->name, ret);
 		}
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1751,12 +1659,10 @@ errno_t pfe_phy_if_flush_mac_addrs(pfe_phy_if_t *iface, pfe_mac_db_crit_t crit,
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1781,12 +1687,10 @@ errno_t pfe_phy_if_flush_mac_addrs(pfe_phy_if_t *iface, pfe_mac_db_crit_t crit,
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
@@ -1819,26 +1723,23 @@ __attribute__((pure)) pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *i
 /**
  * @brief		Get name
  * @param[in]	iface The interface instance
- * @return		Pointer to interface name string or NULL if not found/failed
+ * @return		Pointer to interface name string or "(unknown)" when called with NULL
  */
-__attribute__((pure)) char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
+__attribute__((pure)) const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
 {
-#if defined(PFE_CFG_NULL_ARG_CHECK)
-	if (unlikely(NULL == iface))
+	const char_t *str;
+
+	if (NULL != iface)
 	{
-		NXP_LOG_ERROR("NULL argument received\n");
-		pfe_phy_if_get_name_unknown = NULL;
+		str = iface->name;
 	}
 	else
-#endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-		if (NULL != iface)
-		{
-			pfe_phy_if_get_name_unknown = iface->name;
-		}
+		NXP_LOG_WARNING("NULL argument received for pfe_phy_if_get_name\n");
+		str = "(unknown)";
 	}
 
-	return pfe_phy_if_get_name_unknown;
+	return str;
 }
 
 /**
@@ -1863,12 +1764,10 @@ errno_t pfe_phy_if_get_stats(pfe_phy_if_t *iface, pfe_ct_phy_if_stats_t *stat)
 	else
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_lock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex lock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 		(void)pfe_phy_if_db_lock();
 
@@ -1885,19 +1784,15 @@ errno_t pfe_phy_if_get_stats(pfe_phy_if_t *iface, pfe_ct_phy_if_stats_t *stat)
 
 		(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 		if (EOK != oal_mutex_unlock(&iface->lock))
 		{
 			NXP_LOG_ERROR("mutex unlock failed\n");
 		}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 	}
 
 	return ret;
 }
 
-#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS)
-
 /**
  * @brief		Return physical interface runtime statistics in text form
  * @details		Function writes formatted text into given buffer.
@@ -1928,8 +1823,6 @@ uint32_t pfe_phy_if_get_text_statistics(const pfe_phy_if_t *iface, char_t *buf,
 	return len;
 }
 
-#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(PFE_CFG_TEXT_STATS) */
-
 /**
  * @brief		Get statistic values in numeric form
  * @details		This function providing single statistic value
@@ -1953,12 +1846,10 @@ uint32_t pfe_phy_if_get_stat_value(pfe_phy_if_t *iface, uint32_t stat_id)
 	}
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_lock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex lock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	(void)pfe_phy_if_db_lock();
 
@@ -1977,20 +1868,13 @@ uint32_t pfe_phy_if_get_stat_value(pfe_phy_if_t *iface, uint32_t stat_id)
 
 	(void)pfe_phy_if_db_unlock();
 
-#ifndef PFE_CFG_TARGET_OS_AUTOSAR
 	if (EOK != oal_mutex_unlock(&iface->lock))
 	{
 		NXP_LOG_ERROR("mutex unlock failed\n");
 	}
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
 
 	return stat_val;
 }
 
-#ifdef PFE_CFG_TARGET_OS_AUTOSAR
-#define ETH_43_PFE_STOP_SEC_CODE
-#include "Eth_43_PFE_MemMap.h"
-#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
-
 #endif /* PFE_CFG_PFE_SLAVE */
 
diff --git a/sw/pfe_platform/src/pfe_rtable.c b/sw/pfe_platform/src/pfe_rtable.c
index 9bb94e5..dfabe91 100644
--- a/sw/pfe_platform/src/pfe_rtable.c
+++ b/sw/pfe_platform/src/pfe_rtable.c
@@ -106,6 +106,7 @@ struct pfe_rtable_entry_tag
 	uint32_t curr_timeout;						/*	!< Current timeout value */
 	uint32_t route_id;							/*	!< User-defined route ID */
 	bool_t route_id_valid;						/*	!< If TRUE then 'route_id' is valid */
+	int8_t ref_counter;							/*	!< Count of leased references (pointers) to this entry */
 	void *refptr;								/*	!< User-defined value */
 	pfe_rtable_callback_t callback;				/*	!< User-defined callback function */
 	void *callback_arg;							/*	!< User-defined callback argument */
@@ -180,6 +181,7 @@ static void pfe_rtable_free_stats_index(uint8_t index);
 static errno_t pfe_rtable_destroy_stats_table(pfe_class_t *class, uint32_t table_address);
 static bool_t pfe_rtable_entry_is_duplicate(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
 static errno_t pfe_rtable_add_entry_by_hash(pfe_rtable_t *rtable, uint32_t hash, void **new_phys_entry_va, void **last_phys_entry_va, addr_t *new_phys_entry_pa);
+static void pfe_rtable_entry_free_nolock(pfe_rtable_entry_t *entry, bool_t decrement_reference);
 
 errno_t pfe_rtable_clear_stats(const pfe_rtable_t *rtable, uint8_t conntrack_index);
 #if !defined(PFE_CFG_TARGET_OS_AUTOSAR)
@@ -190,35 +192,37 @@ errno_t pfe_rtable_clear_stats(const pfe_rtable_t *rtable, uint8_t conntrack_ind
 
 static void read_phys_entry_dbus(addr_t phys_entry, pfe_ct_rtable_entry_t *phys_entry_cache)
 {
-	memcpy(phys_entry_cache, (void *)phys_entry, sizeof(*phys_entry_cache));
+	memcpy_fromio(phys_entry_cache, (void __iomem *)phys_entry, sizeof(*phys_entry_cache));
 }
 
 static void write_phys_entry_dbus(addr_t phys_entry, pfe_ct_rtable_entry_t *phys_entry_cache)
 {
-	memcpy((void *)phys_entry, phys_entry_cache, sizeof(*phys_entry_cache));
+	memcpy_toio((void __iomem *)phys_entry, phys_entry_cache, sizeof(*phys_entry_cache));
 }
 
 static void read_phys_entry_cbus(addr_t phys_entry, pfe_ct_rtable_entry_t *phys_entry_cache)
 {
 	uint32_t *data_out = (uint32_t *)phys_entry_cache;
-	uint32_t *data_in = (uint32_t *)phys_entry;
 	int i, words = sizeof(*phys_entry_cache) >> 2;
+	addr_t data_in = phys_entry;
 
 	for (i = 0; i < words; i++)
 	{
-		data_out[i] = oal_ntohl(data_in[i]);
+		data_out[i] = oal_ntohl(hal_read32(data_in));
+		data_in += 4;
 	}
 }
 
 static void write_phys_entry_cbus(addr_t phys_entry, pfe_ct_rtable_entry_t *phys_entry_cache)
 {
-	uint32_t *data_out = (uint32_t *)phys_entry;
 	uint32_t *data_in = (uint32_t *)phys_entry_cache;
 	int i, words = sizeof(*phys_entry_cache) >> 2;
+	addr_t data_out = phys_entry;
 
 	for (i = 0; i < words; i++)
 	{
-		data_out[i] = oal_htonl(data_in[i]);
+		hal_write32(oal_htonl(data_in[i]), data_out);
+		data_out += 4;
 	}
 }
 
@@ -248,7 +252,7 @@ static void pfe_rtable_write_phys_entry(addr_t phys_entry, pfe_ct_rtable_entry_t
 
 static void pfe_rtable_clear_phys_entry(addr_t phys_entry)
 {
-	memset((void *)phys_entry, 0, sizeof(pfe_ct_rtable_entry_t));
+	memset_io((void __iomem *)phys_entry, 0, sizeof(pfe_ct_rtable_entry_t));
 }
 
 /**
@@ -645,6 +649,7 @@ pfe_rtable_entry_t *pfe_rtable_entry_create(void)
 			entry->curr_timeout = entry->timeout;
 			entry->route_id = 0U;
 			entry->route_id_valid = FALSE;
+			entry->ref_counter = 0;
 			entry->callback = NULL;
 			entry->callback_arg = NULL;
 			entry->refptr = NULL;
@@ -658,22 +663,88 @@ pfe_rtable_entry_t *pfe_rtable_entry_create(void)
 }
 
 /**
- * @brief		Release routing table entry instance
- * @details		Once the previously created routing table entry instance is not needed
- *				anymore (inserted into the routing table), allocated resources shall
- *				be released using this call.
- * @param[in]	entry Entry instance previously created by pfe_rtable_entry_create()
+ * @brief		Decrement routing table entry refrence counter. Deallocate the entry if no more references.
+ * @details		Internal "_nolock" function. It assumes that routing table mutex is already locked.
+ * @param[in]	entry	Entry instance previously created by pfe_rtable_entry_create()
+ * @param[in]	decrement_ref_counter
+ * 						Flag for reference counter decrement.
+ * 						TRUE : Function decrements ref_counter. This is a normal behavior.
+ * 						FALSE: Function does not decrement ref_counter. This is a special behavior
+ *								for internal routing table contexts where pointer to entry can be 
+ * 								obtained directly, without a need for ref_counter increment.
  */
-void pfe_rtable_entry_free(pfe_rtable_entry_t *entry)
+static void pfe_rtable_entry_free_nolock(pfe_rtable_entry_t *entry, bool_t decrement_ref_counter)
 {
 	if (NULL != entry)
 	{
-		if (NULL != entry->phys_entry_cache)
+		if (TRUE == decrement_ref_counter)
 		{
-			oal_mm_free(entry->phys_entry_cache);
+			entry->ref_counter--;
 		}
 
-		oal_mm_free(entry);
+		if (0 >= entry->ref_counter)
+		{
+			/* Sanity check: Entry is set for deallocation, but is still part of some rtable. THIS SHOULD NEVER HAPPEN */
+			if (NULL != entry->rtable)
+			{
+				NXP_LOG_WARNING("Refused to deallocate RTable entry @ v0x%p, because the entry is still in some RTable.\n", (void *)entry->phys_entry_va);
+			}
+			else
+			{
+				/* If child link exists, then NULLify the link of child entry. This prevents invalid access to deallocated memory through child pointer. */
+				if (NULL != entry->child)
+				{
+					entry->child->child = NULL;
+				}
+
+				/* deallocate intermediate 'physical' entry storage */
+				if (NULL != entry->phys_entry_cache)
+				{
+					oal_mm_free(entry->phys_entry_cache);
+				}
+
+				/* deallocate the entry */
+				oal_mm_free(entry);
+			}
+		}
+	}
+}
+
+/**
+ * @brief		Decrement routing table entry refrence counter. Deallocate the entry if no more references.
+ * @param[in]	rtable	The routing table instance. Needed only for mutex lock.
+ *							Can be NULL if working with standalone routing table entry which
+ *							has never been a part of any routing table. In all other cases,
+ *							provide last routing table which owned the entry.
+ * @param[in]	entry	Entry instance previously created by pfe_rtable_entry_create()
+ *
+ * @important	When code outside of this module obtains pointer to some routing table entry
+ * 				via _get_first()/_get_next() or via _get_child(), then call this function
+ * 				in outside code when the outside code is done working with the entry.
+ */
+void pfe_rtable_entry_free(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
+{
+	if (NULL != entry)
+	{
+		/* protect ref_counter manipulation */
+		if (NULL != rtable)
+		{
+			if (unlikely(EOK != oal_mutex_lock(rtable->lock)))
+			{
+				NXP_LOG_ERROR("Mutex lock failed\n");
+			}
+		}
+
+		pfe_rtable_entry_free_nolock(entry, TRUE);
+
+		/* stop protecting ref_counter manipulation */
+		if (NULL != rtable)
+		{
+			if (unlikely(EOK != oal_mutex_unlock(rtable->lock)))
+			{
+				NXP_LOG_ERROR("Mutex unlock failed\n");
+			}
+		}
 	}
 }
 
@@ -1847,15 +1918,25 @@ void pfe_rtable_entry_set_child(pfe_rtable_entry_t *entry, pfe_rtable_entry_t *c
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
 		entry->child = child;
+		if (NULL != child)
+		{
+			child->child = entry;
+		}
 	}
 }
 
 /**
  * @brief		Get associated entry
- * @param[in]	entry The routing table entry instance
+ * @details		"_nolock" function. It assumes that routing table mutex is already locked.
+ *				Outside of the routing table module, this function should be called only from
+ *				routing table callbacks.
+ * @param[in]	entry	The routing table entry instance
  * @return		The associated routing table entry linked with the 'entry'. NULL if there is not link.
+ *
+ * @note		When execution thread which called this function finishes working with the provided entry,
+ *				it must call pfe_rtable_entry_free() for the given entry to "release" it.
  */
-pfe_rtable_entry_t *pfe_rtable_entry_get_child(const pfe_rtable_entry_t *entry)
+pfe_rtable_entry_t *pfe_rtable_entry_get_child_nolock(const pfe_rtable_entry_t *entry)
 {
 	pfe_rtable_entry_t *ptr;
 
@@ -1869,6 +1950,47 @@ pfe_rtable_entry_t *pfe_rtable_entry_get_child(const pfe_rtable_entry_t *entry)
 #endif /* PFE_CFG_NULL_ARG_CHECK */
 	{
 		ptr = entry->child;
+		if (NULL != ptr)
+		{
+			ptr->ref_counter++;
+		}
+	}
+
+	return ptr;
+}
+
+/**
+ * @brief		Get associated entry
+ * @param[in]	rtable	The routing table instance. Needed only for mutex lock.
+ *							Can be NULL if working with standalone routing table entry which
+ *							has never been a part of any routing table. In all other cases,
+ *							provide last routing table which owned the entry.
+ * @param[in]	entry	The routing table entry instance
+ * @return		The associated routing table entry linked with the 'entry'. NULL if there is not link.
+ *
+ * @note		When execution thread which called this function finishes working with the provided entry,
+ *				it must call pfe_rtable_entry_free() for the given entry to "release" it.
+ */
+pfe_rtable_entry_t *pfe_rtable_entry_get_child(pfe_rtable_t *rtable, const pfe_rtable_entry_t *entry)
+{
+	pfe_rtable_entry_t *ptr;
+
+	if (NULL != rtable)
+	{
+		if (unlikely(EOK != oal_mutex_lock(rtable->lock)))
+		{
+			NXP_LOG_ERROR("Mutex lock failed\n");
+		}
+	}
+
+	ptr = pfe_rtable_entry_get_child_nolock(entry);
+
+	if (NULL != rtable)
+	{
+		if (unlikely(EOK != oal_mutex_unlock(rtable->lock)))
+		{
+			NXP_LOG_ERROR("Mutex unlock failed\n");
+		}
 	}
 
 	return ptr;
@@ -2210,6 +2332,7 @@ errno_t pfe_rtable_add_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
 		NXP_LOG_INFO("RTable entry added, hash: 0x%x\n", (uint_t)hash);
 
 		entry->rtable = rtable;
+		entry->ref_counter++;
 
 		if (0U == rtable->active_entries_count)
 		{
@@ -2462,6 +2585,7 @@ static errno_t pfe_rtable_del_entry_nolock(pfe_rtable_t *rtable, pfe_rtable_entr
 	}
 
 	entry->rtable = NULL;
+	entry->ref_counter--;
 
 	if (rtable->active_entries_count > 0U)
 	{
@@ -2483,7 +2607,7 @@ static errno_t pfe_rtable_del_entry_nolock(pfe_rtable_t *rtable, pfe_rtable_entr
  */
 void pfe_rtable_do_timeouts(pfe_rtable_t *rtable)
 {
-	LLIST_t *item;
+	LLIST_t *item, *aux;
 	LLIST_t to_be_removed_list;
 	pfe_rtable_entry_t *entry;
 	uint8_t flags;
@@ -2556,7 +2680,7 @@ void pfe_rtable_do_timeouts(pfe_rtable_t *rtable)
 			}
 		}
 
-		LLIST_ForEach(item, &to_be_removed_list)
+		LLIST_ForEachRemovable(item, aux, &to_be_removed_list)
 		{
 			entry = LLIST_Data(item, pfe_rtable_entry_t, list_to_remove_entry);
 
@@ -2566,6 +2690,10 @@ void pfe_rtable_do_timeouts(pfe_rtable_t *rtable)
 			{
 				NXP_LOG_ERROR("Couldn't delete timed-out entry: %d\n", err);
 			}
+			else
+			{
+				pfe_rtable_entry_free_nolock(entry, FALSE);
+			}
 		}
 
 		if (unlikely(EOK != oal_mutex_unlock(rtable->lock)))
@@ -3207,12 +3335,15 @@ static bool_t pfe_rtable_match_criterion(pfe_rtable_get_criterion_t crit, const
 /**
  * @brief		Get first record from the table matching given criterion
  * @details		Intended to be used with pfe_rtable_get_next
- * @param[in]	rtable The routing table instance
- * @param[in]	crit Get criterion
- * @param[in]	art Pointer to criterion argument. Every value shall to be in HOST endian format.
+ * @param[in]	rtable	The routing table instance
+ * @param[in]	crit	Search criterion
+ * @param[in]	arg		Pointer to criterion argument. Every value shall to be in HOST endian format.
  * @return		The entry or NULL if not found
+ * 
  * @warning		The routing table must be locked for the time the function and its returned entry
  *				is being used since the entry might become asynchronously invalid (timed-out).
+ * @note		When execution thread which called this function finishes working with the provided entry,
+ *				it must call pfe_rtable_entry_free() for the given entry to "release" it.
  */
 pfe_rtable_entry_t *pfe_rtable_get_first(pfe_rtable_t *rtable, pfe_rtable_get_criterion_t crit, void *arg)
 {
@@ -3285,6 +3416,7 @@ pfe_rtable_entry_t *pfe_rtable_get_first(pfe_rtable_t *rtable, pfe_rtable_get_cr
 					if (TRUE == pfe_rtable_match_criterion(rtable->cur_crit, &rtable->cur_crit_arg, entry))
 					{
 						match = TRUE;
+						entry->ref_counter++;
 						break;
 					}
 				}
@@ -3308,10 +3440,13 @@ pfe_rtable_entry_t *pfe_rtable_get_first(pfe_rtable_t *rtable, pfe_rtable_get_cr
 /**
  * @brief		Get next record from the table
  * @details		Intended to be used with pfe_rtable_get_first.
- * @param[in]	rtable The routing table instance
+ * @param[in]	rtable	The routing table instance
  * @return		The entry or NULL if not found
+ * 
  * @warning		The routing table must be locked for the time the function and its returned entry
  *				is being used since the entry might become asynchronously invalid (timed-out).
+ * @note		When execution thread which called this function finishes working with the provided entry,
+ *				it must call pfe_rtable_entry_free() for the given entry to "release" it.
  */
 pfe_rtable_entry_t *pfe_rtable_get_next(pfe_rtable_t *rtable)
 {
@@ -3353,6 +3488,7 @@ pfe_rtable_entry_t *pfe_rtable_get_next(pfe_rtable_t *rtable)
 					if (TRUE == pfe_rtable_match_criterion(rtable->cur_crit, &rtable->cur_crit_arg, entry))
 					{
 						match = TRUE;
+						entry->ref_counter++;
 						break;
 					}
 				}
diff --git a/sw/pfe_platform/src/pfe_spd_acc.c b/sw/pfe_platform/src/pfe_spd_acc.c
index 04f5a17..cf4828e 100644
--- a/sw/pfe_platform/src/pfe_spd_acc.c
+++ b/sw/pfe_platform/src/pfe_spd_acc.c
@@ -1,7 +1,7 @@
 /* =========================================================================
  *  
  *  Copyright (c) 2019 Imagination Technologies Limited
- *  Copyright 2020-2022 NXP
+ *  Copyright 2020-2023 NXP
  *
  *  SPDX-License-Identifier: GPL-2.0
  *
@@ -218,7 +218,7 @@ errno_t pfe_spd_acc_add_rule(pfe_phy_if_t *phy_if, uint16_t position, pfe_ct_spd
                 ret = pfe_spd_acc_convert_to_rt_entry(entry, rt_entry);
                 if(EOK != ret)
                 {   /* Conversion failure - revert changes */
-                    pfe_rtable_entry_free(rt_entry);
+                    pfe_rtable_entry_free(NULL, rt_entry);
                     blalloc_free_offs_size(pfe_spd_acc_id_pool, id, 1U);
                     /* We can still add entry as not accelerated here */
                 }
@@ -237,7 +237,7 @@ errno_t pfe_spd_acc_add_rule(pfe_phy_if_t *phy_if, uint16_t position, pfe_ct_spd
                         {   /* Failed to set SPD entry */
                             /* Revert the changes */
                             pfe_rtable_del_entry(rtable_ptr, rt_entry);
-                            pfe_rtable_entry_free(rt_entry);
+                            pfe_rtable_entry_free(rtable_ptr, rt_entry);
                             blalloc_free_offs_size(pfe_spd_acc_id_pool, id, 1U);
                             /* No need to try again adding entry as not accelerated because
                                the same function would be called and fail as well */
@@ -252,7 +252,7 @@ errno_t pfe_spd_acc_add_rule(pfe_phy_if_t *phy_if, uint16_t position, pfe_ct_spd
                     else
                     {   /* Failed to add route entry */
                         /* Free the unused entry */
-                        pfe_rtable_entry_free(rt_entry);
+                        pfe_rtable_entry_free(rtable_ptr, rt_entry);
                         /* Free unique ID previously allocated */
                         blalloc_free_offs_size(pfe_spd_acc_id_pool, id, 1U);
                         /* We can still add entry as not accelerated here */
@@ -331,7 +331,7 @@ errno_t pfe_spd_acc_remove_rule(pfe_phy_if_t * phy_if, uint16_t position)
         {
             /* Remove IP route entry and destroy it */
             pfe_rtable_del_entry(rtable_ptr, rt_entry);
-            pfe_rtable_entry_free(rt_entry);
+            pfe_rtable_entry_free(rtable_ptr, rt_entry);
         }
         /* Free the unique identifier */
         blalloc_free_offs_size(pfe_spd_acc_id_pool, entry.id5t, 1U);
-- 
2.25.1

